{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch BERT baseline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bert-base (uncased-v2, cased-v2) swa + xlnet (5 folds, seed 2333) + bert-base-uncased (question + answer) swa + bert-base-cased (question + answer) swa + xlnet (question + answer) swa + roberta (question + answer) + postprocessing (seefun's version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/sacremoses/sacremoses-master\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses==0.0.35) (1.12.0)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses==0.0.35) (7.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses==0.0.35) (0.13.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from sacremoses==0.0.35) (4.36.1)\r\n",
      "Building wheels for collected packages: sacremoses\r\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=882724 sha256=98f48dbc621c2beff19d0eff18dde09b688b82221df5b66e9ced3292b036868f\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/48/4b/05cb49d913a40c9d76f97931cd747d72fb17a77b0f6415cdba\r\n",
      "Successfully built sacremoses\r\n",
      "Installing collected packages: sacremoses\r\n",
      "Successfully installed sacremoses-0.0.35\r\n",
      "Processing /kaggle/input/transformers/transformers-master\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from transformers==2.1.1) (1.16.4)\r\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from transformers==2.1.1) (1.10.2)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==2.1.1) (2.22.0)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from transformers==2.1.1) (4.36.1)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from transformers==2.1.1) (2019.8.19)\r\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from transformers==2.1.1) (0.1.83)\r\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers==2.1.1) (0.0.35)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (0.2.1)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (0.9.4)\r\n",
      "Requirement already satisfied: botocore<1.14.0,>=1.13.2 in /opt/conda/lib/python3.6/site-packages (from boto3->transformers==2.1.1) (1.13.2)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.1.1) (3.0.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.1.1) (2019.9.11)\r\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.1.1) (1.24.2)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.1.1) (2.8)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (1.12.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (0.13.2)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.1.1) (7.0)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.2->boto3->transformers==2.1.1) (2.8.0)\r\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.14.0,>=1.13.2->boto3->transformers==2.1.1) (0.15.2)\r\n",
      "Building wheels for collected packages: transformers\r\n",
      "  Building wheel for transformers (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for transformers: filename=transformers-2.1.1-cp36-none-any.whl size=334890 sha256=8ee6d1b51d5fd5f1fe843e5186b6d5d2fd875344b7766161efd74308fcb8c1e3\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ce/f3/1a/ee7248890cb4b8e8975988b1a67999e2d09ef54ce8ee815255\r\n",
      "Successfully built transformers\r\n",
      "Installing collected packages: transformers\r\n",
      "Successfully installed transformers-2.1.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ../input/sacremoses/sacremoses-master/\n",
    "!pip install ../input/transformers/transformers-master/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports\n",
    "\n",
    "I've added imports that will be used in training too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "DATA_DIR = '../input/google-quest-challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google-quest-challenge\t\t     qarobertabasecasedaugdiffswaquestion\r\n",
      "pretrained-bert-models-for-pytorch   qaxlnetbasecasedaugdiff\r\n",
      "qabertbasecasedaugdiffswaanswer      qaxlnetbasecasedaugdiffswaanswer\r\n",
      "qabertbasecasedaugdiffswaquestion    qaxlnetbasecasedaugdiffswaquestion\r\n",
      "qabertbasecasedaugdiffv2swa\t     qaxlnetbasecasedaugquestionanswerswa\r\n",
      "qabertbaseuncasedaugdiffswaanswer    roberta-transformers-pytorch\r\n",
      "qabertbaseuncasedaugdiffswaquestion  sacremoses\r\n",
      "qabertuncasedaugdiffv2swa\t     transformers\r\n",
      "qarobertabaseaugdiffswa\t\t     xlnet-pretrained-models-pytorch\r\n",
      "qarobertabasecasedaugdiffswaanswer\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vocab.json',\n",
       " 'config.json',\n",
       " 'special_tokens_map.json',\n",
       " 'merges.txt',\n",
       " 'added_tokens.json',\n",
       " 'pytorch_model.bin',\n",
       " 'tokenizer_config.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/roberta-transformers-pytorch/roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qaxlnetbasecasedaugdiffswaanswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qaxlnetbasecasedaugdiffswaquestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qabertbaseuncasedaugdiffswaanswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qabertbaseuncasedaugdiffswaquestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qabertbasecasedaugdiffswaanswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qabertbasecasedaugdiffswaquestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_9_checkpoint_swa.pth',\n",
       " 'fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_8_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_6_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_7_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth',\n",
       " 'fold_5_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qabertbasecasedaugdiffv2swa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_9_checkpoint_swa.pth',\n",
       " 'fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_8_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_6_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_7_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth',\n",
       " 'fold_5_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qabertuncasedaugdiffv2swa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_3_checkpoint.pth',\n",
       " 'fold_2_checkpoint.pth',\n",
       " 'fold_4_checkpoint.pth',\n",
       " 'fold_1_checkpoint.pth',\n",
       " 'fold_0_checkpoint.pth']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qaxlnetbasecasedaugdiff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fold_0_checkpoint_swa.pth',\n",
       " 'fold_2_checkpoint_swa.pth',\n",
       " 'fold_1_checkpoint_swa.pth',\n",
       " 'fold_3_checkpoint_swa.pth',\n",
       " 'fold_4_checkpoint_swa.pth']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../input/qarobertabasecasedaugdiffswaquestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "      <td>0.00308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.00448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "      <td>0.00673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "      <td>0.01401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "      <td>0.02074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                              0.00308                 0.00308   \n",
       "1     46                              0.00448                 0.00448   \n",
       "2     70                              0.00673                 0.00673   \n",
       "3    132                              0.01401                 0.01401   \n",
       "4    200                              0.02074                 0.02074   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                  0.00308                       0.00308   \n",
       "1                  0.00448                       0.00448   \n",
       "2                  0.00673                       0.00673   \n",
       "3                  0.01401                       0.01401   \n",
       "4                  0.02074                       0.02074   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0                0.00308                                0.00308   \n",
       "1                0.00448                                0.00448   \n",
       "2                0.00673                                0.00673   \n",
       "3                0.01401                                0.01401   \n",
       "4                0.02074                                0.02074   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                          0.00308                        0.00308   \n",
       "1                          0.00448                        0.00448   \n",
       "2                          0.00673                        0.00673   \n",
       "3                          0.01401                        0.01401   \n",
       "4                          0.02074                        0.02074   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0                0.00308  ...                0.00308         0.00308   \n",
       "1                0.00448  ...                0.00448         0.00448   \n",
       "2                0.00673  ...                0.00673         0.00673   \n",
       "3                0.01401  ...                0.01401         0.01401   \n",
       "4                0.02074  ...                0.02074         0.02074   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                      0.00308           0.00308           0.00308   \n",
       "1                      0.00448           0.00448           0.00448   \n",
       "2                      0.00673           0.00673           0.00673   \n",
       "3                      0.01401           0.01401           0.01401   \n",
       "4                      0.02074           0.02074           0.02074   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0              0.00308                   0.00308                0.00308   \n",
       "1              0.00448                   0.00448                0.00448   \n",
       "2              0.00673                   0.00673                0.00673   \n",
       "3              0.01401                   0.01401                0.01401   \n",
       "4              0.02074                   0.02074                0.02074   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                         0.00308              0.00308  \n",
       "1                         0.00448              0.00448  \n",
       "2                         0.00673              0.00673  \n",
       "3                         0.01401              0.01401  \n",
       "4                         0.02074              0.02074  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(f'{DATA_DIR}/sample_submission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['question_asker_intent_understanding',\n",
       " 'question_body_critical',\n",
       " 'question_conversational',\n",
       " 'question_expect_short_answer',\n",
       " 'question_fact_seeking',\n",
       " 'question_has_commonly_accepted_answer',\n",
       " 'question_interestingness_others',\n",
       " 'question_interestingness_self',\n",
       " 'question_multi_intent',\n",
       " 'question_not_really_a_question',\n",
       " 'question_opinion_seeking',\n",
       " 'question_type_choice',\n",
       " 'question_type_compare',\n",
       " 'question_type_consequence',\n",
       " 'question_type_definition',\n",
       " 'question_type_entity',\n",
       " 'question_type_instructions',\n",
       " 'question_type_procedure',\n",
       " 'question_type_reason_explanation',\n",
       " 'question_type_spelling',\n",
       " 'question_well_written',\n",
       " 'answer_helpful',\n",
       " 'answer_level_of_information',\n",
       " 'answer_plausible',\n",
       " 'answer_relevance',\n",
       " 'answer_satisfaction',\n",
       " 'answer_type_instructions',\n",
       " 'answer_type_procedure',\n",
       " 'answer_type_reason_explanation',\n",
       " 'answer_well_written']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET_COLUMNS = sub.columns.values[1:].tolist()\n",
    "TARGET_COLUMNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0      0  What am I losing when using extension tubes in...   \n",
       "1      1  What is the distinction between a city and a s...   \n",
       "2      2  Maximum protusion length for through-hole comp...   \n",
       "3      3              Can an affidavit be used in Beit Din?   \n",
       "4      5       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  ...  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
       "\n",
       "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0              1.000000        1.000000                     0.666667   \n",
       "1              0.888889        0.888889                     0.555556   \n",
       "2              0.777778        0.777778                     0.555556   \n",
       "3              0.888889        0.833333                     0.333333   \n",
       "4              1.000000        1.000000                     0.666667   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          1.000000          1.000000             0.800000   \n",
       "1          0.888889          0.888889             0.666667   \n",
       "2          1.000000          1.000000             0.666667   \n",
       "3          0.833333          1.000000             0.800000   \n",
       "4          1.000000          1.000000             0.800000   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                       1.0               0.000000   \n",
       "1                       0.0               0.000000   \n",
       "2                       0.0               0.333333   \n",
       "3                       0.0               0.000000   \n",
       "4                       1.0               0.000000   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.000000             1.000000  \n",
       "1                        0.666667             0.888889  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             1.000000  \n",
       "4                        1.000000             1.000000  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0     39  Will leaving corpses lying around upset my pri...   \n",
       "1     46         Url link to feature image in the portfolio   \n",
       "2     70  Is accuracy, recoil or bullet spread affected ...   \n",
       "3    132     Suddenly got an I/O error from my external HDD   \n",
       "4    200  Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  I see questions/information online about how t...              Dylan   \n",
       "1  I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "2  To experiment I started a bot game, toggled in...             Konsta   \n",
       "3  I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "4  I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0       https://gaming.stackexchange.com/users/64471   \n",
       "1    https://wordpress.stackexchange.com/users/72927   \n",
       "2       https://gaming.stackexchange.com/users/37545   \n",
       "3  https://raspberrypi.stackexchange.com/users/17341   \n",
       "4       https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  There is no consequence for leaving corpses an...        Nelson868   \n",
       "1  I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "2  You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "3  Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "4  I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                   answer_user_page  \\\n",
       "0      https://gaming.stackexchange.com/users/97324   \n",
       "1   https://wordpress.stackexchange.com/users/27233   \n",
       "2      https://gaming.stackexchange.com/users/70641   \n",
       "3  https://raspberrypi.stackexchange.com/users/1311   \n",
       "4      https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                 url    category  \\\n",
       "0  http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "1  http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "2  http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "3  http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "4  http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                            host  \n",
       "0       gaming.stackexchange.com  \n",
       "1    wordpress.stackexchange.com  \n",
       "2       gaming.stackexchange.com  \n",
       "3  raspberrypi.stackexchange.com  \n",
       "4       travel.stackexchange.com  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#import torch.utils.data as data\n",
    "from torchvision import datasets, models, transforms\n",
    "from transformers import *\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "from math import floor, ceil\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "MAX_LEN = 512\n",
    "#MAX_Q_LEN = 250\n",
    "#MAX_A_LEN = 259\n",
    "SEP_TOKEN_ID = 102\n",
    "\n",
    "class QuestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, model_type=\"bert-base-cased\", max_len=512, content=\"Question_Answer\", train_mode=True, labeled=True):\n",
    "        self.df = df\n",
    "        self.train_mode = train_mode\n",
    "        self.labeled = labeled\n",
    "        self.max_len = max_len\n",
    "        self.content = content\n",
    "        bert_tokenizer_path = '../input/pretrained-bert-models-for-pytorch/' + model_type + '-vocab.txt'\n",
    "        xlnet_tokenizer_path = '../input/xlnet-pretrained-models-pytorch/' + model_type + '-spiece.model'\n",
    "        roberta_tokenizer_path = '../input/roberta-transformers-pytorch/roberta-base/vocab.json'\n",
    "        roberta_tokenizer_merges_file = '../input/roberta-transformers-pytorch/roberta-base/merges.txt'\n",
    "        if model_type == \"bert-base-uncased\":\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(bert_tokenizer_path)\n",
    "        elif model_type == \"bert-base-cased\":\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(bert_tokenizer_path)\n",
    "        elif model_type == \"xlnet-base-cased\":\n",
    "            self.tokenizer = XLNetTokenizer.from_pretrained(xlnet_tokenizer_path)\n",
    "        elif model_type == \"roberta-base\":\n",
    "            self.tokenizer = RobertaTokenizer(vocab_file=roberta_tokenizer_path, merges_file=roberta_tokenizer_merges_file)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        token_ids, seg_ids = self.get_token_ids(row)\n",
    "        if self.labeled:\n",
    "            labels = self.get_label(row)\n",
    "            return token_ids, seg_ids, labels\n",
    "        else:\n",
    "            return token_ids, seg_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def select_tokens(self, tokens, max_num):\n",
    "        if len(tokens) <= max_num:\n",
    "            return tokens\n",
    "        if self.train_mode:\n",
    "            num_remove = len(tokens) - max_num\n",
    "            remove_start = random.randint(0, len(tokens)-num_remove-1)\n",
    "            return tokens[:remove_start] + tokens[remove_start + num_remove:]\n",
    "        else:\n",
    "            return tokens[:max_num//2] + tokens[-(max_num - max_num//2):]\n",
    "        \n",
    "    def trim_input_single_content(self, title, content, max_sequence_length=512, \n",
    "                t_max_len=30, c_max_len=512-30-4, num_token=3):\n",
    "\n",
    "        t = self.tokenizer.tokenize(title)\n",
    "        c = self.tokenizer.tokenize(content)\n",
    "\n",
    "        t_len = len(t)\n",
    "        c_len = len(c)\n",
    "\n",
    "        if (t_len+c_len+num_token) > max_sequence_length:\n",
    "\n",
    "            if t_max_len > t_len:\n",
    "                t_new_len = t_len\n",
    "                c_max_len = c_max_len + floor((t_max_len - t_len)/2)\n",
    "            else:\n",
    "                t_new_len = t_max_len\n",
    "\n",
    "            if c_max_len > c_len:\n",
    "                c_new_len = c_len \n",
    "            else:\n",
    "                c_new_len = c_max_len\n",
    "\n",
    "\n",
    "            if t_new_len+c_new_len+num_token > max_sequence_length:\n",
    "                raise ValueError(\"New sequence length should be less or equal than %d, but is %d\" \n",
    "                                 % (max_sequence_length, (t_new_len+c_new_len+num_token)))\n",
    "            \n",
    "            # truncate\n",
    "            if len(t) - t_new_len > 0:\n",
    "                t = t[:t_new_len//4] + t[len(t)-t_new_len+t_new_len//4:]\n",
    "            else:\n",
    "                t = t[:t_new_len]\n",
    "\n",
    "            if len(c) - c_new_len > 0:\n",
    "                c = c[:c_new_len//4] + c[len(c)-c_new_len+c_new_len//4:]\n",
    "            else:\n",
    "                c = c[:c_new_len]\n",
    "\n",
    "        # some bad cases\n",
    "        if (len(t) + len(c) + num_token > max_sequence_length):\n",
    "            more_token = len(t) + len(c) + num_token - max_sequence_length\n",
    "            c = c[:(len(c)-more_token)]\n",
    "        \n",
    "        return t, c\n",
    "            \n",
    "    def trim_input(self, title, question, answer, max_sequence_length=MAX_LEN, \n",
    "                t_max_len=30, q_max_len=239, a_max_len=239, num_token=4):\n",
    "\n",
    "        t = self.tokenizer.tokenize(title)\n",
    "        q = self.tokenizer.tokenize(question)\n",
    "        a = self.tokenizer.tokenize(answer)\n",
    "\n",
    "        t_len = len(t)\n",
    "        q_len = len(q)\n",
    "        a_len = len(a)\n",
    "\n",
    "        if (t_len+q_len+a_len+num_token) > max_sequence_length:\n",
    "\n",
    "            if t_max_len > t_len:\n",
    "                t_new_len = t_len\n",
    "                a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "                q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "            else:\n",
    "                t_new_len = t_max_len\n",
    "\n",
    "            if a_max_len > a_len:\n",
    "                a_new_len = a_len \n",
    "                q_new_len = q_max_len + (a_max_len - a_len)\n",
    "            elif q_max_len > q_len:\n",
    "                a_new_len = a_max_len + (q_max_len - q_len)\n",
    "                q_new_len = q_len\n",
    "            else:\n",
    "                a_new_len = a_max_len\n",
    "                q_new_len = q_max_len\n",
    "\n",
    "\n",
    "            if t_new_len+a_new_len+q_new_len+num_token > max_sequence_length:\n",
    "                raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                                 % (max_sequence_length, (t_new_len+a_new_len+q_new_len+num_token)))\n",
    "\n",
    "            \n",
    "            # truncate\n",
    "            if len(t) - t_new_len > 0:\n",
    "                t = t[:t_new_len//4] + t[len(t)-t_new_len+t_new_len//4:]\n",
    "            else:\n",
    "                t = t[:t_new_len]\n",
    "\n",
    "            if len(q) - q_new_len > 0:\n",
    "                q = q[:q_new_len//4] + q[len(q)-q_new_len+q_new_len//4:]\n",
    "            else:\n",
    "                q = q[:q_new_len]\n",
    "\n",
    "            if len(a) - a_new_len > 0:\n",
    "                a = a[:a_new_len//4] + a[len(a)-a_new_len+a_new_len//4:]\n",
    "            else:\n",
    "                a = a[:a_new_len]\n",
    "\n",
    "        return t, q, a\n",
    "        \n",
    "    def get_token_ids(self, row):\n",
    "        \n",
    "        num_token = 4\n",
    "        \n",
    "        if self.content == \"Question\":\n",
    "            num_token -= 1\n",
    "        elif self.content == \"Answer\":\n",
    "            num_token -= 1\n",
    "        \n",
    "        if self.content == \"Question_Answer\":   \n",
    "            t_max_len=30\n",
    "            q_max_len=int((self.max_len-t_max_len-num_token)/2)\n",
    "            a_max_len=(self.max_len-t_max_len - num_token - int((self.max_len-t_max_len-num_token)/2))\n",
    "        elif self.content == \"Question\":\n",
    "            t_max_len=30\n",
    "            q_max_len=self.max_len-t_max_len-num_token\n",
    "            a_max_len=0\n",
    "        elif self.content == \"Answer\":\n",
    "            t_max_len=30\n",
    "            q_max_len=0\n",
    "            a_max_len=self.max_len-t_max_len-num_token  \n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        if self.content == \"Question_Answer\":\n",
    "            t_tokens, q_tokens, a_tokens = self.trim_input(row.question_title, row.question_body, row.answer, max_sequence_length=self.max_len, \\\n",
    "                t_max_len=t_max_len, q_max_len=q_max_len, a_max_len=a_max_len, num_token=num_token)\n",
    "        elif self.content == \"Question\":\n",
    "            t_tokens, c_tokens = self.trim_input_single_content(row.question_title, row.question_body, max_sequence_length=self.max_len, \\\n",
    "                t_max_len=t_max_len, c_max_len=q_max_len, num_token=num_token)\n",
    "        elif self.content == \"Answer\":\n",
    "            t_tokens, c_tokens = self.trim_input_single_content(row.question_title, row.answer, max_sequence_length=self.max_len, \\\n",
    "                t_max_len=t_max_len, c_max_len=a_max_len, num_token=num_token)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if self.content == \"Question_Answer\":\n",
    "            tokens = ['[CLS]'] + t_tokens + ['[SEP]'] + q_tokens + ['[SEP]'] + a_tokens + ['[SEP]']\n",
    "        elif ((self.content == \"Question\") or (self.content == \"Answer\")):\n",
    "            tokens = ['[CLS]'] + t_tokens + ['[SEP]'] + c_tokens + ['[SEP]']\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "                \n",
    "        token_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        if len(token_ids) < self.max_len:\n",
    "            token_ids += [0] * (self.max_len - len(token_ids))\n",
    "        ids = torch.tensor(token_ids)\n",
    "        seg_ids = self.get_seg_ids(ids)\n",
    "        \n",
    "        return ids, seg_ids\n",
    "    \n",
    "    def get_seg_ids(self, ids):\n",
    "        seg_ids = torch.zeros_like(ids)\n",
    "        seg_idx = 0\n",
    "        first_sep = True\n",
    "        for i, e in enumerate(ids):\n",
    "            seg_ids[i] = seg_idx\n",
    "            if e == self.tokenizer.sep_token_id:\n",
    "                if first_sep:\n",
    "                    first_sep = False\n",
    "                else:\n",
    "                    seg_idx = 1\n",
    "        pad_idx = torch.nonzero(ids == 0)\n",
    "        seg_ids[pad_idx] = 0\n",
    "\n",
    "        return seg_ids\n",
    "\n",
    "    def get_label(self, row):\n",
    "        #print(row[TARGET_COLUMNS].values)\n",
    "        return torch.tensor(row[TARGET_COLUMNS].values.astype(np.float32))\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        token_ids = torch.stack([x[0] for x in batch])\n",
    "        seg_ids = torch.stack([x[1] for x in batch])\n",
    "    \n",
    "        if self.labeled:\n",
    "            labels = torch.stack([x[2] for x in batch])\n",
    "            return token_ids, seg_ids, labels\n",
    "        else:\n",
    "            return token_ids, seg_ids\n",
    "\n",
    "def get_test_loader(model_type=\"bert-base-cased\", max_len=512, content=\"Question_Answer\", batch_size=4):\n",
    "    df = pd.read_csv(f'{DATA_DIR}/test.csv')\n",
    "    ds_test = QuestDataset(df, model_type, max_len=max_len, content=content, train_mode=False, labeled=False)\n",
    "    loader = torch.utils.data.DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=2, collate_fn=ds_test.collate_fn, drop_last=False)\n",
    "    loader.num = len(df)\n",
    "    \n",
    "    return loader, ds_test.tokenizer\n",
    "        \n",
    "def get_train_val_loaders(model_type=\"bert-base-cased\", max_len=512, content=\"Question_Answer\", batch_size=4, val_batch_size=4, ifold=0):\n",
    "    df = pd.read_csv(f'{DATA_DIR}/train.csv')\n",
    "    df = shuffle(df, random_state=42)\n",
    "    #split_index = int(len(df) * (1-val_percent))\n",
    "    gkf = GroupKFold(n_splits=5).split(X=df.question_body, groups=df.question_body)\n",
    "    for fold, (train_idx, valid_idx) in enumerate(gkf):\n",
    "        if fold == ifold:\n",
    "            df_train = df.iloc[train_idx]\n",
    "            df_val = df.iloc[valid_idx]\n",
    "            break\n",
    "\n",
    "    #print(df_val.head())\n",
    "    #df_train = df[:split_index]\n",
    "    #df_val = df[split_index:]\n",
    "\n",
    "    print(df_train.shape)\n",
    "    print(df_val.shape)\n",
    "\n",
    "    ds_train = QuestDataset(df_train, model_type, max_len=max_len, content=content)\n",
    "    train_loader = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=2, collate_fn=ds_train.collate_fn, drop_last=True)\n",
    "    train_loader.num = len(df_train)\n",
    "\n",
    "    ds_val = QuestDataset(df_val, model_type, max_len=max_len, content=content, train_mode=False)\n",
    "    val_loader = torch.utils.data.DataLoader(ds_val, batch_size=val_batch_size, shuffle=False, num_workers=2, collate_fn=ds_val.collate_fn, drop_last=False)\n",
    "    val_loader.num = len(df_val)\n",
    "    val_loader.df = df_val\n",
    "\n",
    "    return train_loader, val_loader, ds_train.tokenizer\n",
    "\n",
    "def test_train_loader():\n",
    "    loader, _, _ = get_train_val_loaders(\"xlnet-base-cased\", 512, \"Question\", 4, 4, 1)\n",
    "    for ids, seg_ids, labels in loader:\n",
    "        print(ids)\n",
    "        print(seg_ids.numpy())\n",
    "        print(labels)\n",
    "        break\n",
    "def test_test_loader():\n",
    "    loader, _ = get_test_loader(\"roberta-base\", 512, \"Question\", 4)\n",
    "    for ids, seg_ids in loader:\n",
    "        print(ids)\n",
    "        print(seg_ids)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    3, 17485,  1618,  ...,     0,     0,     0],\n",
      "        [    3, 49009,  3104,  ...,     0,     0,     0],\n",
      "        [    3,  6209,  8611,  ...,     0,     0,     0],\n",
      "        [    3, 44711,   300,  ...,     0,     0,     0]])\n",
      "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "test_test_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4863, 41)\n",
      "(1216, 41)\n",
      "tensor([[    0,  7396,  3409,  ...,     0,     0,     0],\n",
      "        [    0,  9134,  7322,  ...,     0,     0,     0],\n",
      "        [    0, 24921,    17,  ...,     0,     0,     0],\n",
      "        [    0, 29118,    31,  ...,     0,     0,     0]])\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "tensor([[1.0000, 0.3333, 0.0000, 1.0000, 1.0000, 1.0000, 0.6667, 0.6667, 1.0000,\n",
      "         0.0000, 0.0000, 1.0000, 0.0000, 0.0000, 0.0000, 0.6667, 0.0000, 0.0000,\n",
      "         0.3333, 0.0000, 0.6667, 0.7778, 0.3333, 0.7778, 0.7778, 0.4667, 0.0000,\n",
      "         0.0000, 0.0000, 0.6667],\n",
      "        [0.6667, 0.3333, 0.0000, 0.0000, 1.0000, 0.0000, 0.5556, 0.4444, 1.0000,\n",
      "         0.0000, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.6667,\n",
      "         0.0000, 0.0000, 0.6667, 0.6667, 0.5000, 1.0000, 0.6667, 0.6000, 1.0000,\n",
      "         0.0000, 1.0000, 1.0000],\n",
      "        [1.0000, 0.8889, 0.0000, 1.0000, 0.6667, 1.0000, 0.4444, 0.4444, 0.0000,\n",
      "         0.0000, 0.3333, 1.0000, 0.0000, 0.0000, 0.0000, 0.3333, 1.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.7778, 1.0000, 0.6667, 1.0000, 1.0000, 0.8667, 0.6667,\n",
      "         0.0000, 0.0000, 1.0000],\n",
      "        [1.0000, 0.7778, 0.6667, 1.0000, 0.0000, 0.3333, 0.5556, 0.6667, 0.0000,\n",
      "         0.0000, 1.0000, 0.3333, 0.0000, 0.0000, 0.0000, 0.3333, 0.0000, 0.0000,\n",
      "         0.3333, 0.0000, 0.8889, 1.0000, 0.6667, 1.0000, 1.0000, 0.9333, 0.0000,\n",
      "         0.0000, 0.3333, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "test_train_loader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class QuestModel(nn.Module):\n",
    "    def __init__(self, model_type=\"xlnet-base-cased\", tokenizer=None, n_classes=30, hidden_layers=[-1, -3, -5, -7, -9]):\n",
    "        super(QuestModel, self).__init__()\n",
    "        self.model_name = 'QuestModel'\n",
    "        self.model_type = model_type\n",
    "        self.hidden_layers = hidden_layers\n",
    "        if model_type == \"bert-base-uncased\":\n",
    "            bert_model_config = '../input/pretrained-bert-models-for-pytorch/bert-base-uncased/bert_config.json'\n",
    "            bert_config = BertConfig.from_json_file(bert_model_config)\n",
    "            bert_config.output_hidden_states = True\n",
    "            # haven't update question_answer model\n",
    "            if n_classes == 30:\n",
    "                bert_config.hidden_dropout_prob = 0.1\n",
    "            else:\n",
    "                bert_config.hidden_dropout_prob = 0\n",
    "            model_path = os.path.join('../input/pretrained-bert-models-for-pytorch/' + model_type)\n",
    "            self.bert_model = BertModel.from_pretrained(model_path, config=bert_config)   \n",
    "        elif model_type == \"bert-base-cased\":\n",
    "            bert_model_config = '../input/pretrained-bert-models-for-pytorch/bert-base-cased/bert_config.json'\n",
    "            bert_config = BertConfig.from_json_file(bert_model_config)\n",
    "            bert_config.output_hidden_states = True\n",
    "            model_path = os.path.join('../input/pretrained-bert-models-for-pytorch/' + model_type)\n",
    "            self.bert_model = BertModel.from_pretrained(model_path, config=bert_config)   \n",
    "        elif model_type == \"xlnet-base-cased\":\n",
    "            xlnet_model_config = '../input/xlnet-pretrained-models-pytorch/xlnet-base-cased-config.json'\n",
    "            xlnet_config = XLNetConfig.from_json_file(xlnet_model_config)\n",
    "            xlnet_config.output_hidden_states = True\n",
    "            xlnet_config.hidden_dropout_prob = 0\n",
    "            model_path = os.path.join('../input/xlnet-pretrained-models-pytorch/' + model_type + '-pytorch_model.bin')\n",
    "            self.xlnet_model = XLNetModel.from_pretrained(model_path, config=xlnet_config)   \n",
    "        elif model_type == \"xlnet-large-cased\":\n",
    "            xlnet_model_config = '../input/xlnet-pretrained-models-pytorch/xlnet-large-cased-config.json'\n",
    "            xlnet_config = XLNetConfig.from_json_file(xlnet_model_config)\n",
    "            xlnet_config.output_hidden_states = True\n",
    "            xlnet_config.hidden_dropout_prob = 0\n",
    "            model_path = os.path.join('../input/xlnet-pretrained-models-pytorch/' + model_type + '-pytorch_model.bin')\n",
    "            self.xlnet_model = XLNetModel.from_pretrained(model_path, config=xlnet_config)  \n",
    "        elif model_type == \"roberta-base\":\n",
    "            roberta_model_config = '../input/roberta-transformers-pytorch/roberta-base/config.json'\n",
    "            roberta_config = RobertaConfig.from_json_file(roberta_model_config)\n",
    "            roberta_config.output_hidden_states = True\n",
    "            roberta_config.hidden_dropout_prob = 0\n",
    "            model_path = os.path.join('../input/roberta-transformers-pytorch/roberta-base/pytorch_model.bin')\n",
    "            self.roberta_model = RobertaModel.from_pretrained(model_path, config=roberta_config)  \n",
    "            self.roberta_model.resize_token_embeddings(len(tokenizer)) \n",
    "        \n",
    "        if model_type == \"bert-base-uncased\":\n",
    "            self.hidden_size = 768\n",
    "        elif model_type == \"bert-large-uncased\":\n",
    "            self.hidden_size = 1024\n",
    "        elif model_type == \"bert-base-cased\":\n",
    "            self.hidden_size = 768\n",
    "        elif model_type == \"xlnet-base-cased\":\n",
    "            self.hidden_size = 768\n",
    "        elif model_type == \"xlnet-large-cased\":\n",
    "            self.hidden_size = 1024\n",
    "        elif model_type == \"roberta-base\":\n",
    "            self.hidden_size = 768\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        self.fc_1 = nn.Linear(self.hidden_size * len(hidden_layers), self.hidden_size)\n",
    "        self.fc = nn.Linear(self.hidden_size, n_classes)\n",
    "            \n",
    "        self.selu = nn.SELU()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.dropouts = nn.ModuleList([\n",
    "            nn.Dropout(0.5) for _ in range(5)\n",
    "        ])\n",
    "\n",
    "    def forward(self, ids, seg_ids):\n",
    "        attention_mask = (ids > 0)\n",
    "        \n",
    "        if ((self.model_type == \"bert-base-uncased\") \\\n",
    "            or (self.model_type == \"bert-base-cased\") \\\n",
    "            or (self.model_type == \"bert-large-uncased\") \\\n",
    "            or (self.model_type == \"bert-large-cased\")):\n",
    "        \n",
    "            outputs = self.bert_model(input_ids=ids, token_type_ids=seg_ids, attention_mask=attention_mask)\n",
    "            hidden_states = outputs[2]\n",
    "            \n",
    "            # pooled_out = outputs[1] #  N * 768\n",
    "        \n",
    "            # sequence_out = torch.unsqueeze(outputs[0][:, 0], dim=-1) # N * 512 * 768 * 1, hidden_states[-1]\n",
    "            # fuse_hidden = sequence_out\n",
    "            \n",
    "            # 13 (embedding + 12 transformers) for base\n",
    "            # 26 (embedding + 25 transformers) for large\n",
    "            \n",
    "            # concat hidden\n",
    "            for i in range(len(self.hidden_layers)):\n",
    "                if i == 0:\n",
    "                    hidden_layer = self.hidden_layers[i]\n",
    "                    # hidden_state = torch.mean(hidden_states[hidden_layer], dim=1)\n",
    "                    hidden_state = hidden_states[hidden_layer][:, 0]\n",
    "                    fuse_hidden = torch.unsqueeze(hidden_state, dim=-1) # N * 768 * 1\n",
    "                else:\n",
    "                    hidden_layer = self.hidden_layers[i]\n",
    "                    # hidden_state = torch.mean(hidden_states[hidden_layer], dim=1)\n",
    "                    hidden_state = hidden_states[hidden_layer][:, 0]\n",
    "                    h = torch.unsqueeze(hidden_state, dim=-1) # N * 768 * 1\n",
    "                    fuse_hidden = torch.cat([fuse_hidden, h], dim=-1)\n",
    "                    \n",
    "            fuse_hidden = fuse_hidden.reshape(fuse_hidden.shape[0], -1)\n",
    "            h = self.relu(self.fc_1(fuse_hidden))\n",
    "        \n",
    "        elif ((self.model_type == \"xlnet-base-cased\") \\\n",
    "            or (self.model_type == \"xlnet-large-cased\")):\n",
    "\n",
    "            attention_mask = attention_mask.float()\n",
    "            outputs = self.xlnet_model(input_ids=ids, token_type_ids=seg_ids, attention_mask=attention_mask)\n",
    "            hidden_states = outputs[1]\n",
    "            \n",
    "            # last_hidden_out = outputs[0]\n",
    "            # mem = outputs[1], when config.mem_len > 0\n",
    "            \n",
    "            # concat hidden, summary_type=\"first\", first_dropout = 0\n",
    "            for i in range(len(self.hidden_layers)):\n",
    "                if i == 0:\n",
    "                    hidden_layer = self.hidden_layers[i]\n",
    "                    # hidden_state = hidden_states[hidden_layer].mean(dim=1)\n",
    "                    hidden_state = hidden_states[hidden_layer][:, 0]\n",
    "                    fuse_hidden = torch.unsqueeze(hidden_state, dim=-1) # N * 768 * 1\n",
    "                else:\n",
    "                    hidden_layer = self.hidden_layers[i]\n",
    "                    # hidden_state = hidden_states[hidden_layer].mean(dim=1)\n",
    "                    hidden_state = hidden_states[hidden_layer][:, 0]\n",
    "                    h = torch.unsqueeze(hidden_state, dim=-1) # N * 768 * 1\n",
    "                    fuse_hidden = torch.cat([fuse_hidden, h], dim=-1)\n",
    "        \n",
    "            fuse_hidden = fuse_hidden.reshape(fuse_hidden.shape[0], -1)\n",
    "            h = self.relu(self.fc_1(fuse_hidden))\n",
    "        elif (self.model_type == \"roberta-base\"):\n",
    "\n",
    "            attention_mask = attention_mask.float()\n",
    "            outputs = self.roberta_model(input_ids=ids, token_type_ids=seg_ids, attention_mask=attention_mask)\n",
    "            # outputs = self.roberta_model(input_ids=ids, attention_mask=attention_mask)\n",
    "            hidden_states = outputs[2]\n",
    "            \n",
    "            for i in range(len(self.hidden_layers)):\n",
    "                if i == 0:\n",
    "                    hidden_layer = self.hidden_layers[i]\n",
    "                    # hidden_state = hidden_states[hidden_layer].mean(dim=1)\n",
    "                    hidden_state = hidden_states[hidden_layer][:, 0]\n",
    "                    fuse_hidden = torch.unsqueeze(hidden_state, dim=-1) # N * 768 * 1\n",
    "                else:\n",
    "                    hidden_layer = self.hidden_layers[i]\n",
    "                    # hidden_state = hidden_states[hidden_layer].mean(dim=1)\n",
    "                    hidden_state = hidden_states[hidden_layer][:, 0]\n",
    "                    h = torch.unsqueeze(hidden_state, dim=-1) # N * 768 * 1\n",
    "                    fuse_hidden = torch.cat([fuse_hidden, h], dim=-1)\n",
    "        \n",
    "            fuse_hidden = fuse_hidden.reshape(fuse_hidden.shape[0], -1)\n",
    "            h = self.relu(self.fc_1(fuse_hidden))\n",
    "            \n",
    "            \n",
    "            \n",
    "        for j, dropout in enumerate(self.dropouts):\n",
    "            \n",
    "            if j == 0:\n",
    "                logit = self.fc(dropout(h))\n",
    "            else:\n",
    "                logit += self.fc(dropout(h))\n",
    "                \n",
    "        return logit / len(self.dropouts)\n",
    "    \n",
    "def test_model(model_type=\"bert-base-cased\", hidden_layers=[-1, -3, -5, -7, -9]):\n",
    "    x = torch.tensor([[1,2,3,4,5, 0, 0], [1,2,3,4,5, 0, 0]])\n",
    "    seg_ids = torch.tensor([[0,0,0,0,0, 0, 0], [0,0,0,0,0, 0, 0]])\n",
    "    model = QuestModel(model_type=model_type, hidden_layers=hidden_layers)\n",
    "\n",
    "    y = model(x, seg_ids)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2717, -0.1464, -0.2704, -0.1031, -0.2045, -0.2167,  0.3013,  0.0519,\n",
      "          0.0022, -0.0681, -0.1713,  0.1744,  0.1060, -0.1527,  0.1318,  0.0085,\n",
      "         -0.2474, -0.0484, -0.2268, -0.3609, -0.0945, -0.0292, -0.0441, -0.2440,\n",
      "         -0.0222,  0.0332,  0.1378, -0.1127,  0.0975,  0.0498],\n",
      "        [ 0.2297, -0.1792, -0.2585, -0.1225, -0.0326, -0.1100,  0.1723,  0.2708,\n",
      "         -0.0359, -0.1441, -0.2970,  0.2156,  0.0917, -0.0833,  0.0772,  0.1163,\n",
      "         -0.1736, -0.0761, -0.2305, -0.1720, -0.1235,  0.0376, -0.0374, -0.1798,\n",
      "         -0.0731,  0.1155,  0.0509, -0.0292,  0.0692, -0.0633]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "test_model(model_type=\"bert-base-cased\", hidden_layers=[-3, -4, -5, -6, -7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bert_base_uncased_models():\n",
    "    models = []\n",
    "    for i in range(10):\n",
    "        model = QuestModel(model_type=\"bert-base-uncased\", hidden_layers=[-1, -3, -5, -7, -9])\n",
    "        model.load_state_dict(torch.load(f'../input/qabertuncasedaugdiffv2swa/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_bert_base_cased_models():\n",
    "    models = []\n",
    "    for i in range(10):\n",
    "        model = QuestModel(model_type=\"bert-base-cased\", hidden_layers=[-1, -3, -5, -7, -9])\n",
    "        model.load_state_dict(torch.load(f'../input/qabertbasecasedaugdiffv2swa/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_xlnet_base_cased_models():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"xlnet-base-cased\", hidden_layers=[-3, -4, -5, -6, -7])\n",
    "        model.load_state_dict(torch.load(f'../input/qaxlnetbasecasedaugquestionanswerswa/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_xlnet_base_cased_question_models():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"xlnet-base-cased\", n_classes=21, hidden_layers=[-3, -4, -5, -6, -7])\n",
    "        model.load_state_dict(torch.load(f'../input/qaxlnetbasecasedaugdiffswaquestion/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_xlnet_base_cased_answer_models():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"xlnet-base-cased\", n_classes=9, hidden_layers=[-3, -4, -5, -6, -7])\n",
    "        model.load_state_dict(torch.load(f'../input/qaxlnetbasecasedaugdiffswaanswer/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "\n",
    "def create_bert_base_uncased_question_models():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"bert-base-uncased\", n_classes=21, hidden_layers=[-3, -4, -5, -6, -7])\n",
    "        model.load_state_dict(torch.load(f'../input/qabertbaseuncasedaugdiffswaquestion/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_bert_base_uncased_answer_models():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"bert-base-uncased\", n_classes=9, hidden_layers=[-3, -4, -5, -6, -7])\n",
    "        model.load_state_dict(torch.load(f'../input/qabertbaseuncasedaugdiffswaanswer/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_bert_base_cased_question_models():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"bert-base-cased\", n_classes=21, hidden_layers=[-2, -4, -6, -8, -10])\n",
    "        model.load_state_dict(torch.load(f'../input/qabertbasecasedaugdiffswaquestion/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_bert_base_cased_answer_models():\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"bert-base-cased\", n_classes=9, hidden_layers=[-2, -4, -6, -8, -10])\n",
    "        model.load_state_dict(torch.load(f'../input/qabertbasecasedaugdiffswaanswer/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_roberta_base_models(tokenizer):\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"roberta-base\", tokenizer=tokenizer, n_classes=30, hidden_layers=[-3, -4, -5, -6, -7])\n",
    "        model.load_state_dict(torch.load(f'../input/qarobertabaseaugdiffswa/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_roberta_base_question_models(tokenizer):\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"roberta-base\", tokenizer=tokenizer, n_classes=21, hidden_layers=[-3, -4, -5, -6, -7])\n",
    "        model.load_state_dict(torch.load(f'../input/qarobertabasecasedaugdiffswaquestion/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models\n",
    "\n",
    "def create_roberta_base_answer_models(tokenizer):\n",
    "    models = []\n",
    "    for i in range(5):\n",
    "        model = QuestModel(model_type=\"roberta-base\", tokenizer=tokenizer, n_classes=9, hidden_layers=[-3, -4, -5, -6, -7])\n",
    "        model.load_state_dict(torch.load(f'../input/qarobertabasecasedaugdiffswaanswer/fold_{i}_checkpoint_swa.pth'))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "def predict(models, test_loader):\n",
    "    all_scores = []\n",
    "    with torch.no_grad():\n",
    "        for ids, seg_ids in tqdm(test_loader, total=test_loader.num // test_loader.batch_size):\n",
    "            ids, seg_ids = ids.cuda(), seg_ids.cuda()\n",
    "            scores = []\n",
    "            for model in models:\n",
    "                model = model.cuda()\n",
    "                outputs = torch.sigmoid(model(ids, seg_ids)).cpu()\n",
    "                scores.append(outputs)\n",
    "            all_scores.append(torch.mean(torch.stack(scores), 0))\n",
    "\n",
    "    all_scores = torch.cat(all_scores, 0).numpy()\n",
    "    \n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, tokenizer = get_test_loader(model_type=\"roberta-base\", content=\"Question_Answer\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:45,  3.02s/it]\n"
     ]
    }
   ],
   "source": [
    "roberta_base_models = create_roberta_base_models(tokenizer)\n",
    "roberta_base_preds = predict(roberta_base_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "824"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del roberta_base_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with xlnet-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"xlnet-base-cased\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [01:59,  8.00s/it]\n"
     ]
    }
   ],
   "source": [
    "xlnet_base_cased_models = create_xlnet_base_cased_models()\n",
    "xlnet_base_cased_preds = predict(xlnet_base_cased_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del xlnet_base_cased_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with xlnet-base-cased question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"xlnet-base-cased\", content=\"Question\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [02:00,  8.02s/it]\n"
     ]
    }
   ],
   "source": [
    "xlnet_base_cased_question_models = create_xlnet_base_cased_question_models()\n",
    "xlnet_base_cased_question_preds = predict(xlnet_base_cased_question_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del xlnet_base_cased_question_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"xlnet-base-cased\", content=\"Answer\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [01:59,  7.99s/it]\n"
     ]
    }
   ],
   "source": [
    "xlnet_base_cased_answer_models = create_xlnet_base_cased_answer_models()\n",
    "xlnet_base_cased_answer_preds = predict(xlnet_base_cased_answer_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1290"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del xlnet_base_cased_answer_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_base_cased_question_answer_preds = np.concatenate([xlnet_base_cased_question_preds, xlnet_base_cased_answer_preds], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with roberta-base question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, tokenizer = get_test_loader(model_type=\"roberta-base\", content=\"Question\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:43,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "roberta_base_question_models = create_roberta_base_question_models(tokenizer)\n",
    "roberta_base_question_preds = predict(roberta_base_question_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del roberta_base_question_models, test_loader, tokenizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, tokenizer = get_test_loader(model_type=\"roberta-base\", content=\"Answer\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:43,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "roberta_base_answer_models = create_roberta_base_answer_models(tokenizer)\n",
    "roberta_base_answer_preds = predict(roberta_base_answer_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1236"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del roberta_base_answer_models, test_loader, tokenizer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_base_question_answer_preds = np.concatenate([roberta_base_question_preds, roberta_base_answer_preds], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with bert-base-cased question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"bert-base-cased\", content=\"Question\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:43,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "bert_base_cased_question_models = create_bert_base_cased_question_models()\n",
    "bert_base_cased_question_preds = predict(bert_base_cased_question_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del bert_base_cased_question_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"bert-base-cased\", content=\"Answer\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:43,  2.91s/it]\n"
     ]
    }
   ],
   "source": [
    "bert_base_cased_answer_models = create_bert_base_cased_answer_models()\n",
    "bert_base_cased_answer_preds = predict(bert_base_cased_answer_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del bert_base_cased_answer_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_cased_question_answer_preds = np.concatenate([bert_base_cased_question_preds, bert_base_cased_answer_preds], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with bert-base-uncased question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"bert-base-uncased\", content=\"Question\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:43,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "bert_base_uncased_question_models = create_bert_base_uncased_question_models()\n",
    "bert_base_uncased_question_preds = predict(bert_base_uncased_question_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del bert_base_uncased_question_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"bert-base-uncased\", content=\"Answer\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:43,  2.92s/it]\n"
     ]
    }
   ],
   "source": [
    "bert_base_uncased_answer_models = create_bert_base_uncased_answer_models()\n",
    "bert_base_uncased_answer_preds = predict(bert_base_uncased_answer_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "663"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del bert_base_uncased_answer_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_base_uncased_question_answer_preds = np.concatenate([bert_base_uncased_question_preds, bert_base_uncased_answer_preds], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with bert-base-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"bert-base-cased\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [01:26,  5.76s/it]\n"
     ]
    }
   ],
   "source": [
    "bert_base_cased_models = create_bert_base_cased_models()\n",
    "bert_base_cased_preds = predict(bert_base_cased_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del bert_base_cased_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict with bert-base-uncased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader, _ = get_test_loader(model_type=\"bert-base-uncased\", batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [01:26,  5.75s/it]\n"
     ]
    }
   ],
   "source": [
    "bert_base_uncased_models = create_bert_base_uncased_models()\n",
    "bert_base_uncased_preds = predict(bert_base_uncased_models, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del bert_base_uncased_models, test_loader\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = bert_base_uncased_question_answer_preds\n",
    "preds = ((bert_base_uncased_preds + bert_base_uncased_question_answer_preds)/2.0 \\\n",
    "         + (xlnet_base_cased_preds + xlnet_base_cased_question_answer_preds)/2.0 \\\n",
    "         + (bert_base_cased_preds + bert_base_cased_question_answer_preds)/2.0 \\\n",
    "         + (roberta_base_preds + roberta_base_question_answer_preds)/2.0)/4.0\n",
    "# preds = bert_base_uncased_preds\n",
    "# preds = roberta_base_question_answer_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[TARGET_COLUMNS] = bert_base_uncased_question_answer_preds\n",
    "sub.to_csv('submission_bert_base_uncased.csv', index=False)\n",
    "sub[TARGET_COLUMNS] =roberta_base_preds\n",
    "sub.to_csv('submission_roberta_base.csv', index=False)\n",
    "# sub[TARGET_COLUMNS] = xlnet_base_cased_preds\n",
    "# sub.to_csv('submission_xlnet_base_cased.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[TARGET_COLUMNS] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.946479</td>\n",
       "      <td>0.707502</td>\n",
       "      <td>0.205354</td>\n",
       "      <td>0.533394</td>\n",
       "      <td>0.655454</td>\n",
       "      <td>0.614164</td>\n",
       "      <td>0.689819</td>\n",
       "      <td>0.662526</td>\n",
       "      <td>0.559902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928341</td>\n",
       "      <td>0.907877</td>\n",
       "      <td>0.596855</td>\n",
       "      <td>0.959356</td>\n",
       "      <td>0.959874</td>\n",
       "      <td>0.827286</td>\n",
       "      <td>0.034999</td>\n",
       "      <td>0.033786</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.882484</td>\n",
       "      <td>0.526338</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.748191</td>\n",
       "      <td>0.789841</td>\n",
       "      <td>0.923876</td>\n",
       "      <td>0.560750</td>\n",
       "      <td>0.471400</td>\n",
       "      <td>0.093181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716655</td>\n",
       "      <td>0.954225</td>\n",
       "      <td>0.660048</td>\n",
       "      <td>0.974810</td>\n",
       "      <td>0.984117</td>\n",
       "      <td>0.886513</td>\n",
       "      <td>0.916196</td>\n",
       "      <td>0.139103</td>\n",
       "      <td>0.097643</td>\n",
       "      <td>0.900407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.919672</td>\n",
       "      <td>0.696181</td>\n",
       "      <td>0.018344</td>\n",
       "      <td>0.776811</td>\n",
       "      <td>0.901784</td>\n",
       "      <td>0.932817</td>\n",
       "      <td>0.615691</td>\n",
       "      <td>0.517755</td>\n",
       "      <td>0.168939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883403</td>\n",
       "      <td>0.934817</td>\n",
       "      <td>0.614443</td>\n",
       "      <td>0.971507</td>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.853534</td>\n",
       "      <td>0.093786</td>\n",
       "      <td>0.055929</td>\n",
       "      <td>0.857272</td>\n",
       "      <td>0.915597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.880351</td>\n",
       "      <td>0.463604</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.714098</td>\n",
       "      <td>0.761837</td>\n",
       "      <td>0.910165</td>\n",
       "      <td>0.555330</td>\n",
       "      <td>0.434210</td>\n",
       "      <td>0.107091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708653</td>\n",
       "      <td>0.951855</td>\n",
       "      <td>0.690843</td>\n",
       "      <td>0.972785</td>\n",
       "      <td>0.983968</td>\n",
       "      <td>0.900273</td>\n",
       "      <td>0.795460</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.729357</td>\n",
       "      <td>0.900414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.918522</td>\n",
       "      <td>0.506116</td>\n",
       "      <td>0.028073</td>\n",
       "      <td>0.792776</td>\n",
       "      <td>0.792307</td>\n",
       "      <td>0.869300</td>\n",
       "      <td>0.643961</td>\n",
       "      <td>0.607475</td>\n",
       "      <td>0.167064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745867</td>\n",
       "      <td>0.901345</td>\n",
       "      <td>0.645428</td>\n",
       "      <td>0.958213</td>\n",
       "      <td>0.958456</td>\n",
       "      <td>0.818084</td>\n",
       "      <td>0.346361</td>\n",
       "      <td>0.141630</td>\n",
       "      <td>0.590266</td>\n",
       "      <td>0.905628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.946479                0.707502   \n",
       "1     46                             0.882484                0.526338   \n",
       "2     70                             0.919672                0.696181   \n",
       "3    132                             0.880351                0.463604   \n",
       "4    200                             0.918522                0.506116   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.205354                      0.533394   \n",
       "1                 0.003054                      0.748191   \n",
       "2                 0.018344                      0.776811   \n",
       "3                 0.003637                      0.714098   \n",
       "4                 0.028073                      0.792776   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.655454                               0.614164   \n",
       "1               0.789841                               0.923876   \n",
       "2               0.901784                               0.932817   \n",
       "3               0.761837                               0.910165   \n",
       "4               0.792307                               0.869300   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.689819                       0.662526   \n",
       "1                         0.560750                       0.471400   \n",
       "2                         0.615691                       0.517755   \n",
       "3                         0.555330                       0.434210   \n",
       "4                         0.643961                       0.607475   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.559902  ...               0.928341        0.907877   \n",
       "1               0.093181  ...               0.716655        0.954225   \n",
       "2               0.168939  ...               0.883403        0.934817   \n",
       "3               0.107091  ...               0.708653        0.951855   \n",
       "4               0.167064  ...               0.745867        0.901345   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.596855          0.959356          0.959874   \n",
       "1                     0.660048          0.974810          0.984117   \n",
       "2                     0.614443          0.971507          0.972197   \n",
       "3                     0.690843          0.972785          0.983968   \n",
       "4                     0.645428          0.958213          0.958456   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.827286                  0.034999               0.033786   \n",
       "1             0.886513                  0.916196               0.139103   \n",
       "2             0.853534                  0.093786               0.055929   \n",
       "3             0.900273                  0.795460               0.157647   \n",
       "4             0.818084                  0.346361               0.141630   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.805360             0.921400  \n",
       "1                        0.097643             0.900407  \n",
       "2                        0.857272             0.915597  \n",
       "3                        0.729357             0.900414  \n",
       "4                        0.590266             0.905628  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.set_index('qa_id').join(sub.set_index('qa_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>host</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qa_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Will leaving corpses lying around upset my pri...</td>\n",
       "      <td>I see questions/information online about how t...</td>\n",
       "      <td>Dylan</td>\n",
       "      <td>https://gaming.stackexchange.com/users/64471</td>\n",
       "      <td>There is no consequence for leaving corpses an...</td>\n",
       "      <td>Nelson868</td>\n",
       "      <td>https://gaming.stackexchange.com/users/97324</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/1979...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928341</td>\n",
       "      <td>0.907877</td>\n",
       "      <td>0.596855</td>\n",
       "      <td>0.959356</td>\n",
       "      <td>0.959874</td>\n",
       "      <td>0.827286</td>\n",
       "      <td>0.034999</td>\n",
       "      <td>0.033786</td>\n",
       "      <td>0.805360</td>\n",
       "      <td>0.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Url link to feature image in the portfolio</td>\n",
       "      <td>I am new to Wordpress. i have issue with Featu...</td>\n",
       "      <td>Anu</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/72927</td>\n",
       "      <td>I think it is possible with custom fields.\\n\\n...</td>\n",
       "      <td>Irina</td>\n",
       "      <td>https://wordpress.stackexchange.com/users/27233</td>\n",
       "      <td>http://wordpress.stackexchange.com/questions/1...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>wordpress.stackexchange.com</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716655</td>\n",
       "      <td>0.954225</td>\n",
       "      <td>0.660048</td>\n",
       "      <td>0.974810</td>\n",
       "      <td>0.984117</td>\n",
       "      <td>0.886513</td>\n",
       "      <td>0.916196</td>\n",
       "      <td>0.139103</td>\n",
       "      <td>0.097643</td>\n",
       "      <td>0.900407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Is accuracy, recoil or bullet spread affected ...</td>\n",
       "      <td>To experiment I started a bot game, toggled in...</td>\n",
       "      <td>Konsta</td>\n",
       "      <td>https://gaming.stackexchange.com/users/37545</td>\n",
       "      <td>You do not have armour in the screenshots. Thi...</td>\n",
       "      <td>Damon Smithies</td>\n",
       "      <td>https://gaming.stackexchange.com/users/70641</td>\n",
       "      <td>http://gaming.stackexchange.com/questions/2154...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>gaming.stackexchange.com</td>\n",
       "      <td>...</td>\n",
       "      <td>0.883403</td>\n",
       "      <td>0.934817</td>\n",
       "      <td>0.614443</td>\n",
       "      <td>0.971507</td>\n",
       "      <td>0.972197</td>\n",
       "      <td>0.853534</td>\n",
       "      <td>0.093786</td>\n",
       "      <td>0.055929</td>\n",
       "      <td>0.857272</td>\n",
       "      <td>0.915597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Suddenly got an I/O error from my external HDD</td>\n",
       "      <td>I have used my Raspberry Pi as a torrent-serve...</td>\n",
       "      <td>robbannn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/17341</td>\n",
       "      <td>Your Western Digital hard drive is disappearin...</td>\n",
       "      <td>HeatfanJohn</td>\n",
       "      <td>https://raspberrypi.stackexchange.com/users/1311</td>\n",
       "      <td>http://raspberrypi.stackexchange.com/questions...</td>\n",
       "      <td>TECHNOLOGY</td>\n",
       "      <td>raspberrypi.stackexchange.com</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708653</td>\n",
       "      <td>0.951855</td>\n",
       "      <td>0.690843</td>\n",
       "      <td>0.972785</td>\n",
       "      <td>0.983968</td>\n",
       "      <td>0.900273</td>\n",
       "      <td>0.795460</td>\n",
       "      <td>0.157647</td>\n",
       "      <td>0.729357</td>\n",
       "      <td>0.900414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Passenger Name - Flight Booking Passenger only...</td>\n",
       "      <td>I have bought Delhi-London return flights for ...</td>\n",
       "      <td>Amit</td>\n",
       "      <td>https://travel.stackexchange.com/users/29089</td>\n",
       "      <td>I called two persons who work for Saudia (tick...</td>\n",
       "      <td>Nean Der Thal</td>\n",
       "      <td>https://travel.stackexchange.com/users/10051</td>\n",
       "      <td>http://travel.stackexchange.com/questions/4704...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>travel.stackexchange.com</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745867</td>\n",
       "      <td>0.901345</td>\n",
       "      <td>0.645428</td>\n",
       "      <td>0.958213</td>\n",
       "      <td>0.958456</td>\n",
       "      <td>0.818084</td>\n",
       "      <td>0.346361</td>\n",
       "      <td>0.141630</td>\n",
       "      <td>0.590266</td>\n",
       "      <td>0.905628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          question_title  \\\n",
       "qa_id                                                      \n",
       "39     Will leaving corpses lying around upset my pri...   \n",
       "46            Url link to feature image in the portfolio   \n",
       "70     Is accuracy, recoil or bullet spread affected ...   \n",
       "132       Suddenly got an I/O error from my external HDD   \n",
       "200    Passenger Name - Flight Booking Passenger only...   \n",
       "\n",
       "                                           question_body question_user_name  \\\n",
       "qa_id                                                                         \n",
       "39     I see questions/information online about how t...              Dylan   \n",
       "46     I am new to Wordpress. i have issue with Featu...                Anu   \n",
       "70     To experiment I started a bot game, toggled in...             Konsta   \n",
       "132    I have used my Raspberry Pi as a torrent-serve...           robbannn   \n",
       "200    I have bought Delhi-London return flights for ...               Amit   \n",
       "\n",
       "                                      question_user_page  \\\n",
       "qa_id                                                      \n",
       "39          https://gaming.stackexchange.com/users/64471   \n",
       "46       https://wordpress.stackexchange.com/users/72927   \n",
       "70          https://gaming.stackexchange.com/users/37545   \n",
       "132    https://raspberrypi.stackexchange.com/users/17341   \n",
       "200         https://travel.stackexchange.com/users/29089   \n",
       "\n",
       "                                                  answer answer_user_name  \\\n",
       "qa_id                                                                       \n",
       "39     There is no consequence for leaving corpses an...        Nelson868   \n",
       "46     I think it is possible with custom fields.\\n\\n...            Irina   \n",
       "70     You do not have armour in the screenshots. Thi...   Damon Smithies   \n",
       "132    Your Western Digital hard drive is disappearin...      HeatfanJohn   \n",
       "200    I called two persons who work for Saudia (tick...    Nean Der Thal   \n",
       "\n",
       "                                       answer_user_page  \\\n",
       "qa_id                                                     \n",
       "39         https://gaming.stackexchange.com/users/97324   \n",
       "46      https://wordpress.stackexchange.com/users/27233   \n",
       "70         https://gaming.stackexchange.com/users/70641   \n",
       "132    https://raspberrypi.stackexchange.com/users/1311   \n",
       "200        https://travel.stackexchange.com/users/10051   \n",
       "\n",
       "                                                     url    category  \\\n",
       "qa_id                                                                  \n",
       "39     http://gaming.stackexchange.com/questions/1979...     CULTURE   \n",
       "46     http://wordpress.stackexchange.com/questions/1...  TECHNOLOGY   \n",
       "70     http://gaming.stackexchange.com/questions/2154...     CULTURE   \n",
       "132    http://raspberrypi.stackexchange.com/questions...  TECHNOLOGY   \n",
       "200    http://travel.stackexchange.com/questions/4704...     CULTURE   \n",
       "\n",
       "                                host  ...  question_well_written  \\\n",
       "qa_id                                 ...                          \n",
       "39          gaming.stackexchange.com  ...               0.928341   \n",
       "46       wordpress.stackexchange.com  ...               0.716655   \n",
       "70          gaming.stackexchange.com  ...               0.883403   \n",
       "132    raspberrypi.stackexchange.com  ...               0.708653   \n",
       "200         travel.stackexchange.com  ...               0.745867   \n",
       "\n",
       "       answer_helpful  answer_level_of_information  answer_plausible  \\\n",
       "qa_id                                                                  \n",
       "39           0.907877                     0.596855          0.959356   \n",
       "46           0.954225                     0.660048          0.974810   \n",
       "70           0.934817                     0.614443          0.971507   \n",
       "132          0.951855                     0.690843          0.972785   \n",
       "200          0.901345                     0.645428          0.958213   \n",
       "\n",
       "       answer_relevance  answer_satisfaction  answer_type_instructions  \\\n",
       "qa_id                                                                    \n",
       "39             0.959874             0.827286                  0.034999   \n",
       "46             0.984117             0.886513                  0.916196   \n",
       "70             0.972197             0.853534                  0.093786   \n",
       "132            0.983968             0.900273                  0.795460   \n",
       "200            0.958456             0.818084                  0.346361   \n",
       "\n",
       "       answer_type_procedure  answer_type_reason_explanation  \\\n",
       "qa_id                                                          \n",
       "39                  0.033786                        0.805360   \n",
       "46                  0.139103                        0.097643   \n",
       "70                  0.055929                        0.857272   \n",
       "132                 0.157647                        0.729357   \n",
       "200                 0.141630                        0.590266   \n",
       "\n",
       "       answer_well_written  \n",
       "qa_id                       \n",
       "39                0.921400  \n",
       "46                0.900407  \n",
       "70                0.915597  \n",
       "132               0.900414  \n",
       "200               0.905628  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "    \n",
    "def postprocessing(oof_df):\n",
    "   \n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    # type 1 column [0, 0.333333, 0.5, 0.666667, 1]\n",
    "    # type 2 column [0, 0.333333, 0.666667]\n",
    "    # type 3 column [0.333333, 0.444444, 0.5, 0.555556, 0.666667, 0.777778, 0.8333333, 0.888889, 1]\n",
    "    # type 4 column [0.200000, 0.266667, 0.300000, 0.333333, 0.400000, \\\n",
    "    # 0.466667, 0.5, 0.533333, 0.600000, 0.666667, 0.700000, \\\n",
    "    # 0.733333, 0.800000, 0.866667, 0.900000, 0.933333, 1]\n",
    "    \n",
    "    # comment some columns based on oof result\n",
    "    \n",
    "    ################################################# handle type 1 columns\n",
    "    type_one_column_list = [\n",
    "       'question_conversational', \\\n",
    "       'question_has_commonly_accepted_answer', \\\n",
    "       'question_not_really_a_question', \\\n",
    "       'question_type_choice', \\\n",
    "       'question_type_compare', \\\n",
    "       'question_type_consequence', \\\n",
    "       'question_type_definition', \\\n",
    "       'question_type_entity', \\\n",
    "       'question_type_instructions', \n",
    "    ]\n",
    "    \n",
    "    oof_df[type_one_column_list] = scaler.fit_transform(oof_df[type_one_column_list])\n",
    "    \n",
    "    tmp = oof_df.copy(deep=True)\n",
    "    \n",
    "    for column in type_one_column_list:\n",
    "        \n",
    "        oof_df.loc[tmp[column] <= 0.16667, column] = 0\n",
    "        oof_df.loc[(tmp[column] > 0.16667) & (tmp[column] <= 0.41667), column] = 0.333333\n",
    "        oof_df.loc[(tmp[column] > 0.41667) & (tmp[column] <= 0.58333), column] = 0.500000\n",
    "        oof_df.loc[(tmp[column] > 0.58333) & (tmp[column] <= 0.73333), column] = 0.666667\n",
    "        oof_df.loc[(tmp[column] > 0.73333), column] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################################# handle type 2 columns      \n",
    "#     type_two_column_list = [\n",
    "#         'question_type_spelling'\n",
    "#     ]\n",
    "    \n",
    "#     for column in type_two_column_list:\n",
    "#         if sum(tmp[column] > 0.15)>0:\n",
    "#             oof_df.loc[tmp[column] <= 0.15, column] = 0\n",
    "#             oof_df.loc[(tmp[column] > 0.15) & (tmp[column] <= 0.45), column] = 0.333333\n",
    "#             oof_df.loc[(tmp[column] > 0.45), column] = 0.666667\n",
    "#         else:\n",
    "#             t1 = max(int(len(tmp[column])*0.0013),2)\n",
    "#             t2 = max(int(len(tmp[column])*0.0008),1)\n",
    "#             thred1 = sorted(list(tmp[column]))[-t1]\n",
    "#             thred2 = sorted(list(tmp[column]))[-t2]\n",
    "#             oof_df.loc[tmp[column] <= thred1, column] = 0\n",
    "#             oof_df.loc[(tmp[column] > thred1) & (tmp[column] <= thred2), column] = 0.333333\n",
    "#             oof_df.loc[(tmp[column] > thred2), column] = 0.666667\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################################# handle type 3 columns      \n",
    "    type_three_column_list = [\n",
    "       'question_interestingness_self', \n",
    "    ]\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    oof_df[type_three_column_list] = scaler.fit_transform(oof_df[type_three_column_list])\n",
    "    tmp[type_three_column_list] = scaler.fit_transform(tmp[type_three_column_list])\n",
    "    \n",
    "    for column in type_three_column_list:\n",
    "        oof_df.loc[tmp[column] <= 0.385, column] = 0.333333\n",
    "        oof_df.loc[(tmp[column] > 0.385) & (tmp[column] <= 0.47), column] = 0.444444\n",
    "        oof_df.loc[(tmp[column] > 0.47) & (tmp[column] <= 0.525), column] = 0.5\n",
    "        oof_df.loc[(tmp[column] > 0.525) & (tmp[column] <= 0.605), column] = 0.555556\n",
    "        oof_df.loc[(tmp[column] > 0.605) & (tmp[column] <= 0.715), column] = 0.666667\n",
    "        oof_df.loc[(tmp[column] > 0.715) & (tmp[column] <= 0.8), column] = 0.833333\n",
    "        oof_df.loc[(tmp[column] > 0.8) & (tmp[column] <= 0.94), column] = 0.888889\n",
    "        oof_df.loc[(tmp[column] > 0.94), column] = 1\n",
    "        \n",
    "        \n",
    "        \n",
    "    ################################################# handle type 4 columns      \n",
    "    type_four_column_list = [\n",
    "        'answer_satisfaction'\n",
    "    ]\n",
    "    scaler = MinMaxScaler(feature_range=(0.2, 1))\n",
    "    oof_df[type_four_column_list] = scaler.fit_transform(oof_df[type_four_column_list])\n",
    "    tmp[type_four_column_list] = scaler.fit_transform(tmp[type_four_column_list])\n",
    "    \n",
    "    for column in type_four_column_list:\n",
    "        \n",
    "        oof_df.loc[tmp[column] <= 0.233, column] = 0.200000\n",
    "        oof_df.loc[(tmp[column] > 0.233) & (tmp[column] <= 0.283), column] = 0.266667\n",
    "        oof_df.loc[(tmp[column] > 0.283) & (tmp[column] <= 0.315), column] = 0.300000\n",
    "        oof_df.loc[(tmp[column] > 0.315) & (tmp[column] <= 0.365), column] = 0.333333\n",
    "        oof_df.loc[(tmp[column] > 0.365) & (tmp[column] <= 0.433), column] = 0.400000\n",
    "        oof_df.loc[(tmp[column] > 0.433) & (tmp[column] <= 0.483), column] = 0.466667\n",
    "        oof_df.loc[(tmp[column] > 0.483) & (tmp[column] <= 0.517), column] = 0.500000\n",
    "        oof_df.loc[(tmp[column] > 0.517) & (tmp[column] <= 0.567), column] = 0.533333\n",
    "        oof_df.loc[(tmp[column] > 0.567) & (tmp[column] <= 0.633), column] = 0.600000\n",
    "        oof_df.loc[(tmp[column] > 0.633) & (tmp[column] <= 0.683), column] = 0.666667\n",
    "        oof_df.loc[(tmp[column] > 0.683) & (tmp[column] <= 0.715), column] = 0.700000\n",
    "        oof_df.loc[(tmp[column] > 0.715) & (tmp[column] <= 0.767), column] = 0.733333\n",
    "        oof_df.loc[(tmp[column] > 0.767) & (tmp[column] <= 0.833), column] = 0.800000\n",
    "        oof_df.loc[(tmp[column] > 0.883) & (tmp[column] <= 0.915), column] = 0.900000\n",
    "        oof_df.loc[(tmp[column] > 0.915) & (tmp[column] <= 0.967), column] = 0.933333\n",
    "        oof_df.loc[(tmp[column] > 0.967), column] = 1\n",
    "    \n",
    "    \n",
    "    ################################################# round to i / 90 (i from 0 to 90)\n",
    "    oof_values = oof_df[TARGET_COLUMNS].values\n",
    "    DEGREE = len(oof_df)//45*9\n",
    "#     if degree:\n",
    "#         DEGREE = degree\n",
    "#     DEGREE = 90\n",
    "    oof_values = np.around(oof_values * DEGREE) / DEGREE  ### 90 To be changed\n",
    "    oof_df[TARGET_COLUMNS] = oof_values\n",
    "    \n",
    "    return oof_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = postprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.944444    41\n",
      "0.888889    41\n",
      "0.911111    39\n",
      "0.900000    39\n",
      "0.877778    38\n",
      "0.866667    37\n",
      "0.922222    36\n",
      "0.933333    36\n",
      "0.855556    32\n",
      "0.955556    31\n",
      "0.844444    24\n",
      "0.833333    21\n",
      "0.966667    17\n",
      "0.811111    12\n",
      "0.822222     9\n",
      "0.788889     6\n",
      "0.766667     4\n",
      "0.977778     4\n",
      "0.755556     4\n",
      "0.777778     2\n",
      "0.800000     2\n",
      "0.733333     1\n",
      "Name: question_asker_intent_understanding, dtype: int64\n",
      "0.511111    18\n",
      "0.466667    17\n",
      "0.477778    16\n",
      "0.688889    16\n",
      "0.422222    16\n",
      "0.722222    16\n",
      "0.622222    15\n",
      "0.755556    15\n",
      "0.522222    14\n",
      "0.455556    14\n",
      "0.411111    13\n",
      "0.655556    13\n",
      "0.566667    13\n",
      "0.677778    12\n",
      "0.433333    12\n",
      "0.777778    12\n",
      "0.500000    12\n",
      "0.577778    12\n",
      "0.444444    11\n",
      "0.700000    11\n",
      "0.711111    10\n",
      "0.800000    10\n",
      "0.588889    10\n",
      "0.788889    10\n",
      "0.666667     9\n",
      "0.633333     9\n",
      "0.400000     9\n",
      "0.544444     9\n",
      "0.733333     9\n",
      "0.611111     9\n",
      "0.744444     9\n",
      "0.766667     9\n",
      "0.811111     9\n",
      "0.644444     9\n",
      "0.488889     8\n",
      "0.600000     8\n",
      "0.822222     7\n",
      "0.533333     6\n",
      "0.377778     6\n",
      "0.555556     6\n",
      "0.388889     5\n",
      "0.366667     5\n",
      "0.855556     4\n",
      "0.844444     4\n",
      "0.866667     4\n",
      "0.833333     2\n",
      "0.355556     1\n",
      "0.333333     1\n",
      "0.322222     1\n",
      "Name: question_body_critical, dtype: int64\n",
      "0.000000    433\n",
      "0.333333     29\n",
      "0.500000      7\n",
      "1.000000      5\n",
      "0.666667      2\n",
      "Name: question_conversational, dtype: int64\n",
      "0.722222    28\n",
      "0.688889    26\n",
      "0.777778    26\n",
      "0.733333    26\n",
      "0.711111    24\n",
      "0.700000    22\n",
      "0.744444    22\n",
      "0.655556    22\n",
      "0.766667    20\n",
      "0.677778    19\n",
      "0.666667    17\n",
      "0.633333    14\n",
      "0.644444    13\n",
      "0.755556    12\n",
      "0.788889    12\n",
      "0.800000    11\n",
      "0.822222    11\n",
      "0.833333    11\n",
      "0.811111    10\n",
      "0.622222    10\n",
      "0.600000     8\n",
      "0.611111     8\n",
      "0.566667     7\n",
      "0.911111     7\n",
      "0.844444     7\n",
      "0.588889     7\n",
      "0.533333     7\n",
      "0.866667     6\n",
      "0.855556     6\n",
      "0.933333     6\n",
      "0.522222     5\n",
      "0.577778     5\n",
      "0.900000     4\n",
      "0.877778     4\n",
      "0.555556     4\n",
      "0.888889     4\n",
      "0.544444     3\n",
      "0.922222     3\n",
      "0.511111     3\n",
      "0.488889     2\n",
      "0.944444     2\n",
      "0.466667     2\n",
      "0.222222     1\n",
      "0.477778     1\n",
      "0.355556     1\n",
      "0.411111     1\n",
      "0.322222     1\n",
      "0.955556     1\n",
      "0.400000     1\n",
      "0.344444     1\n",
      "0.422222     1\n",
      "0.500000     1\n",
      "Name: question_expect_short_answer, dtype: int64\n",
      "0.822222    31\n",
      "0.811111    30\n",
      "0.766667    28\n",
      "0.800000    26\n",
      "0.788889    25\n",
      "0.888889    23\n",
      "0.777778    23\n",
      "0.844444    22\n",
      "0.877778    21\n",
      "0.866667    20\n",
      "0.755556    20\n",
      "0.855556    18\n",
      "0.922222    18\n",
      "0.933333    15\n",
      "0.733333    14\n",
      "0.744444    13\n",
      "0.833333    13\n",
      "0.911111    12\n",
      "0.900000    12\n",
      "0.944444    12\n",
      "0.955556     7\n",
      "0.711111     6\n",
      "0.722222     6\n",
      "0.966667     6\n",
      "0.688889     6\n",
      "0.644444     5\n",
      "0.977778     5\n",
      "0.700000     4\n",
      "0.655556     4\n",
      "0.611111     3\n",
      "0.566667     3\n",
      "0.433333     2\n",
      "0.622222     2\n",
      "0.677778     2\n",
      "0.588889     2\n",
      "0.577778     2\n",
      "0.522222     2\n",
      "0.666667     1\n",
      "0.511111     1\n",
      "0.422222     1\n",
      "0.533333     1\n",
      "0.377778     1\n",
      "0.411111     1\n",
      "0.466667     1\n",
      "0.477778     1\n",
      "0.488889     1\n",
      "0.600000     1\n",
      "0.544444     1\n",
      "0.455556     1\n",
      "0.500000     1\n",
      "Name: question_fact_seeking, dtype: int64\n",
      "1.000000    395\n",
      "0.666667     36\n",
      "0.500000     21\n",
      "0.333333     17\n",
      "0.000000      7\n",
      "Name: question_has_commonly_accepted_answer, dtype: int64\n",
      "0.544444    59\n",
      "0.533333    56\n",
      "0.555556    50\n",
      "0.566667    38\n",
      "0.588889    35\n",
      "0.611111    29\n",
      "0.522222    29\n",
      "0.577778    26\n",
      "0.622222    25\n",
      "0.655556    23\n",
      "0.600000    18\n",
      "0.644444    17\n",
      "0.633333    15\n",
      "0.511111    15\n",
      "0.666667    11\n",
      "0.688889    11\n",
      "0.677778    11\n",
      "0.711111     3\n",
      "0.500000     3\n",
      "0.700000     2\n",
      "Name: question_interestingness_others, dtype: int64\n",
      "0.333333    329\n",
      "0.444444     36\n",
      "0.666667     31\n",
      "0.500000     20\n",
      "0.888889     19\n",
      "0.833333     18\n",
      "0.555556     18\n",
      "1.000000      5\n",
      "Name: question_interestingness_self, dtype: int64\n",
      "0.055556    35\n",
      "0.044444    31\n",
      "0.066667    28\n",
      "0.100000    23\n",
      "0.033333    23\n",
      "            ..\n",
      "0.755556     1\n",
      "0.766667     1\n",
      "0.611111     1\n",
      "0.811111     1\n",
      "0.777778     1\n",
      "Name: question_multi_intent, Length: 69, dtype: int64\n",
      "0.000000    388\n",
      "0.333333     64\n",
      "0.500000     11\n",
      "1.000000      8\n",
      "0.666667      5\n",
      "Name: question_not_really_a_question, dtype: int64\n",
      "0.444444    21\n",
      "0.466667    18\n",
      "0.477778    17\n",
      "0.488889    16\n",
      "0.522222    15\n",
      "            ..\n",
      "0.888889     1\n",
      "0.722222     1\n",
      "0.777778     1\n",
      "0.666667     1\n",
      "0.800000     1\n",
      "Name: question_opinion_seeking, Length: 72, dtype: int64\n",
      "0.000000    242\n",
      "0.333333     71\n",
      "1.000000     65\n",
      "0.500000     57\n",
      "0.666667     41\n",
      "Name: question_type_choice, dtype: int64\n",
      "0.000000    454\n",
      "0.333333     10\n",
      "0.666667      6\n",
      "1.000000      4\n",
      "0.500000      2\n",
      "Name: question_type_compare, dtype: int64\n",
      "0.000000    461\n",
      "0.333333      8\n",
      "0.500000      5\n",
      "0.666667      1\n",
      "1.000000      1\n",
      "Name: question_type_consequence, dtype: int64\n",
      "0.000000    459\n",
      "0.333333     10\n",
      "0.500000      3\n",
      "0.666667      2\n",
      "1.000000      2\n",
      "Name: question_type_definition, dtype: int64\n",
      "0.000000    439\n",
      "0.333333     18\n",
      "0.666667      8\n",
      "1.000000      6\n",
      "0.500000      5\n",
      "Name: question_type_entity, dtype: int64\n",
      "1.000000    238\n",
      "0.000000    113\n",
      "0.333333     53\n",
      "0.666667     38\n",
      "0.500000     34\n",
      "Name: question_type_instructions, dtype: int64\n",
      "0.200000    43\n",
      "0.211111    34\n",
      "0.222222    29\n",
      "0.188889    26\n",
      "0.033333    24\n",
      "0.177778    21\n",
      "0.244444    18\n",
      "0.166667    18\n",
      "0.122222    17\n",
      "0.133333    17\n",
      "0.100000    17\n",
      "0.255556    17\n",
      "0.022222    17\n",
      "0.055556    16\n",
      "0.233333    15\n",
      "0.155556    15\n",
      "0.088889    14\n",
      "0.044444    14\n",
      "0.066667    14\n",
      "0.266667    13\n",
      "0.144444    13\n",
      "0.300000    12\n",
      "0.288889     9\n",
      "0.111111     8\n",
      "0.277778     8\n",
      "0.011111     8\n",
      "0.077778     7\n",
      "0.333333     4\n",
      "0.311111     4\n",
      "0.322222     2\n",
      "0.355556     2\n",
      "Name: question_type_procedure, dtype: int64\n",
      "0.055556    22\n",
      "0.088889    19\n",
      "0.111111    16\n",
      "0.100000    13\n",
      "0.133333    13\n",
      "            ..\n",
      "0.344444     2\n",
      "0.633333     1\n",
      "0.377778     1\n",
      "0.455556     1\n",
      "0.800000     1\n",
      "Name: question_type_reason_explanation, Length: 85, dtype: int64\n",
      "0.000000    474\n",
      "0.011111      2\n",
      "Name: question_type_spelling, dtype: int64\n",
      "0.911111    34\n",
      "0.900000    28\n",
      "0.688889    25\n",
      "0.877778    24\n",
      "0.733333    24\n",
      "0.888889    22\n",
      "0.700000    22\n",
      "0.800000    22\n",
      "0.922222    21\n",
      "0.866667    19\n",
      "0.844444    19\n",
      "0.855556    18\n",
      "0.777778    18\n",
      "0.711111    18\n",
      "0.722222    17\n",
      "0.788889    16\n",
      "0.744444    16\n",
      "0.655556    14\n",
      "0.766667    14\n",
      "0.755556    14\n",
      "0.833333    12\n",
      "0.811111    12\n",
      "0.822222    11\n",
      "0.677778    11\n",
      "0.933333     9\n",
      "0.666667     5\n",
      "0.944444     3\n",
      "0.633333     3\n",
      "0.644444     2\n",
      "0.622222     2\n",
      "0.955556     1\n",
      "Name: question_well_written, dtype: int64\n",
      "0.944444    107\n",
      "0.955556    105\n",
      "0.933333     86\n",
      "0.922222     52\n",
      "0.966667     31\n",
      "0.911111     28\n",
      "0.900000     28\n",
      "0.888889     16\n",
      "0.877778     12\n",
      "0.977778      5\n",
      "0.866667      3\n",
      "0.855556      2\n",
      "0.811111      1\n",
      "Name: answer_helpful, dtype: int64\n",
      "0.644444    57\n",
      "0.688889    49\n",
      "0.655556    49\n",
      "0.677778    49\n",
      "0.666667    47\n",
      "0.633333    45\n",
      "0.700000    41\n",
      "0.622222    39\n",
      "0.711111    22\n",
      "0.611111    21\n",
      "0.600000    18\n",
      "0.733333    10\n",
      "0.722222     9\n",
      "0.744444     7\n",
      "0.588889     6\n",
      "0.577778     3\n",
      "0.755556     2\n",
      "0.566667     1\n",
      "0.544444     1\n",
      "Name: answer_level_of_information, dtype: int64\n",
      "0.966667    188\n",
      "0.977778    137\n",
      "0.955556     88\n",
      "0.944444     36\n",
      "0.933333     16\n",
      "0.988889      9\n",
      "0.911111      1\n",
      "0.922222      1\n",
      "Name: answer_plausible, dtype: int64\n",
      "0.977778    228\n",
      "0.988889     98\n",
      "0.966667     84\n",
      "0.955556     42\n",
      "0.944444     16\n",
      "0.933333      7\n",
      "0.911111      1\n",
      "Name: answer_relevance, dtype: int64\n",
      "0.800000    131\n",
      "0.733333     94\n",
      "0.600000     51\n",
      "0.666667     50\n",
      "0.700000     41\n",
      "0.533333     21\n",
      "0.500000     15\n",
      "0.866667     11\n",
      "0.855556     11\n",
      "0.466667     10\n",
      "0.844444     10\n",
      "0.400000      8\n",
      "0.933333      4\n",
      "0.833333      4\n",
      "0.900000      4\n",
      "0.877778      4\n",
      "1.000000      3\n",
      "0.333333      2\n",
      "0.200000      1\n",
      "0.300000      1\n",
      "Name: answer_satisfaction, dtype: int64\n",
      "0.011111    22\n",
      "0.911111    19\n",
      "0.888889    15\n",
      "0.877778    15\n",
      "0.855556    12\n",
      "            ..\n",
      "0.933333     1\n",
      "0.533333     1\n",
      "0.400000     1\n",
      "0.200000     1\n",
      "0.000000     1\n",
      "Name: answer_type_instructions, Length: 82, dtype: int64\n",
      "0.144444    43\n",
      "0.166667    35\n",
      "0.155556    34\n",
      "0.122222    33\n",
      "0.177778    32\n",
      "0.133333    29\n",
      "0.100000    27\n",
      "0.077778    23\n",
      "0.111111    23\n",
      "0.188889    21\n",
      "0.033333    20\n",
      "0.200000    19\n",
      "0.022222    18\n",
      "0.211111    18\n",
      "0.222222    15\n",
      "0.044444    14\n",
      "0.088889    13\n",
      "0.055556    13\n",
      "0.244444    11\n",
      "0.066667     9\n",
      "0.011111     9\n",
      "0.233333     6\n",
      "0.255556     5\n",
      "0.266667     2\n",
      "0.277778     2\n",
      "0.300000     1\n",
      "0.311111     1\n",
      "Name: answer_type_procedure, dtype: int64\n",
      "0.555556    11\n",
      "0.422222    11\n",
      "0.811111    11\n",
      "0.655556    10\n",
      "0.111111    10\n",
      "            ..\n",
      "0.044444     1\n",
      "0.777778     1\n",
      "0.700000     1\n",
      "0.477778     1\n",
      "0.788889     1\n",
      "Name: answer_type_reason_explanation, Length: 85, dtype: int64\n",
      "0.922222    124\n",
      "0.911111    106\n",
      "0.900000     90\n",
      "0.933333     78\n",
      "0.888889     33\n",
      "0.877778     23\n",
      "0.944444     15\n",
      "0.866667      4\n",
      "0.855556      2\n",
      "0.844444      1\n",
      "Name: answer_well_written, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for column in TARGET_COLUMNS:\n",
    "    print(test[column].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign postprocessed result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test[TARGET_COLUMNS].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub[ sub[TARGET_COLUMNS] > 1.0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.522222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.088889</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.855556</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.877778</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.922222</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.744444</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.144444</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.911111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.944444                0.711111   \n",
       "1     46                             0.877778                0.522222   \n",
       "2     70                             0.922222                0.700000   \n",
       "3    132                             0.877778                0.466667   \n",
       "4    200                             0.922222                0.511111   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.333333                      0.533333   \n",
       "1                 0.000000                      0.744444   \n",
       "2                 0.000000                      0.777778   \n",
       "3                 0.000000                      0.711111   \n",
       "4                 0.000000                      0.788889   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.655556                                    0.5   \n",
       "1               0.788889                                    1.0   \n",
       "2               0.900000                                    1.0   \n",
       "3               0.766667                                    1.0   \n",
       "4               0.788889                                    1.0   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.688889                       0.833333   \n",
       "1                         0.555556                       0.333333   \n",
       "2                         0.611111                       0.444444   \n",
       "3                         0.555556                       0.333333   \n",
       "4                         0.644444                       0.666667   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.555556  ...               0.933333        0.911111   \n",
       "1               0.088889  ...               0.711111        0.955556   \n",
       "2               0.166667  ...               0.888889        0.933333   \n",
       "3               0.111111  ...               0.711111        0.955556   \n",
       "4               0.166667  ...               0.744444        0.900000   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.600000          0.955556          0.955556   \n",
       "1                     0.655556          0.977778          0.988889   \n",
       "2                     0.611111          0.966667          0.966667   \n",
       "3                     0.688889          0.977778          0.988889   \n",
       "4                     0.644444          0.955556          0.955556   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.600000                  0.033333               0.033333   \n",
       "1             0.800000                  0.911111               0.144444   \n",
       "2             0.666667                  0.088889               0.055556   \n",
       "3             0.800000                  0.800000               0.155556   \n",
       "4             0.533333                  0.344444               0.144444   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.800000             0.922222  \n",
       "1                        0.100000             0.900000  \n",
       "2                        0.855556             0.911111  \n",
       "3                        0.733333             0.900000  \n",
       "4                        0.588889             0.911111  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(f'{DATA_DIR}/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=test['url'].apply(lambda x:(('ell.stackexchange.com' in x) or ('english.stackexchange.com' in x))).tolist()\n",
    "spelling=[]\n",
    "for x in n:\n",
    "    if x:\n",
    "        spelling.append(0.5)\n",
    "    else:\n",
    "        spelling.append(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['question_type_spelling'] = spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    465\n",
       "0.5     11\n",
       "Name: question_type_spelling, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub['question_type_spelling'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "086421f7eec44c769f08f5f68fafafdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0e7c81c0da784e04b530236bad005c33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18b951cd8c1447eaa1e12f972ac37d42": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "danger",
       "description": "  9%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_9e743ecd26cd4877a539f9bbbd23d114",
       "max": 308,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e34fafda1e234d9c981322beff1068e7",
       "value": 29
      }
     },
     "35645b239e914aee807cfdc234fc5b75": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dfdee9b109bc4176a0bc3a26ae38f7a3",
       "placeholder": "​",
       "style": "IPY_MODEL_086421f7eec44c769f08f5f68fafafdc",
       "value": " 29/308 [7:12:46&lt;66:18:40, 855.63s/it]"
      }
     },
     "554271f3ed5d48efa844608a0b72fdac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "685ecca481e3463d83a2465f15f7b33f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_80ae0d356c3e4b1bbe511c5f5a2694b5",
       "max": 4059,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a34804b28be74d7c9972a0a13410ba77",
       "value": 4059
      }
     },
     "7f49d7d685554687bc2d131959058cb3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "80ae0d356c3e4b1bbe511c5f5a2694b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "840e74b11eb44a58b1ed0433e924dc82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9e743ecd26cd4877a539f9bbbd23d114": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a34804b28be74d7c9972a0a13410ba77": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a61c8f56dbd74e29a155fad0d7095f79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_18b951cd8c1447eaa1e12f972ac37d42",
        "IPY_MODEL_35645b239e914aee807cfdc234fc5b75"
       ],
       "layout": "IPY_MODEL_7f49d7d685554687bc2d131959058cb3"
      }
     },
     "c9ab84b07a32426282543b5ff054ddec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_840e74b11eb44a58b1ed0433e924dc82",
       "placeholder": "​",
       "style": "IPY_MODEL_554271f3ed5d48efa844608a0b72fdac",
       "value": " 4059/4059 [14:53&lt;00:00,  4.54it/s]"
      }
     },
     "dfdee9b109bc4176a0bc3a26ae38f7a3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e34fafda1e234d9c981322beff1068e7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "fd692cff30e343aa8afa007a05d66acc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_685ecca481e3463d83a2465f15f7b33f",
        "IPY_MODEL_c9ab84b07a32426282543b5ff054ddec"
       ],
       "layout": "IPY_MODEL_0e7c81c0da784e04b530236bad005c33"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
