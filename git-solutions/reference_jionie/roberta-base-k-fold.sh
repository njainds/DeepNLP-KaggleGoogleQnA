# 5 fold roberta-base, question_answer, seed 2345
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question_Answer" --model_name "roberta-base" --fold 0 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 13 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question_Answer" --model_name "roberta-base" --fold 1 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 13 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question_Answer" --model_name "roberta-base" --fold 2 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 13 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question_Answer" --model_name "roberta-base" --fold 3 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 13 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question_Answer" --model_name "roberta-base" --fold 4 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 13 --num_workers 4


# 5 fold roberta-base, question + answer, seed 123
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 0 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 1 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 2 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 3 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 4 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4

python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 0 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 1 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 2 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 3 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 4 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 1e-4 --split "GroupKfold" --loss "bce" --augment --num_epoch 8 --num_workers 4
