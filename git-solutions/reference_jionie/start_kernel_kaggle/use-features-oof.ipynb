{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import pickle  \n",
    "import random\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import keras.backend as K\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from os.path import join as path_join\n",
    "from numpy.random import seed\n",
    "from urllib.parse import urlparse\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import MultiTaskElasticNet\n",
    "\n",
    "seed(42)\n",
    "tf.random.set_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6079, 41) (476, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_title</th>\n",
       "      <th>question_body</th>\n",
       "      <th>question_user_name</th>\n",
       "      <th>question_user_page</th>\n",
       "      <th>answer</th>\n",
       "      <th>answer_user_name</th>\n",
       "      <th>answer_user_page</th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>What am I losing when using extension tubes in...</td>\n",
       "      <td>After playing around with macro photography on...</td>\n",
       "      <td>ysap</td>\n",
       "      <td>https://photo.stackexchange.com/users/1024</td>\n",
       "      <td>I just got extension tubes, so here's the skin...</td>\n",
       "      <td>rfusca</td>\n",
       "      <td>https://photo.stackexchange.com/users/1917</td>\n",
       "      <td>http://photo.stackexchange.com/questions/9169/...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the distinction between a city and a s...</td>\n",
       "      <td>I am trying to understand what kinds of places...</td>\n",
       "      <td>russellpierce</td>\n",
       "      <td>https://rpg.stackexchange.com/users/8774</td>\n",
       "      <td>It might be helpful to look into the definitio...</td>\n",
       "      <td>Erik Schmidt</td>\n",
       "      <td>https://rpg.stackexchange.com/users/1871</td>\n",
       "      <td>http://rpg.stackexchange.com/questions/47820/w...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Maximum protusion length for through-hole comp...</td>\n",
       "      <td>I'm working on a PCB that has through-hole com...</td>\n",
       "      <td>Joe Baker</td>\n",
       "      <td>https://electronics.stackexchange.com/users/10157</td>\n",
       "      <td>Do you even need grooves?  We make several pro...</td>\n",
       "      <td>Dwayne Reid</td>\n",
       "      <td>https://electronics.stackexchange.com/users/64754</td>\n",
       "      <td>http://electronics.stackexchange.com/questions...</td>\n",
       "      <td>SCIENCE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Can an affidavit be used in Beit Din?</td>\n",
       "      <td>An affidavit, from what i understand, is basic...</td>\n",
       "      <td>Scimonster</td>\n",
       "      <td>https://judaism.stackexchange.com/users/5151</td>\n",
       "      <td>Sending an \"affidavit\" it is a dispute between...</td>\n",
       "      <td>Y     e     z</td>\n",
       "      <td>https://judaism.stackexchange.com/users/4794</td>\n",
       "      <td>http://judaism.stackexchange.com/questions/551...</td>\n",
       "      <td>CULTURE</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How do you make a binary image in Photoshop?</td>\n",
       "      <td>I am trying to make a binary image. I want mor...</td>\n",
       "      <td>leigero</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>Check out Image Trace in Adobe Illustrator. \\n...</td>\n",
       "      <td>q2ra</td>\n",
       "      <td>https://graphicdesign.stackexchange.com/users/...</td>\n",
       "      <td>http://graphicdesign.stackexchange.com/questio...</td>\n",
       "      <td>LIFE_ARTS</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id                                     question_title  \\\n",
       "0      0  What am I losing when using extension tubes in...   \n",
       "1      1  What is the distinction between a city and a s...   \n",
       "2      2  Maximum protusion length for through-hole comp...   \n",
       "3      3              Can an affidavit be used in Beit Din?   \n",
       "4      5       How do you make a binary image in Photoshop?   \n",
       "\n",
       "                                       question_body question_user_name  \\\n",
       "0  After playing around with macro photography on...               ysap   \n",
       "1  I am trying to understand what kinds of places...      russellpierce   \n",
       "2  I'm working on a PCB that has through-hole com...          Joe Baker   \n",
       "3  An affidavit, from what i understand, is basic...         Scimonster   \n",
       "4  I am trying to make a binary image. I want mor...            leigero   \n",
       "\n",
       "                                  question_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1024   \n",
       "1           https://rpg.stackexchange.com/users/8774   \n",
       "2  https://electronics.stackexchange.com/users/10157   \n",
       "3       https://judaism.stackexchange.com/users/5151   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                              answer answer_user_name  \\\n",
       "0  I just got extension tubes, so here's the skin...           rfusca   \n",
       "1  It might be helpful to look into the definitio...     Erik Schmidt   \n",
       "2  Do you even need grooves?  We make several pro...      Dwayne Reid   \n",
       "3  Sending an \"affidavit\" it is a dispute between...    Y     e     z   \n",
       "4  Check out Image Trace in Adobe Illustrator. \\n...             q2ra   \n",
       "\n",
       "                                    answer_user_page  \\\n",
       "0         https://photo.stackexchange.com/users/1917   \n",
       "1           https://rpg.stackexchange.com/users/1871   \n",
       "2  https://electronics.stackexchange.com/users/64754   \n",
       "3       https://judaism.stackexchange.com/users/4794   \n",
       "4  https://graphicdesign.stackexchange.com/users/...   \n",
       "\n",
       "                                                 url   category  ...  \\\n",
       "0  http://photo.stackexchange.com/questions/9169/...  LIFE_ARTS  ...   \n",
       "1  http://rpg.stackexchange.com/questions/47820/w...    CULTURE  ...   \n",
       "2  http://electronics.stackexchange.com/questions...    SCIENCE  ...   \n",
       "3  http://judaism.stackexchange.com/questions/551...    CULTURE  ...   \n",
       "4  http://graphicdesign.stackexchange.com/questio...  LIFE_ARTS  ...   \n",
       "\n",
       "  question_well_written  answer_helpful  answer_level_of_information  \\\n",
       "0              1.000000        1.000000                     0.666667   \n",
       "1              0.888889        0.888889                     0.555556   \n",
       "2              0.777778        0.777778                     0.555556   \n",
       "3              0.888889        0.833333                     0.333333   \n",
       "4              1.000000        1.000000                     0.666667   \n",
       "\n",
       "   answer_plausible  answer_relevance  answer_satisfaction  \\\n",
       "0          1.000000          1.000000             0.800000   \n",
       "1          0.888889          0.888889             0.666667   \n",
       "2          1.000000          1.000000             0.666667   \n",
       "3          0.833333          1.000000             0.800000   \n",
       "4          1.000000          1.000000             0.800000   \n",
       "\n",
       "   answer_type_instructions  answer_type_procedure  \\\n",
       "0                       1.0               0.000000   \n",
       "1                       0.0               0.000000   \n",
       "2                       0.0               0.333333   \n",
       "3                       0.0               0.000000   \n",
       "4                       1.0               0.000000   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.000000             1.000000  \n",
       "1                        0.666667             0.888889  \n",
       "2                        1.000000             0.888889  \n",
       "3                        1.000000             1.000000  \n",
       "4                        1.000000             1.000000  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../input/google-quest-challenge/'\n",
    "train = pd.read_csv(path_join(data_dir, 'train.csv'))\n",
    "test = pd.read_csv(path_join(data_dir, 'test.csv'))\n",
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\n",
    "        'question_asker_intent_understanding',\n",
    "        'question_body_critical',\n",
    "        'question_conversational',\n",
    "        'question_expect_short_answer',\n",
    "        'question_fact_seeking',\n",
    "        'question_has_commonly_accepted_answer',\n",
    "        'question_interestingness_others',\n",
    "        'question_interestingness_self',\n",
    "        'question_multi_intent',\n",
    "        'question_not_really_a_question',\n",
    "        'question_opinion_seeking',\n",
    "        'question_type_choice',\n",
    "        'question_type_compare',\n",
    "        'question_type_consequence',\n",
    "        'question_type_definition',\n",
    "        'question_type_entity',\n",
    "        'question_type_instructions',\n",
    "        'question_type_procedure',\n",
    "        'question_type_reason_explanation',\n",
    "        'question_type_spelling',\n",
    "        'question_well_written',\n",
    "        'answer_helpful',\n",
    "        'answer_level_of_information',\n",
    "        'answer_plausible',\n",
    "        'answer_relevance',\n",
    "        'answer_satisfaction',\n",
    "        'answer_type_instructions',\n",
    "        'answer_type_procedure',\n",
    "        'answer_type_reason_explanation',\n",
    "        'answer_well_written'    \n",
    "    ]\n",
    "\n",
    "input_columns = ['question_title', 'question_body', 'answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = re.compile(r\"^[^.]*\")\n",
    "\n",
    "train['netloc'] = train['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n",
    "test['netloc'] = test['url'].apply(lambda x: re.findall(find, urlparse(x).netloc)[0])\n",
    "\n",
    "features = ['netloc', 'category']\n",
    "merged = pd.concat([train[features], test[features]])\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(merged)\n",
    "\n",
    "features_train = ohe.transform(train[features]).toarray()\n",
    "features_test = ohe.transform(test[features]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_url = \"../input/universalsentenceencoderlarge4/\"\n",
    "embed = hub.load(module_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question_title\n",
      "question_body\n",
      "answer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_train = {}\n",
    "embeddings_test = {}\n",
    "for text in input_columns:\n",
    "    print(text)\n",
    "    train_text = train[text].str.replace('?', '.').str.replace('!', '.').tolist()\n",
    "    test_text = test[text].str.replace('?', '.').str.replace('!', '.').tolist()\n",
    "    \n",
    "    curr_train_emb = []\n",
    "    curr_test_emb = []\n",
    "    batch_size = 4\n",
    "    ind = 0\n",
    "    while ind*batch_size < len(train_text):\n",
    "        curr_train_emb.append(embed(train_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n",
    "        ind += 1\n",
    "        \n",
    "    ind = 0\n",
    "    while ind*batch_size < len(test_text):\n",
    "        curr_test_emb.append(embed(test_text[ind*batch_size: (ind + 1)*batch_size])[\"outputs\"].numpy())\n",
    "        ind += 1    \n",
    "        \n",
    "    embeddings_train[text + '_embedding'] = np.vstack(curr_train_emb)\n",
    "    embeddings_test[text + '_embedding'] = np.vstack(curr_test_emb)\n",
    "    \n",
    "del embed\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_dist = lambda x, y: np.power(x - y, 2).sum(axis=1)\n",
    "\n",
    "cos_dist = lambda x, y: (x*y).sum(axis=1)\n",
    "\n",
    "dist_features_train = np.array([\n",
    "    l2_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n",
    "    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n",
    "    l2_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding']),\n",
    "    cos_dist(embeddings_train['question_title_embedding'], embeddings_train['answer_embedding']),\n",
    "    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['answer_embedding']),\n",
    "    cos_dist(embeddings_train['question_body_embedding'], embeddings_train['question_title_embedding'])\n",
    "]).T\n",
    "\n",
    "dist_features_test = np.array([\n",
    "    l2_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n",
    "    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n",
    "    l2_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding']),\n",
    "    cos_dist(embeddings_test['question_title_embedding'], embeddings_test['answer_embedding']),\n",
    "    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['answer_embedding']),\n",
    "    cos_dist(embeddings_test['question_body_embedding'], embeddings_test['question_title_embedding'])\n",
    "]).T\n",
    "\n",
    "X_train = np.hstack([item for k, item in embeddings_train.items()] + [features_train, dist_features_train])\n",
    "X_test = np.hstack([item for k, item in embeddings_test.items()] + [features_test, dist_features_test])\n",
    "y_train = train[targets].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compatible with tensorflow backend\n",
    "class SpearmanRhoCallback(Callback):\n",
    "    def __init__(self, training_data, validation_data, patience, model_name):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.value = -1\n",
    "        self.bad_epochs = 0\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        rho_val = np.mean([spearmanr(self.y_val[:, ind], y_pred_val[:, ind] + np.random.normal(0, 1e-7, y_pred_val.shape[0])).correlation for ind in range(y_pred_val.shape[1])])\n",
    "        if rho_val >= self.value:\n",
    "            self.value = rho_val\n",
    "            self.model.save_weights(self.model_name)\n",
    "        else:\n",
    "            self.bad_epochs += 1\n",
    "        if self.bad_epochs >= self.patience:\n",
    "            print(\"Epoch %05d: early stopping Threshold\" % epoch)\n",
    "            self.model.stop_training = True\n",
    "        print('\\rval_spearman-rho: %s' % (str(round(rho_val, 4))), end=100*' '+'\\n')\n",
    "        return rho_val\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inps = Input(shape=(X_train.shape[1],))\n",
    "    x = Dense(512, activation='elu')(inps)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(y_train.shape[1], activation='sigmoid')(x)\n",
    "    model = Model(inputs=inps, outputs=x)\n",
    "    model.compile(\n",
    "        optimizer=Adam(lr=1e-4),\n",
    "        loss=['binary_crossentropy']\n",
    "    )\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1606)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               822784    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 838,174\n",
      "Trainable params: 838,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 160us/step - loss: 0.5220 - val_loss: 0.4271\n",
      "val_spearman-rho: 0.1903                                                                                                    \n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.4128 - val_loss: 0.4037\n",
      "val_spearman-rho: 0.2552                                                                                                    \n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3982 - val_loss: 0.3948\n",
      "val_spearman-rho: 0.2914                                                                                                    \n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3904 - val_loss: 0.3891\n",
      "val_spearman-rho: 0.3148                                                                                                    \n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3852 - val_loss: 0.3850\n",
      "val_spearman-rho: 0.3297                                                                                                    \n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3810 - val_loss: 0.3821\n",
      "val_spearman-rho: 0.3391                                                                                                    \n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3773 - val_loss: 0.3797\n",
      "val_spearman-rho: 0.3465                                                                                                    \n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3747 - val_loss: 0.3780\n",
      "val_spearman-rho: 0.3517                                                                                                    \n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3724 - val_loss: 0.3767\n",
      "val_spearman-rho: 0.3557                                                                                                    \n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3705 - val_loss: 0.3755\n",
      "val_spearman-rho: 0.3588                                                                                                    \n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3685 - val_loss: 0.3746\n",
      "val_spearman-rho: 0.3616                                                                                                    \n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3667 - val_loss: 0.3739\n",
      "val_spearman-rho: 0.364                                                                                                    \n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3653 - val_loss: 0.3733\n",
      "val_spearman-rho: 0.3659                                                                                                    \n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3643 - val_loss: 0.3729\n",
      "val_spearman-rho: 0.3677                                                                                                    \n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3630 - val_loss: 0.3725\n",
      "val_spearman-rho: 0.3693                                                                                                    \n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3617 - val_loss: 0.3722\n",
      "val_spearman-rho: 0.3704                                                                                                    \n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3605 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3713                                                                                                    \n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3596 - val_loss: 0.3718\n",
      "val_spearman-rho: 0.3724                                                                                                    \n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3587 - val_loss: 0.3716\n",
      "val_spearman-rho: 0.3731                                                                                                    \n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3580 - val_loss: 0.3715\n",
      "val_spearman-rho: 0.3736                                                                                                    \n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3570 - val_loss: 0.3715\n",
      "val_spearman-rho: 0.3742                                                                                                    \n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3560 - val_loss: 0.3715\n",
      "val_spearman-rho: 0.3747                                                                                                    \n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3554 - val_loss: 0.3715\n",
      "val_spearman-rho: 0.3749                                                                                                    \n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3544 - val_loss: 0.3715\n",
      "val_spearman-rho: 0.3751                                                                                                    \n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3540 - val_loss: 0.3716\n",
      "val_spearman-rho: 0.3754                                                                                                    \n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3534 - val_loss: 0.3716\n",
      "val_spearman-rho: 0.3758                                                                                                    \n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3526 - val_loss: 0.3715\n",
      "val_spearman-rho: 0.3757                                                                                                    \n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3520 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3757                                                                                                    \n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3514 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3755                                                                                                    \n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3505 - val_loss: 0.3720\n",
      "val_spearman-rho: 0.3755                                                                                                    \n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3504 - val_loss: 0.3720\n",
      "Epoch 00030: early stopping Threshold\n",
      "val_spearman-rho: 0.3754                                                                                                    \n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1606)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               822784    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 838,174\n",
      "Trainable params: 838,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 158us/step - loss: 0.5241 - val_loss: 0.4285\n",
      "val_spearman-rho: 0.1797                                                                                                    \n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.4133 - val_loss: 0.4035\n",
      "val_spearman-rho: 0.2466                                                                                                    \n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3982 - val_loss: 0.3944\n",
      "val_spearman-rho: 0.2853                                                                                                    \n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3906 - val_loss: 0.3888\n",
      "val_spearman-rho: 0.3123                                                                                                    \n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3852 - val_loss: 0.3848\n",
      "val_spearman-rho: 0.3293                                                                                                    \n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3808 - val_loss: 0.3818\n",
      "val_spearman-rho: 0.3405                                                                                                    \n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3776 - val_loss: 0.3795\n",
      "val_spearman-rho: 0.3488                                                                                                    \n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3749 - val_loss: 0.3778\n",
      "val_spearman-rho: 0.3554                                                                                                    \n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3724 - val_loss: 0.3764\n",
      "val_spearman-rho: 0.3605                                                                                                    \n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3707 - val_loss: 0.3753\n",
      "val_spearman-rho: 0.3646                                                                                                    \n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3689 - val_loss: 0.3744\n",
      "val_spearman-rho: 0.3681                                                                                                    \n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3671 - val_loss: 0.3737\n",
      "val_spearman-rho: 0.3708                                                                                                    \n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3657 - val_loss: 0.3731\n",
      "val_spearman-rho: 0.373                                                                                                    \n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3644 - val_loss: 0.3725\n",
      "val_spearman-rho: 0.3752                                                                                                    \n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 124us/step - loss: 0.3633 - val_loss: 0.3720\n",
      "val_spearman-rho: 0.3768                                                                                                    \n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3623 - val_loss: 0.3718\n",
      "val_spearman-rho: 0.378                                                                                                    \n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3613 - val_loss: 0.3713\n",
      "val_spearman-rho: 0.3793                                                                                                    \n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3604 - val_loss: 0.3711\n",
      "val_spearman-rho: 0.3804                                                                                                    \n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3590 - val_loss: 0.3709\n",
      "val_spearman-rho: 0.3815                                                                                                    \n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3585 - val_loss: 0.3707\n",
      "val_spearman-rho: 0.3821                                                                                                    \n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3574 - val_loss: 0.3705\n",
      "val_spearman-rho: 0.3827                                                                                                    \n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 123us/step - loss: 0.3567 - val_loss: 0.3703\n",
      "val_spearman-rho: 0.3837                                                                                                    \n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3560 - val_loss: 0.3704\n",
      "val_spearman-rho: 0.3839                                                                                                    \n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 1s 126us/step - loss: 0.3552 - val_loss: 0.3703\n",
      "val_spearman-rho: 0.3845                                                                                                    \n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 1s 121us/step - loss: 0.3545 - val_loss: 0.3703\n",
      "val_spearman-rho: 0.3846                                                                                                    \n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3538 - val_loss: 0.3703\n",
      "val_spearman-rho: 0.3848                                                                                                    \n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3529 - val_loss: 0.3702\n",
      "val_spearman-rho: 0.385                                                                                                    \n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 1s 125us/step - loss: 0.3525 - val_loss: 0.3702\n",
      "val_spearman-rho: 0.3852                                                                                                    \n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3519 - val_loss: 0.3703\n",
      "val_spearman-rho: 0.3851                                                                                                    \n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3514 - val_loss: 0.3704\n",
      "val_spearman-rho: 0.385                                                                                                    \n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3508 - val_loss: 0.3703\n",
      "val_spearman-rho: 0.3848                                                                                                    \n",
      "Epoch 32/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3501 - val_loss: 0.3706\n",
      "val_spearman-rho: 0.3845                                                                                                    \n",
      "Epoch 33/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3496 - val_loss: 0.3706\n",
      "Epoch 00032: early stopping Threshold\n",
      "val_spearman-rho: 0.3845                                                                                                    \n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1606)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               822784    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 838,174\n",
      "Trainable params: 838,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 154us/step - loss: 0.5269 - val_loss: 0.4279\n",
      "val_spearman-rho: 0.1919                                                                                                    \n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.4128 - val_loss: 0.4031\n",
      "val_spearman-rho: 0.2566                                                                                                    \n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3979 - val_loss: 0.3942\n",
      "val_spearman-rho: 0.294                                                                                                    \n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3900 - val_loss: 0.3890\n",
      "val_spearman-rho: 0.3166                                                                                                    \n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3845 - val_loss: 0.3849\n",
      "val_spearman-rho: 0.331                                                                                                    \n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3805 - val_loss: 0.3822\n",
      "val_spearman-rho: 0.3403                                                                                                    \n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3772 - val_loss: 0.3799\n",
      "val_spearman-rho: 0.3471                                                                                                    \n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3744 - val_loss: 0.3783\n",
      "val_spearman-rho: 0.3518                                                                                                    \n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3722 - val_loss: 0.3771\n",
      "val_spearman-rho: 0.3563                                                                                                    \n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3702 - val_loss: 0.3761\n",
      "val_spearman-rho: 0.3595                                                                                                    \n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3684 - val_loss: 0.3753\n",
      "val_spearman-rho: 0.3619                                                                                                    \n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3665 - val_loss: 0.3746\n",
      "val_spearman-rho: 0.3642                                                                                                    \n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3651 - val_loss: 0.3740\n",
      "val_spearman-rho: 0.366                                                                                                    \n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 120us/step - loss: 0.3638 - val_loss: 0.3735\n",
      "val_spearman-rho: 0.3674                                                                                                    \n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3626 - val_loss: 0.3732\n",
      "val_spearman-rho: 0.3687                                                                                                    \n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3616 - val_loss: 0.3729\n",
      "val_spearman-rho: 0.3696                                                                                                    \n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3605 - val_loss: 0.3726\n",
      "val_spearman-rho: 0.3708                                                                                                    \n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3597 - val_loss: 0.3723\n",
      "val_spearman-rho: 0.3714                                                                                                    \n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3584 - val_loss: 0.3723\n",
      "val_spearman-rho: 0.3718                                                                                                    \n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3576 - val_loss: 0.3721\n",
      "val_spearman-rho: 0.3725                                                                                                    \n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3567 - val_loss: 0.3720\n",
      "val_spearman-rho: 0.3729                                                                                                    \n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3559 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3732                                                                                                    \n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3554 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3738                                                                                                    \n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3543 - val_loss: 0.3720\n",
      "val_spearman-rho: 0.3738                                                                                                    \n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3536 - val_loss: 0.3718\n",
      "val_spearman-rho: 0.3742                                                                                                    \n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3531 - val_loss: 0.3720\n",
      "val_spearman-rho: 0.374                                                                                                    \n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3524 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3742                                                                                                    \n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3518 - val_loss: 0.3720\n",
      "val_spearman-rho: 0.3743                                                                                                    \n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3513 - val_loss: 0.3721\n",
      "val_spearman-rho: 0.3742                                                                                                    \n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3506 - val_loss: 0.3722\n",
      "val_spearman-rho: 0.3742                                                                                                    \n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3500 - val_loss: 0.3722\n",
      "Epoch 00030: early stopping Threshold\n",
      "val_spearman-rho: 0.3741                                                                                                    \n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 1606)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               822784    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 838,174\n",
      "Trainable params: 838,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4863 samples, validate on 1216 samples\n",
      "Epoch 1/100\n",
      "4863/4863 [==============================] - 1s 156us/step - loss: 0.5337 - val_loss: 0.4300\n",
      "val_spearman-rho: 0.2005                                                                                                    \n",
      "Epoch 2/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.4145 - val_loss: 0.4021\n",
      "val_spearman-rho: 0.2635                                                                                                    \n",
      "Epoch 3/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3986 - val_loss: 0.3928\n",
      "val_spearman-rho: 0.2947                                                                                                    \n",
      "Epoch 4/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3906 - val_loss: 0.3872\n",
      "val_spearman-rho: 0.316                                                                                                    \n",
      "Epoch 5/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3853 - val_loss: 0.3835\n",
      "val_spearman-rho: 0.3296                                                                                                    \n",
      "Epoch 6/100\n",
      "4863/4863 [==============================] - 1s 117us/step - loss: 0.3810 - val_loss: 0.3804\n",
      "val_spearman-rho: 0.339                                                                                                    \n",
      "Epoch 7/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3777 - val_loss: 0.3783\n",
      "val_spearman-rho: 0.3456                                                                                                    \n",
      "Epoch 8/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3749 - val_loss: 0.3767\n",
      "val_spearman-rho: 0.3513                                                                                                    \n",
      "Epoch 9/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3725 - val_loss: 0.3754\n",
      "val_spearman-rho: 0.3552                                                                                                    \n",
      "Epoch 10/100\n",
      "4863/4863 [==============================] - 1s 111us/step - loss: 0.3706 - val_loss: 0.3743\n",
      "val_spearman-rho: 0.3585                                                                                                    \n",
      "Epoch 11/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3687 - val_loss: 0.3736\n",
      "val_spearman-rho: 0.361                                                                                                    \n",
      "Epoch 12/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3672 - val_loss: 0.3730\n",
      "val_spearman-rho: 0.3631                                                                                                    \n",
      "Epoch 13/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3656 - val_loss: 0.3724\n",
      "val_spearman-rho: 0.365                                                                                                    \n",
      "Epoch 14/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3642 - val_loss: 0.3719\n",
      "val_spearman-rho: 0.3663                                                                                                    \n",
      "Epoch 15/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3631 - val_loss: 0.3717\n",
      "val_spearman-rho: 0.3674                                                                                                    \n",
      "Epoch 16/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3619 - val_loss: 0.3713\n",
      "val_spearman-rho: 0.3684                                                                                                    \n",
      "Epoch 17/100\n",
      "4863/4863 [==============================] - 1s 122us/step - loss: 0.3610 - val_loss: 0.3711\n",
      "val_spearman-rho: 0.3691                                                                                                    \n",
      "Epoch 18/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3599 - val_loss: 0.3710\n",
      "val_spearman-rho: 0.3699                                                                                                    \n",
      "Epoch 19/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3590 - val_loss: 0.3709\n",
      "val_spearman-rho: 0.3705                                                                                                    \n",
      "Epoch 20/100\n",
      "4863/4863 [==============================] - 1s 118us/step - loss: 0.3582 - val_loss: 0.3707\n",
      "val_spearman-rho: 0.3708                                                                                                    \n",
      "Epoch 21/100\n",
      "4863/4863 [==============================] - 1s 113us/step - loss: 0.3572 - val_loss: 0.3706\n",
      "val_spearman-rho: 0.3712                                                                                                    \n",
      "Epoch 22/100\n",
      "4863/4863 [==============================] - 1s 114us/step - loss: 0.3564 - val_loss: 0.3706\n",
      "val_spearman-rho: 0.3715                                                                                                    \n",
      "Epoch 23/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3558 - val_loss: 0.3706\n",
      "val_spearman-rho: 0.3717                                                                                                    \n",
      "Epoch 24/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3551 - val_loss: 0.3706\n",
      "val_spearman-rho: 0.3721                                                                                                    \n",
      "Epoch 25/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3541 - val_loss: 0.3705\n",
      "val_spearman-rho: 0.3722                                                                                                    \n",
      "Epoch 26/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3533 - val_loss: 0.3707\n",
      "val_spearman-rho: 0.3722                                                                                                    \n",
      "Epoch 27/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3529 - val_loss: 0.3707\n",
      "val_spearman-rho: 0.3725                                                                                                    \n",
      "Epoch 28/100\n",
      "4863/4863 [==============================] - 1s 116us/step - loss: 0.3523 - val_loss: 0.3707\n",
      "val_spearman-rho: 0.3724                                                                                                    \n",
      "Epoch 29/100\n",
      "4863/4863 [==============================] - 1s 119us/step - loss: 0.3517 - val_loss: 0.3708\n",
      "val_spearman-rho: 0.3723                                                                                                    \n",
      "Epoch 30/100\n",
      "4863/4863 [==============================] - 1s 112us/step - loss: 0.3512 - val_loss: 0.3707\n",
      "val_spearman-rho: 0.3724                                                                                                    \n",
      "Epoch 31/100\n",
      "4863/4863 [==============================] - 1s 115us/step - loss: 0.3504 - val_loss: 0.3710\n",
      "Epoch 00030: early stopping Threshold\n",
      "val_spearman-rho: 0.3722                                                                                                    \n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 1606)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               822784    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 838,174\n",
      "Trainable params: 838,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 4864 samples, validate on 1215 samples\n",
      "Epoch 1/100\n",
      "4864/4864 [==============================] - 1s 160us/step - loss: 0.5203 - val_loss: 0.4261\n",
      "val_spearman-rho: 0.1921                                                                                                    \n",
      "Epoch 2/100\n",
      "4864/4864 [==============================] - 1s 118us/step - loss: 0.4122 - val_loss: 0.4022\n",
      "val_spearman-rho: 0.2507                                                                                                    \n",
      "Epoch 3/100\n",
      "4864/4864 [==============================] - 1s 119us/step - loss: 0.3976 - val_loss: 0.3937\n",
      "val_spearman-rho: 0.2837                                                                                                    \n",
      "Epoch 4/100\n",
      "4864/4864 [==============================] - 1s 116us/step - loss: 0.3898 - val_loss: 0.3888\n",
      "val_spearman-rho: 0.3052                                                                                                    \n",
      "Epoch 5/100\n",
      "4864/4864 [==============================] - 1s 121us/step - loss: 0.3844 - val_loss: 0.3852\n",
      "val_spearman-rho: 0.3195                                                                                                    \n",
      "Epoch 6/100\n",
      "4864/4864 [==============================] - 1s 116us/step - loss: 0.3801 - val_loss: 0.3827\n",
      "val_spearman-rho: 0.3293                                                                                                    \n",
      "Epoch 7/100\n",
      "4864/4864 [==============================] - 1s 114us/step - loss: 0.3768 - val_loss: 0.3807\n",
      "val_spearman-rho: 0.3365                                                                                                    \n",
      "Epoch 8/100\n",
      "4864/4864 [==============================] - 1s 120us/step - loss: 0.3739 - val_loss: 0.3792\n",
      "val_spearman-rho: 0.3426                                                                                                    \n",
      "Epoch 9/100\n",
      "4864/4864 [==============================] - 1s 116us/step - loss: 0.3716 - val_loss: 0.3779\n",
      "val_spearman-rho: 0.3474                                                                                                    \n",
      "Epoch 10/100\n",
      "4864/4864 [==============================] - 1s 116us/step - loss: 0.3695 - val_loss: 0.3769\n",
      "val_spearman-rho: 0.3512                                                                                                    \n",
      "Epoch 11/100\n",
      "4864/4864 [==============================] - 1s 121us/step - loss: 0.3678 - val_loss: 0.3762\n",
      "val_spearman-rho: 0.3542                                                                                                    \n",
      "Epoch 12/100\n",
      "4864/4864 [==============================] - 1s 121us/step - loss: 0.3662 - val_loss: 0.3756\n",
      "val_spearman-rho: 0.3568                                                                                                    \n",
      "Epoch 13/100\n",
      "4864/4864 [==============================] - 1s 116us/step - loss: 0.3646 - val_loss: 0.3752\n",
      "val_spearman-rho: 0.3588                                                                                                    \n",
      "Epoch 14/100\n",
      "4864/4864 [==============================] - 1s 119us/step - loss: 0.3634 - val_loss: 0.3746\n",
      "val_spearman-rho: 0.3605                                                                                                    \n",
      "Epoch 15/100\n",
      "4864/4864 [==============================] - 1s 113us/step - loss: 0.3621 - val_loss: 0.3743\n",
      "val_spearman-rho: 0.362                                                                                                    \n",
      "Epoch 16/100\n",
      "4864/4864 [==============================] - 1s 116us/step - loss: 0.3611 - val_loss: 0.3741\n",
      "val_spearman-rho: 0.3629                                                                                                    \n",
      "Epoch 17/100\n",
      "4864/4864 [==============================] - 1s 120us/step - loss: 0.3600 - val_loss: 0.3739\n",
      "val_spearman-rho: 0.3638                                                                                                    \n",
      "Epoch 18/100\n",
      "4864/4864 [==============================] - 1s 118us/step - loss: 0.3590 - val_loss: 0.3736\n",
      "val_spearman-rho: 0.3646                                                                                                    \n",
      "Epoch 19/100\n",
      "4864/4864 [==============================] - 1s 116us/step - loss: 0.3580 - val_loss: 0.3735\n",
      "val_spearman-rho: 0.3651                                                                                                    \n",
      "Epoch 20/100\n",
      "4864/4864 [==============================] - 1s 113us/step - loss: 0.3572 - val_loss: 0.3736\n",
      "val_spearman-rho: 0.3656                                                                                                    \n",
      "Epoch 21/100\n",
      "4864/4864 [==============================] - 1s 111us/step - loss: 0.3563 - val_loss: 0.3735\n",
      "val_spearman-rho: 0.3657                                                                                                    \n",
      "Epoch 22/100\n",
      "4864/4864 [==============================] - 1s 119us/step - loss: 0.3555 - val_loss: 0.3734\n",
      "val_spearman-rho: 0.3661                                                                                                    \n",
      "Epoch 23/100\n",
      "4864/4864 [==============================] - 1s 113us/step - loss: 0.3548 - val_loss: 0.3733\n",
      "val_spearman-rho: 0.3666                                                                                                    \n",
      "Epoch 24/100\n",
      "4864/4864 [==============================] - 1s 118us/step - loss: 0.3542 - val_loss: 0.3734\n",
      "val_spearman-rho: 0.3666                                                                                                    \n",
      "Epoch 25/100\n",
      "4864/4864 [==============================] - 1s 115us/step - loss: 0.3532 - val_loss: 0.3734\n",
      "val_spearman-rho: 0.3669                                                                                                    \n",
      "Epoch 26/100\n",
      "4864/4864 [==============================] - 1s 113us/step - loss: 0.3526 - val_loss: 0.3736\n",
      "val_spearman-rho: 0.3669                                                                                                    \n",
      "Epoch 27/100\n",
      "4864/4864 [==============================] - 1s 113us/step - loss: 0.3521 - val_loss: 0.3736\n",
      "val_spearman-rho: 0.3667                                                                                                    \n",
      "Epoch 28/100\n",
      "4864/4864 [==============================] - 1s 116us/step - loss: 0.3512 - val_loss: 0.3737\n",
      "val_spearman-rho: 0.3667                                                                                                    \n",
      "Epoch 29/100\n",
      "4864/4864 [==============================] - 1s 113us/step - loss: 0.3507 - val_loss: 0.3740\n",
      "val_spearman-rho: 0.3668                                                                                                    \n",
      "Epoch 30/100\n",
      "4864/4864 [==============================] - 1s 115us/step - loss: 0.3502 - val_loss: 0.3740\n",
      "Epoch 00029: early stopping Threshold\n",
      "val_spearman-rho: 0.3666                                                                                                    \n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 1606)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 512)               822784    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 30)                15390     \n",
      "=================================================================\n",
      "Total params: 838,174\n",
      "Trainable params: 838,174\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for ind, (tr, val) in enumerate(kf.split(X_train)):\n",
    "    X_tr = X_train[tr]\n",
    "    y_tr = y_train[tr]\n",
    "    X_vl = X_train[val]\n",
    "    y_vl = y_train[val]\n",
    "    \n",
    "    model = create_model()\n",
    "    model.fit(\n",
    "        X_tr, y_tr, epochs=100, batch_size=32, validation_data=(X_vl, y_vl), verbose=True, \n",
    "        callbacks=[SpearmanRhoCallback(training_data=(X_tr, y_tr), validation_data=(X_vl, y_vl),\n",
    "                                       patience=5, model_name=u'best_model_batch.h5')]\n",
    "    )\n",
    "    model.load_weights('best_model_batch.h5')\n",
    "    all_predictions.append(model.predict(X_test))\n",
    "    \n",
    "    os.remove('best_model_batch.h5')\n",
    "    \n",
    "model = create_model()\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, verbose=False)\n",
    "all_predictions.append(model.predict(X_test))\n",
    "    \n",
    "kf = KFold(n_splits=5, random_state=2019, shuffle=True)\n",
    "for ind, (tr, val) in enumerate(kf.split(X_train)):\n",
    "    X_tr = X_train[tr]\n",
    "    y_tr = y_train[tr]\n",
    "    X_vl = X_train[val]\n",
    "    y_vl = y_train[val]\n",
    "    \n",
    "    model = MultiTaskElasticNet(alpha=0.001, random_state=42, l1_ratio=0.5)\n",
    "    model.fit(X_tr, y_tr)\n",
    "    all_predictions.append(model.predict(X_test))\n",
    "    \n",
    "model = MultiTaskElasticNet(alpha=0.001, random_state=42, l1_ratio=0.5)\n",
    "model.fit(X_train, y_train)\n",
    "all_predictions.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = np.array([np.array([rankdata(c) for c in p.T]).T for p in all_predictions]).mean(axis=0)\n",
    "max_val = test_preds.max() + 1\n",
    "test_preds = test_preds/max_val + 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column_ind in range(y_train.shape[1]):\n",
    "    curr_column = y_train[:, column_ind]\n",
    "    values = np.unique(curr_column)\n",
    "    map_quantiles = []\n",
    "    for val in values:\n",
    "        occurrence = np.mean(curr_column == val)\n",
    "        cummulative = sum(el['occurrence'] for el in map_quantiles)\n",
    "        map_quantiles.append({'value': val, 'occurrence': occurrence, 'cummulative': cummulative})\n",
    "            \n",
    "    for quant in map_quantiles:\n",
    "        pred_col = test_preds[:, column_ind]\n",
    "        q1, q2 = np.quantile(pred_col, quant['cummulative']), np.quantile(pred_col, min(quant['cummulative'] + quant['occurrence'], 1))\n",
    "        pred_col[(pred_col >= q1) & (pred_col <= q2)] = quant['value']\n",
    "        test_preds[:, column_ind] = pred_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.805031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.319706</td>\n",
       "      <td>0.384696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.740042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.438679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.456848</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.440950</td>\n",
       "      <td>0.620545</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.787212</td>\n",
       "      <td>0.319008</td>\n",
       "      <td>0.187107</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.294549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.386094</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.292103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.419637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.551712</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665618</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.634521</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.849581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             1.000000                0.777778   \n",
       "1     46                             1.000000                0.438679   \n",
       "2     70                             1.000000                0.666667   \n",
       "3    132                             0.386094                0.555556   \n",
       "4    200                             1.000000                0.419637   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.333333                           1.0   \n",
       "1                 0.000000                           1.0   \n",
       "2                 0.000000                           1.0   \n",
       "3                 0.000000                           1.0   \n",
       "4                 0.000000                           1.0   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               1.000000                                    1.0   \n",
       "1               1.000000                                    1.0   \n",
       "2               1.000000                                    1.0   \n",
       "3               1.000000                                    1.0   \n",
       "4               0.551712                                    1.0   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.666667                       0.555556   \n",
       "1                         0.456848                       0.444444   \n",
       "2                         0.666667                       0.444444   \n",
       "3                         0.555556                       0.444444   \n",
       "4                         0.777778                       1.000000   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.333333  ...               0.805031        1.000000   \n",
       "1               0.000000  ...               0.440950        0.620545   \n",
       "2               0.666667  ...               0.787212        0.319008   \n",
       "3               0.666667  ...               0.292103        1.000000   \n",
       "4               0.666667  ...               0.665618        1.000000   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.319706          0.384696               1.0   \n",
       "1                     0.777778          1.000000               1.0   \n",
       "2                     0.187107          1.000000               1.0   \n",
       "3                     0.777778          1.000000               1.0   \n",
       "4                     0.777778          1.000000               1.0   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             1.000000                  0.333333               0.333333   \n",
       "1             1.000000                  1.000000               0.333333   \n",
       "2             1.000000                  0.333333               0.333333   \n",
       "3             1.000000                  0.666667               0.333333   \n",
       "4             0.634521                  0.333333               0.333333   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        1.000000             0.740042  \n",
       "1                        0.000000             0.777778  \n",
       "2                        1.000000             0.294549  \n",
       "3                        1.000000             0.777778  \n",
       "4                        0.666667             0.849581  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(path_join(data_dir, 'sample_submission.csv'))\n",
    "submission[targets] = test_preds\n",
    "submission.to_csv(\"submission.csv\", index = False)\n",
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
