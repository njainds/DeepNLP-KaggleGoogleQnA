# 5 fold roberta-base, question_answer, seed 2345
python swa-k-fold.py --model_type "bert" --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 0 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python swa-k-fold.py --model_type "bert" --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 1 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python swa-k-fold.py --model_type "bert" --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 2 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python swa-k-fold.py --model_type "bert" --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 3 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python swa-k-fold.py --model_type "bert" --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 4 --seed 2345 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain


# 5 fold roberta-base, question + answer, seed 123
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 0 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 1 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 2 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 3 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python training-k-fold.py --model_type "bert" --max_len 512 --content "Question" --model_name "roberta-base" --fold 4 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain

python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 0 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 1 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 2 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 3 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
python training-k-fold.py --model_type "bert" --max_len 512 --content "Answer" --model_name "roberta-base" --fold 4 --seed 123 --n_splits 5 --batch_size 8 --valid_batch_size 32 --accumulation_steps 1 --lr 5e-7 --split "GroupKfold" --loss "bce" --augment --num_epoch 3 --num_workers 4 --load_pretrain
