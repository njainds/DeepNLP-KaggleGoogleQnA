# google_quest_qa
kaggle
different varieties of models with SWA, correction for robert and xlnet, re-shuffling of batch at every epoch

# 0.401 sudo python3 train_model.py --model_name "bert-base-uncased" --content "Question_Answer" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 4 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#sudo python3 train_model.py --model_name "bert-base-cased" --content "Question_Answer" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 4 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#sudo python3 train_model.py --model_name "bert-base-uncased" --content "Question_Answer" --lr_scheduler "WarmRestart" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 4 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#sudo python3 train_model.py --model_name "bert-base-uncased" --content "Question_Answer" --lr_scheduler "WarmRestart" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 8 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#sudo python3 train_model.py --model_name "roberta-base" --content "Question_Answer" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 4 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#sudo python3 train_model.py --model_type "xlnet" --model_name "xlnet-base-cased" --content "Question_Answer" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 4 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#sudo python3 train_model.py --model_name "bert-large-uncased" --content "Question_Answer" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 2 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#sudo python3 train_model.py --model_type "xlnet" --model_name "xlnet-large-cased" --content "Question_Answer" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 4 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#sudo python3 train_model.py --model_name "bert-base-uncased" --extra_token --content "Question_Answer" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 4 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
#0.407 sudo python3 train_model.py --model_name "bert-base-uncased" --content "Question_Answer" --max_len 512 --fold 0 --seed 2020 --split "MultilabelStratifiedKFold" --n_splits 10 --batch_size 8 --valid_batch_size 32 --accumulation_steps 2 --lr 1e-4 --loss "bce" --augment --num_epoch 8 --num_workers 4
