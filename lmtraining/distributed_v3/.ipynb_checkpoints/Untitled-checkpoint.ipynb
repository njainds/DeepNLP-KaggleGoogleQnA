{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Documents\\Nitin\\mycodes\\kaggle_google_quest_qna\\lmtraining\\distributed_v3\\code\\source_dir_v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir(os.getcwd() + '\\\\codesource_dir_v2')\n",
    "print(os.getcwd())\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "# from callbacks import CSVParamLogger\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "import time\n",
    "from transformers import BertConfig, BertForPreTraining\n",
    "from transformers import AdamW, BertTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "# from apex import amp\n",
    "# from apex.parallel import DistributedDataParallel as DDP\n",
    "# from apex.optimizers import FusedAdam\n",
    "# from apex.normalization.fused_layer_norm import FusedLayerNorm\n",
    "import logging\n",
    "import warnings\n",
    "#import horovod.torch as hvd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from model_dataset import QuestDataset\n",
    "from utils.loss_function import *\n",
    "from utils.metric import *\n",
    "from utils.lrs_scheduler import *\n",
    "from utils.file import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackx_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                            | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "arduino.stackexchange.com:   0%|                                                                 | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "arduino.stackexchange.com:  12%|███████▏                                                 | 1/8 [00:00<00:01,  5.65it/s]\u001b[A\n",
      "3dprinting.stackexchange.com:  12%|██████▊                                               | 1/8 [00:00<00:01,  5.65it/s]\u001b[A\n",
      "3dprinting.stackexchange.com:  25%|█████████████▌                                        | 2/8 [00:00<00:00,  6.10it/s]\u001b[A\n",
      "anime.stackexchange.com:  25%|██████████████▊                                            | 2/8 [00:00<00:00,  6.10it/s]\u001b[A\n",
      "anime.stackexchange.com:  38%|██████████████████████▏                                    | 3/8 [00:00<00:00,  6.20it/s]\u001b[A\n",
      "apple.stackexchange.com:  38%|██████████████████████▏                                    | 3/8 [00:00<00:00,  6.20it/s]\u001b[A\n",
      "apple.stackexchange.com:  50%|█████████████████████████████▌                             | 4/8 [00:00<00:00,  4.12it/s]\u001b[A\n",
      "android.stackexchange.com:  50%|████████████████████████████▌                            | 4/8 [00:00<00:00,  4.12it/s]\u001b[A\n",
      "android.stackexchange.com:  62%|███████████████████████████████████▋                     | 5/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "askubuntu.com:  62%|███████████████████████████████████████████▏                         | 5/8 [00:01<00:00,  3.99it/s]\u001b[A\n",
      "askubuntu.com:  75%|███████████████████████████████████████████████████▊                 | 6/8 [00:02<00:01,  1.88it/s]\u001b[A\n",
      "ai.stackexchange.com:  75%|██████████████████████████████████████████████▌               | 6/8 [00:02<00:01,  1.88it/s]\u001b[A\n",
      "ai.stackexchange.com:  88%|██████████████████████████████████████████████████████▎       | 7/8 [00:02<00:00,  2.41it/s]\u001b[A\n",
      "academia.stackexchange.com:  88%|█████████████████████████████████████████████████       | 7/8 [00:02<00:00,  2.41it/s]\u001b[A\n",
      "academia.stackexchange.com: 100%|████████████████████████████████████████████████████████| 8/8 [00:02<00:00,  2.95it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "#stackx_data = pd.read_csv( \"./data/input/qa_stackexchange_cleaned.csv\", nrows=600000)\n",
    "TARGETS = ['question_score','question_views','question_favs','answer_score','is_answer_accepted']\n",
    "stackx_data[\"question_title\"] = stackx_data[\"question_title\"].astype(str)\n",
    "stackx_data[\"question_body\"] = stackx_data[\"question_body\"].astype(str)\n",
    "stackx_data[\"answer\"] = stackx_data[\"answer\"].astype(str)\n",
    "# print(stackx_data.shape)\n",
    "\n",
    "\n",
    "# Normalize aux targets\n",
    "encoded = []\n",
    "trange = tqdm(stackx_data[\"host\"].unique())\n",
    "for host in trange:\n",
    "    host_mask = stackx_data[\"host\"] == host\n",
    "    trange.set_description(str(host))\n",
    "    host_labels = deepcopy(stackx_data[host_mask][TARGETS])\n",
    "    for col in [\"question_score\", \"question_views\", \"question_favs\", \"answer_score\"]:\n",
    "        host_labels[col] = rankdata(stackx_data[host_mask][col]) / host_mask.sum()\n",
    "    encoded.append(host_labels)\n",
    "\n",
    "encoded = pd.concat(encoded, sort=False).reindex(stackx_data.index)\n",
    "stackx_data[encoded.columns] = encoded\n",
    "\n",
    "\n",
    "# Train-Val Split\n",
    "train_df, test_df = train_test_split(stackx_data, test_size=0.1, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'host', 'question_username', 'question_score', 'question_views',\n",
       "       'question_favs', 'answers_count', 'answers_max_score',\n",
       "       'answers_mean_score', 'question_title', 'question_body',\n",
       "       'answer_username', 'answer', 'answer_score', 'is_answer_accepted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestMLMDataset(QuestDataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128, content=\"Question_Answer\", mlm_prob=0.15,\n",
    "                 non_masked_idx=-1, sop_prob=0.5, target_cols=TARGETS):\n",
    "        super(QuestMLMDataset, self).__init__(df=df, target_cols=target_cols, max_len=max_len, content=content,\n",
    "                                              tokenizer=tokenizer)\n",
    "        self.mlm_probability = mlm_prob\n",
    "        self.sop_prob = sop_prob\n",
    "        self.non_masked_idx = non_masked_idx\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cls_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.cls_token)\n",
    "        self.sep_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.sep_token)\n",
    "        self.mask_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    def _mask_tokens(self, inputs, masked_random_replace_prob=0.2):\n",
    "        labels = inputs.clone()\n",
    "        masked_indices = torch.bernoulli(torch.full(labels.shape, self.mlm_probability)).bool()\n",
    "        for special_tokens in [self.cls_token_idx, self.sep_token_idx, self.mask_token_idx]:\n",
    "            masked_indices &= inputs != special_tokens\n",
    "        labels[~masked_indices] = self.non_masked_idx\n",
    "        indices_replaced = (\n",
    "                    torch.bernoulli(torch.full(labels.shape, 1 - masked_random_replace_prob)).bool() & masked_indices)\n",
    "        inputs[indices_replaced] = self.mask_token_idx\n",
    "        indices_random = (torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced)\n",
    "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
    "        inputs[indices_random] = random_words[indices_random]\n",
    "        return inputs, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title, body, answer = self._get_text(index)\n",
    "        numeric_targets = self.get_label(index)\n",
    "        sop_label = 0\n",
    "        if np.random.uniform(0, 1) < self.sop_prob:\n",
    "            sop_label = 1\n",
    "            perm = list(np.random.permutation(range(3)))\n",
    "            if perm == [0, 1, 2]:\n",
    "                perm = [0, 2, 1]\n",
    "            title, body, answer = [[title, body, answer][i] for i in perm]\n",
    "        input_ids, token_type_ids, attention_mask = self.get_token_ids(title, body, answer)\n",
    "        input_ids, token_type_ids, attention_mask = map(torch.LongTensor, [input_ids, token_type_ids, attention_mask])\n",
    "        input_ids, labels = self._mask_tokens(torch.LongTensor(input_ids))\n",
    "        return ((input_ids, token_type_ids, attention_mask), (labels, sop_label, numeric_targets))\n",
    "\n",
    "\n",
    "class BertPretrain(BertForPreTraining):\n",
    "    def __init__(self, config, num_labels):\n",
    "        super(BertPretrain, self).__init__(config, )\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "        logits = self.classifier(self.dropout(torch.mean(sequence_output, dim=1)))\n",
    "        pred_scores, seq_rel_score = self.cls(sequence_output, pooled_output)\n",
    "        outputs = (pred_scores, seq_rel_score, logits,pooled_output)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def spearmanr(y_true, y_pred):\n",
    "    corr = [spearmanr(pred_col, act_col).correlation for pred_col, act_col in zip(y_pred.T, y_true.T)]\n",
    "    return np.nanmean(corr)\n",
    "\n",
    "\n",
    "# Loss\n",
    "class MLMloss(nn.CrossEntropyLoss):\n",
    "    def forward(self, logits, targets):\n",
    "        n_samples = np.prod(targets.shape)\n",
    "        loss = super(MLMloss, self).forward(logits.view(n_samples, -1), targets.view(n_samples))\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SOPloss(nn.CrossEntropyLoss):\n",
    "    def forward(self, logits, targets):\n",
    "        n_samples = np.prod(targets.shape)\n",
    "        loss = super(SOPloss, self).forward(logits.view(-1, 2), targets.view(-1))\n",
    "        return loss\n",
    "\n",
    "\n",
    "class PretrainingLoss(torch.nn.Module):\n",
    "    def __init__(self, targets_alpha=1.0):\n",
    "        super(PretrainingLoss, self).__init__()\n",
    "        self.mlm_loss = MLMloss(ignore_index=-1)\n",
    "        self.sop_loss = SOPloss()\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss()\n",
    "        self.targets_alpha = targets_alpha\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        return (\n",
    "                self.mlm_loss(logits[0], targets[0])\n",
    "                + self.sop_loss(logits[1], targets[1])\n",
    "                + self.targets_alpha * self.bce(logits[2], targets[2])\n",
    "        )\n",
    "\n",
    "\n",
    "class MLMPerplexity(MLMloss):\n",
    "    __name__ = \"mlm_perplexity\"\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        logits, targets = logits[0], targets[0]\n",
    "        loss = super(MLMPerplexity, self).forward(logits, targets)\n",
    "        perplexity = 2 ** loss\n",
    "        return float(perplexity)\n",
    "\n",
    "\n",
    "def sop_accuracy(logits, targets):\n",
    "    logits, targets = logits[1], targets[1]\n",
    "    pred = torch.argmax(logits.view(-1, 2), dim=-1)\n",
    "    targets = targets.view(-1)\n",
    "    return float(torch.mean((pred == targets).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(str(\"C:/Users/admin/Documents/Nitin/mycodes/kaggle_google_quest_qna/lmtraining/distributed_v3/data/input/data/vocab.txt\"), do_basic_tokenize=True, do_lower_case=False)\n",
    "train_dataset = QuestMLMDataset(train_df, tokenizer, target_cols=TARGETS)\n",
    "val_dataset = QuestMLMDataset(test_df, tokenizer, target_cols=TARGETS)\n",
    "config = BertConfig.from_json_file(str( \"C:/Users/admin/Documents/Nitin/mycodes/kaggle_google_quest_qna/lmtraining/distributed_v3/data/input/data/config.json\"))\n",
    "model = BertPretrain(config, len(TARGETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_bert = BertForPreTraining.from_pretrained(\"bert-base-cased\")\n",
    "orig_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "state_dict = orig_bert.state_dict()\n",
    "del state_dict[\"cls.predictions.decoder.weight\"], state_dict[\"cls.predictions.bias\"], state_dict[\n",
    "    \"cls.predictions.decoder.bias\"]\n",
    "orig_embedding = state_dict[\"bert.embeddings.word_embeddings.weight\"]\n",
    "extra_tokens = list(tokenizer.vocab.keys())[len(orig_tokenizer.vocab):]\n",
    "new_tokens_as_orig_indices = [[i] for i in range(len(orig_tokenizer.vocab))] + [\n",
    "    orig_tokenizer.encode(t, add_special_tokens=False) for t in extra_tokens]\n",
    "new_embedding = torch.zeros(len(new_tokens_as_orig_indices), orig_embedding.shape[-1])\n",
    "new_embedding.normal_(mean=0.0, std=0.02)\n",
    "for row, indices in enumerate(new_tokens_as_orig_indices):\n",
    "    if len(indices) > 0:\n",
    "        new_embedding[row] = orig_embedding[indices].mean(0)\n",
    "state_dict[\"bert.embeddings.word_embeddings.weight\"] = new_embedding\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.tie_weights()\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8)\n",
    "#Keeping validation as non-distributed\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_batch_i\n"
     ]
    }
   ],
   "source": [
    "for tr_batch_i, (inputs, targets) in enumerate(train_loader):\n",
    "    if tr_batch_i==21:\n",
    "        print('tr_batch_i')\n",
    "        input_ids, token_type_ids, attention_mask = inputs\n",
    "        targets_mlm, targets_sop, targets_extra = targets\n",
    "        logits = model(input_ids, token_type_ids, attention_mask)\n",
    "        logits_mlm, logits_sop, logits_extra = logits\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlm_loss = MLMloss(ignore_index=-1)(logits_mlm, targets_mlm).item()\n",
    "sop_loss = SOPloss()(logits_sop, targets_sop).item()\n",
    "mlm_perplexity = MLMPerplexity(ignore_index=-1)((logits_mlm, logits_sop, logits_extra),(targets_mlm, targets_sop, targets_extra))\n",
    "sop_acc = sop_accuracy((logits_mlm, logits_sop, logits_extra),(targets_mlm, targets_sop,targets_extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 5])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "10.573634147644043\n",
      "2.6019551753997803\n",
      "1523.9862060546875\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(targets_mlm.shape)\n",
    "print(targets_sop.shape)\n",
    "print(targets_extra.shape)\n",
    "print(input_ids.shape)\n",
    "print(token_type_ids.shape)\n",
    "print(attention_mask.shape)\n",
    "print(mlm_loss)\n",
    "print(sop_loss)\n",
    "print(mlm_perplexity)\n",
    "print(sop_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.8911, -2.1035],\n",
       "        [ 3.1024, -2.4086],\n",
       "        [ 3.1619, -2.5610],\n",
       "        [ 3.7053, -3.1655],\n",
       "        [ 2.1620, -1.1883],\n",
       "        [ 2.5203, -1.5912],\n",
       "        [ 2.9326, -2.0579],\n",
       "        [ 3.5572, -3.1209]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "w = model.cls.seq_relationship.state_dict()['weight']\n",
    "b = model.cls.seq_relationship.state_dict()['bias']\n",
    "print(w.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1449, -0.1398]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand((1,768))\n",
    "output = torch.mm(x,torch.transpose(w,0,1)) + b\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
