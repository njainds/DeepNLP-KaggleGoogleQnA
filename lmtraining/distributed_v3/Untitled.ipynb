{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Documents\\Nitin\\mycodes\\kaggle_google_quest_qna\\lmtraining\\distributed_v3\\code\\source_dir_v2\n",
      "matplotlib.get_backend :  module://ipykernel.pylab.backend_inline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(os.getcwd() + '\\\\code\\\\source_dir_v2')\n",
    "print(os.getcwd())\n",
    "from copy import deepcopy\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import torch\n",
    "# from callbacks import CSVParamLogger\n",
    "from scipy.stats import spearmanr, rankdata\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data.sampler import RandomSampler, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "import time\n",
    "from transformers import BertConfig, BertForPreTraining\n",
    "from transformers import AdamW, BertTokenizer, get_linear_schedule_with_warmup\n",
    "\n",
    "# from apex import amp\n",
    "# from apex.parallel import DistributedDataParallel as DDP\n",
    "# from apex.optimizers import FusedAdam\n",
    "# from apex.normalization.fused_layer_norm import FusedLayerNorm\n",
    "import logging\n",
    "import warnings\n",
    "#import horovod.torch as hvd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from model_dataset import QuestDataset\n",
    "from utils.loss_function import *\n",
    "from utils.metric import *\n",
    "from utils.lrs_scheduler import *\n",
    "from utils.file import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stackx_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\admin\\\\Documents\\\\Nitin\\\\mycodes\\\\kaggle_google_quest_qna\\\\lmtraining\\\\distributed_v3\\\\code\\\\source_dir_v2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "arduino.stackexchange.com: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 13.32it/s]\n"
     ]
    }
   ],
   "source": [
    "stackx_data = pd.read_csv( \"C:/Users/admin/Documents/Nitin/mycodes/kaggle_google_quest_qna/lmtraining/distributed_v3/data/input/qa_stackexchange_cleaned.csv\", nrows=20000)\n",
    "TARGETS = ['question_score','question_views','question_favs','answer_score','is_answer_accepted']\n",
    "stackx_data[\"question_title\"] = stackx_data[\"question_title\"].astype(str)\n",
    "stackx_data[\"question_body\"] = stackx_data[\"question_body\"].astype(str)\n",
    "stackx_data[\"answer\"] = stackx_data[\"answer\"].astype(str)\n",
    "# print(stackx_data.shape)\n",
    "\n",
    "\n",
    "# Normalize aux targets\n",
    "encoded = []\n",
    "trange = tqdm(stackx_data[\"host\"].unique())\n",
    "for host in trange:\n",
    "    host_mask = stackx_data[\"host\"] == host\n",
    "    trange.set_description(str(host))\n",
    "    host_labels = deepcopy(stackx_data[host_mask][TARGETS])\n",
    "    for col in [\"question_score\", \"question_views\", \"question_favs\", \"answer_score\"]:\n",
    "        host_labels[col] = rankdata(stackx_data[host_mask][col]) / host_mask.sum()\n",
    "    encoded.append(host_labels)\n",
    "\n",
    "encoded = pd.concat(encoded, sort=False).reindex(stackx_data.index)\n",
    "stackx_data[encoded.columns] = encoded\n",
    "\n",
    "\n",
    "# Train-Val Split\n",
    "train_df, test_df = train_test_split(stackx_data, test_size=0.1, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'host', 'question_username', 'question_score', 'question_views',\n",
       "       'question_favs', 'answers_count', 'answers_max_score',\n",
       "       'answers_mean_score', 'question_title', 'question_body',\n",
       "       'answer_username', 'answer', 'answer_score', 'is_answer_accepted'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class QuestMLMDataset(QuestDataset):\n",
    "    def __init__(self, df, tokenizer, max_len=128, content=\"Question_Answer\", mlm_prob=0.15,\n",
    "                 non_masked_idx=-1, sop_prob=0.5, target_cols=TARGETS):\n",
    "        super(QuestMLMDataset, self).__init__(df=df, target_cols=target_cols, max_len=max_len, content=content,\n",
    "                                              tokenizer=tokenizer)\n",
    "        self.mlm_probability = mlm_prob\n",
    "        self.sop_prob = sop_prob\n",
    "        self.non_masked_idx = non_masked_idx\n",
    "        self.tokenizer = tokenizer\n",
    "        self.cls_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.cls_token)\n",
    "        self.sep_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.sep_token)\n",
    "        self.mask_token_idx = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)\n",
    "\n",
    "    def _mask_tokens(self, inputs, masked_random_replace_prob=0.2):\n",
    "        labels = inputs.clone()\n",
    "        masked_indices = torch.bernoulli(torch.full(labels.shape, self.mlm_probability)).bool()\n",
    "        for special_tokens in [self.cls_token_idx, self.sep_token_idx, self.mask_token_idx]:\n",
    "            masked_indices &= inputs != special_tokens\n",
    "        labels[~masked_indices] = self.non_masked_idx\n",
    "        indices_replaced = (\n",
    "                    torch.bernoulli(torch.full(labels.shape, 1 - masked_random_replace_prob)).bool() & masked_indices)\n",
    "        inputs[indices_replaced] = self.mask_token_idx\n",
    "        indices_random = (torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced)\n",
    "        random_words = torch.randint(len(self.tokenizer), labels.shape, dtype=torch.long)\n",
    "        inputs[indices_random] = random_words[indices_random]\n",
    "        return inputs, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        title, body, answer = self._get_text(index)\n",
    "        numeric_targets = self.get_label(index)\n",
    "        sop_label = 0\n",
    "        if np.random.uniform(0, 1) < self.sop_prob:\n",
    "            sop_label = 1\n",
    "            perm = list(np.random.permutation(range(3)))\n",
    "            if perm == [0, 1, 2]:\n",
    "                perm = [0, 2, 1]\n",
    "            title, body, answer = [[title, body, answer][i] for i in perm]\n",
    "        input_ids, token_type_ids, attention_mask = self.get_token_ids(title, body, answer)\n",
    "        input_ids, token_type_ids, attention_mask = map(torch.LongTensor, [input_ids, token_type_ids, attention_mask])\n",
    "        input_ids, labels = self._mask_tokens(torch.LongTensor(input_ids))\n",
    "        return ((input_ids, token_type_ids, attention_mask), (labels, sop_label, numeric_targets))\n",
    "\n",
    "\n",
    "class BertPretrain(BertForPreTraining):\n",
    "    def __init__(self, config, num_labels):\n",
    "        super(BertPretrain, self).__init__(config, )\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, num_labels)\n",
    "\n",
    "    def forward(self, input_ids=None, token_type_ids=None, attention_mask=None):\n",
    "        outputs = self.bert(input_ids, token_type_ids, attention_mask)\n",
    "        sequence_output, pooled_output = outputs[:2]\n",
    "        logits = self.classifier(self.dropout(torch.mean(sequence_output, dim=1)))\n",
    "        pred_scores, seq_rel_score = self.cls(sequence_output, pooled_output)\n",
    "        outputs = (pred_scores, seq_rel_score, logits,pooled_output)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "def spearmanr(y_true, y_pred):\n",
    "    corr = [spearmanr(pred_col, act_col).correlation for pred_col, act_col in zip(y_pred.T, y_true.T)]\n",
    "    return np.nanmean(corr)\n",
    "\n",
    "\n",
    "# Loss\n",
    "class MLMloss(nn.CrossEntropyLoss):\n",
    "    def forward(self, logits, targets):\n",
    "        n_samples = np.prod(targets.shape)\n",
    "        loss = super(MLMloss, self).forward(logits.view(n_samples, -1), targets.view(n_samples))\n",
    "        return loss\n",
    "\n",
    "\n",
    "class SOPloss(nn.CrossEntropyLoss):\n",
    "    def forward(self, logits, targets):\n",
    "        n_samples = np.prod(targets.shape)\n",
    "        loss = super(SOPloss, self).forward(logits.view(-1, 2), targets.view(-1))\n",
    "        return loss\n",
    "\n",
    "\n",
    "class PretrainingLoss(torch.nn.Module):\n",
    "    def __init__(self, targets_alpha=1.0):\n",
    "        super(PretrainingLoss, self).__init__()\n",
    "        self.mlm_loss = MLMloss(ignore_index=-1)\n",
    "        self.sop_loss = SOPloss()\n",
    "        self.bce = torch.nn.BCEWithLogitsLoss()\n",
    "        self.targets_alpha = targets_alpha\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        return (\n",
    "                self.mlm_loss(logits[0], targets[0])\n",
    "                + self.sop_loss(logits[1], targets[1])\n",
    "                + self.targets_alpha * self.bce(logits[2], targets[2])\n",
    "        )\n",
    "\n",
    "\n",
    "class MLMPerplexity(MLMloss):\n",
    "    __name__ = \"mlm_perplexity\"\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        logits, targets = logits[0], targets[0]\n",
    "        loss = super(MLMPerplexity, self).forward(logits, targets)\n",
    "        perplexity = 2 ** loss\n",
    "        return float(perplexity)\n",
    "\n",
    "\n",
    "def sop_accuracy(logits, targets):\n",
    "    logits, targets = logits[1], targets[1]\n",
    "    pred = torch.argmax(logits.view(-1, 2), dim=-1)\n",
    "    targets = targets.view(-1)\n",
    "    return float(torch.mean((pred == targets).float()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer(str(\"C:/Users/admin/Documents/Nitin/mycodes/kaggle_google_quest_qna/lmtraining/distributed_v3/data/input/data/vocab.txt\"), do_basic_tokenize=True, do_lower_case=False)\n",
    "train_dataset = QuestMLMDataset(train_df, tokenizer, target_cols=TARGETS)\n",
    "val_dataset = QuestMLMDataset(test_df, tokenizer, target_cols=TARGETS)\n",
    "config = BertConfig.from_json_file(str( \"C:/Users/admin/Documents/Nitin/mycodes/kaggle_google_quest_qna/lmtraining/distributed_v3/data/input/data/config.json\"))\n",
    "model = BertPretrain(config, len(TARGETS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0514 23:46:02.075158  2844 configuration_utils.py:256] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at C:\\Users\\admin\\.cache\\torch\\transformers\\b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.9da767be51e1327499df13488672789394e2ca38b877837e52618a67d7002391\n",
      "I0514 23:46:02.080227  2844 configuration_utils.py:292] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0514 23:46:06.070763  2844 modeling_utils.py:461] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at C:\\Users\\admin\\.cache\\torch\\transformers\\35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n",
      "I0514 23:46:13.128875  2844 modeling_utils.py:546] Weights of BertForPreTraining not initialized from pretrained model: ['cls.predictions.decoder.bias']\n",
      "I0514 23:46:15.150234  2844 tokenization_utils.py:501] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at C:\\Users\\admin\\.cache\\torch\\transformers\\5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n"
     ]
    }
   ],
   "source": [
    "orig_bert = BertForPreTraining.from_pretrained(\"bert-base-cased\")\n",
    "orig_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "state_dict = orig_bert.state_dict()\n",
    "del state_dict[\"cls.predictions.decoder.weight\"], state_dict[\"cls.predictions.bias\"], state_dict[\n",
    "    \"cls.predictions.decoder.bias\"]\n",
    "orig_embedding = state_dict[\"bert.embeddings.word_embeddings.weight\"]\n",
    "extra_tokens = list(tokenizer.vocab.keys())[len(orig_tokenizer.vocab):]\n",
    "new_tokens_as_orig_indices = [[i] for i in range(len(orig_tokenizer.vocab))] + [\n",
    "    orig_tokenizer.encode(t, add_special_tokens=False) for t in extra_tokens]\n",
    "new_embedding = torch.zeros(len(new_tokens_as_orig_indices), orig_embedding.shape[-1])\n",
    "new_embedding.normal_(mean=0.0, std=0.02)\n",
    "for row, indices in enumerate(new_tokens_as_orig_indices):\n",
    "    if len(indices) > 0:\n",
    "        new_embedding[row] = orig_embedding[indices].mean(0)\n",
    "state_dict[\"bert.embeddings.word_embeddings.weight\"] = new_embedding\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "model.tie_weights()\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8)\n",
    "#Keeping validation as non-distributed\n",
    "val_loader = DataLoader(val_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tr_batch_i\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for tr_batch_i, (inputs, targets) in enumerate(train_loader):\n",
    "    if tr_batch_i==0:\n",
    "        print('tr_batch_i')\n",
    "        input_ids, token_type_ids, attention_mask = inputs\n",
    "        targets_mlm, targets_sop, targets_extra = targets\n",
    "        logits = model(input_ids, token_type_ids, attention_mask)\n",
    "        logits_mlm, logits_sop, logits_extra, pooled = logits\n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 38071, 62599,  ...,  1115,   119,   102],\n",
       "        [  101, 59921,   103,  ...,  1208,   119,   102],\n",
       "        [  101, 14709,   170,  ...,   114,   119,   102],\n",
       "        ...,\n",
       "        [  101, 11193,   103,  ...,   108, 38262,   102],\n",
       "        [  101,   146,  1821,  ..., 51318,   136,   102],\n",
       "        [  101, 32492,   103,  ...,  1141,   136,   102]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlm_loss = MLMloss(ignore_index=-1)(logits_mlm, targets_mlm).item()\n",
    "sop_loss = SOPloss()(logits_sop, targets_sop).item()\n",
    "mlm_perplexity = MLMPerplexity(ignore_index=-1)((logits_mlm, logits_sop, logits_extra),(targets_mlm, targets_sop, targets_extra))\n",
    "sop_acc = sop_accuracy((logits_mlm, logits_sop, logits_extra),(targets_mlm, targets_sop,targets_extra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 128])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 5])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "torch.Size([8, 128])\n",
      "9.34911823272705\n",
      "1.567033052444458\n",
      "652.1763305664062\n",
      "0.625\n",
      "torch.Size([8, 128, 110000])\n",
      "torch.Size([8, 2])\n",
      "torch.Size([8, 5])\n"
     ]
    }
   ],
   "source": [
    "print(targets_mlm.shape)\n",
    "print(targets_sop.shape)\n",
    "print(targets_extra.shape)\n",
    "print(input_ids.shape)\n",
    "print(token_type_ids.shape)\n",
    "print(attention_mask.shape)\n",
    "print(mlm_loss)\n",
    "print(sop_loss)\n",
    "print(mlm_perplexity)\n",
    "print(sop_acc)\n",
    "print(logits_mlm.shape)\n",
    "print(logits_sop.shape)\n",
    "print(logits_extra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9986, -2.2750],\n",
       "        [ 2.6503, -1.8422],\n",
       "        [ 2.0961, -1.0245],\n",
       "        [ 2.1254, -1.1128],\n",
       "        [ 1.6194, -0.4749],\n",
       "        [ 3.0544, -2.1734],\n",
       "        [ 2.1251, -1.1417],\n",
       "        [ 3.2816, -2.4898]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_sop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 768])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "w = model.cls.seq_relationship.state_dict()['weight']\n",
    "b = model.cls.seq_relationship.state_dict()['bias']\n",
    "print(w.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.9986, -2.2750],\n",
       "        [ 2.6503, -1.8422],\n",
       "        [ 2.0961, -1.0245],\n",
       "        [ 2.1254, -1.1128],\n",
       "        [ 1.6194, -0.4749],\n",
       "        [ 3.0544, -2.1734],\n",
       "        [ 2.1251, -1.1417],\n",
       "        [ 3.2816, -2.4898]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.rand((1,768))\n",
    "output = torch.mm(pooled,torch.transpose(w,0,1)) + b\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6431,  0.5832,  0.9989, -0.8948,  0.7898, -0.3820,  0.8346, -0.8237,\n",
      "        -0.6892, -0.4968,  0.8630,  0.9191, -0.8367, -0.9983, -0.7681, -0.7107,\n",
      "         0.8587, -0.5896, -0.9994,  0.4606,  0.0474, -0.9979,  0.5147,  0.2998,\n",
      "         0.6597, -0.1198,  0.8687,  0.9991,  0.5288,  0.2529,  0.1140, -0.8886,\n",
      "        -0.2462, -0.9789,  0.2963, -0.2580, -0.1181, -0.2651, -0.3137, -0.0101,\n",
      "        -0.1880,  0.5700, -0.0327, -0.4400, -0.1142, -0.1373,  0.2286, -0.1764,\n",
      "        -0.2754,  0.9999, -0.8045,  0.9998, -0.8261,  0.9822,  0.8720,  0.1916,\n",
      "         0.8933,  0.1491, -0.8682,  0.2915,  0.6768,  0.0044,  0.6759, -0.3878,\n",
      "        -0.5226,  0.6660, -0.2957,  0.3238, -0.0159,  0.0717, -0.0425,  0.4768,\n",
      "         0.8646, -0.7591,  0.0161, -0.7480,  0.7355, -0.9990,  0.8082,  0.9990,\n",
      "         0.1002, -0.9904,  0.8975, -0.3334,  0.1221, -0.7445, -0.8191, -0.9893,\n",
      "         0.1739, -0.2528, -0.1109, -0.8420, -0.1446,  0.4793,  0.9994, -0.1870,\n",
      "        -0.3045,  0.2573,  0.0875,  0.1870, -0.1907,  0.3016,  0.8500, -0.5811,\n",
      "         0.8149, -0.2535, -0.5888,  0.3258, -0.5988,  0.3349,  0.7577, -0.8103,\n",
      "         0.0780,  0.2824, -0.1146, -0.0829,  0.8746, -0.3457, -0.3505,  0.9996,\n",
      "        -0.4362, -0.2546,  0.9563, -0.5584,  0.1486, -0.3279,  0.1946, -0.6952,\n",
      "         0.3793, -0.4126,  0.6693, -0.8825, -0.7707,  0.9901, -0.4007,  0.9993,\n",
      "        -0.9828,  0.5345, -0.9990, -0.5169,  0.0541, -0.3932,  0.0553,  0.3921,\n",
      "         0.7141,  0.3208,  0.0749,  0.6052,  0.2780,  0.1166,  0.3490,  0.5634,\n",
      "        -0.7324,  0.9997,  0.8156,  0.0639,  0.2373,  0.3416,  0.6748,  0.1925,\n",
      "         0.6742, -0.9829, -0.5087, -0.5865,  0.9949,  0.8658, -0.2232, -0.7724,\n",
      "         0.9985,  0.4654, -0.0187, -0.3023, -0.2416, -0.8590,  0.3717,  0.4041,\n",
      "         0.6262,  0.9988, -0.9279,  0.9994,  0.9987, -0.0895,  0.5988,  0.8296,\n",
      "        -0.9003, -0.7521, -0.8082,  0.4741, -0.7720, -0.3244,  0.1760,  0.7869,\n",
      "         0.8021,  0.0833, -0.9957, -0.2259,  0.7698, -0.4940,  0.9989,  0.5614,\n",
      "        -0.9950,  0.3388, -0.4384,  0.3172, -0.2708,  0.6800,  0.0336, -0.0228,\n",
      "         0.7430, -0.9996,  0.7674, -0.6033, -0.7742,  0.6306,  0.8326,  0.5267,\n",
      "        -0.1933,  0.3505, -0.1056,  0.9980, -0.9934, -0.0265,  0.1421, -0.9433,\n",
      "        -0.9358,  0.7741, -0.2039,  0.1033, -0.4037, -0.8099,  0.1416,  0.2354,\n",
      "         0.8842,  0.3765,  0.6321, -0.9964, -0.6614, -0.3901,  0.1547,  0.1469,\n",
      "         0.6750, -0.4601, -0.5135, -0.7827,  0.8562,  0.2155,  0.2935, -0.2754,\n",
      "         0.2712, -0.7483, -0.6152,  0.4357, -0.9922,  0.9900,  0.3932,  0.7471,\n",
      "         0.7203, -0.8838,  0.3117, -0.8602, -0.2976, -0.9990, -0.3248, -0.5768,\n",
      "         0.4545, -0.1660,  0.8336, -0.6436,  0.0867, -0.4081, -0.9987,  0.7125,\n",
      "        -0.1335,  0.9749, -0.5562,  0.5658,  0.8519,  0.2585, -0.8201, -0.9952,\n",
      "        -0.0942,  0.9993, -0.9256, -0.2340,  0.9978, -0.8101, -0.4235, -0.8114,\n",
      "        -0.8323, -0.9858, -0.0383, -0.0619,  0.0521,  0.7803, -0.2269,  0.0699,\n",
      "         0.8729,  0.9773, -0.0320,  0.3191,  0.3213, -0.8857, -0.9994, -0.5236,\n",
      "         0.2553, -0.9995,  0.9975, -0.6604,  0.9994, -0.1227, -0.8006,  0.6088,\n",
      "        -0.0345, -0.0047,  0.2227,  0.9974,  0.7889, -0.2795,  0.2112,  0.3403,\n",
      "         0.1447, -0.4333,  0.3732,  0.1137,  0.2759, -0.6746,  0.2167, -0.1716,\n",
      "        -0.8720,  0.6754,  0.1279,  0.2926,  0.1614,  0.4403,  0.8661, -0.2144,\n",
      "         0.1278,  0.1355, -0.9987, -0.6165,  0.2070, -0.8448,  0.4006, -0.1672,\n",
      "         0.8235, -0.6150,  0.9862, -0.1352, -0.0934, -0.7538,  0.9997, -0.9483,\n",
      "         0.2624, -0.3424, -0.0930,  0.4852,  0.8896,  0.8088,  0.3934,  0.2836,\n",
      "        -0.0030,  0.4870,  0.7964, -0.2168, -0.1884, -0.8794,  0.6543,  0.9863,\n",
      "         0.8106, -0.1931, -0.4420, -0.8156,  0.5980,  0.3530,  0.5323, -0.1319,\n",
      "        -0.2923, -0.3165,  0.8102,  0.2757,  0.1503,  0.2652, -0.8258,  0.3696,\n",
      "        -0.0606,  0.9939, -0.8059, -0.1752,  0.7730, -0.4043, -0.3049,  0.2392,\n",
      "         0.7904, -0.6280, -0.4108, -0.9855, -0.2053, -0.6248,  0.2422,  0.6835,\n",
      "        -0.0450,  0.1548,  0.1702, -0.0432,  0.2578,  0.2705,  0.6394, -0.0472,\n",
      "        -0.1086, -0.3892,  0.4035,  0.4398,  0.0567,  0.8272, -0.5517,  0.9991,\n",
      "        -0.0682, -0.9985, -0.7479,  0.5348, -0.9996, -0.6298, -0.9611,  0.7737,\n",
      "        -0.2458, -0.7772, -0.8731, -0.9734, -0.9977, -0.2858, -0.2581, -0.2898,\n",
      "        -0.7312,  0.9983, -0.0242,  0.3839, -0.0858, -0.6868, -0.1597, -0.7623,\n",
      "        -0.0487, -0.9990,  0.6784,  0.7707, -0.8446,  0.2813, -0.8356, -0.4745,\n",
      "        -0.6185,  0.2330,  0.8247,  0.0716,  0.5126, -0.9996,  0.8870,  0.0556,\n",
      "         0.0574,  0.0383, -0.8058,  0.9957, -0.0377,  0.1027, -0.1298, -0.9936,\n",
      "         0.3942, -0.2917,  0.3049, -0.8558,  0.1592, -0.7327, -0.9984,  0.2347,\n",
      "         0.7480,  0.9731,  0.8243,  0.3129, -0.4005, -0.5430,  0.3345, -0.9989,\n",
      "         0.0109,  0.0039, -0.6379,  0.4699,  0.5761,  0.7621,  0.2866,  0.0335,\n",
      "        -0.5110,  0.5623,  0.6274,  0.7217, -0.0855,  0.5100, -0.2536, -0.7867,\n",
      "        -0.7121,  0.9394, -0.8572,  0.2770,  0.4216,  0.8097,  0.1636, -0.1929,\n",
      "        -0.1760, -0.9967, -0.3200, -0.0865, -0.9984,  0.9990, -0.9995,  0.1993,\n",
      "         0.6469, -0.2619,  0.8875,  0.0762, -0.9982, -0.9980, -0.2491, -0.1132,\n",
      "         0.8569,  0.0300,  0.2146,  0.3304, -0.1667,  0.9195,  0.3756,  0.4397,\n",
      "        -0.8144,  0.9915,  0.1106, -0.9585,  0.5736, -0.9958,  0.4055,  0.8533,\n",
      "         0.7802,  0.8328, -0.8289,  0.9994, -0.9985,  0.9619, -0.9994, -0.8348,\n",
      "         0.9949, -0.8198,  0.4930, -0.9940, -0.7793, -0.0460,  0.3055, -0.3814,\n",
      "         0.8477, -0.9973, -0.9439,  0.3316,  0.2885, -0.2401,  0.7211,  0.3348,\n",
      "         0.8345,  0.0094,  0.8041, -0.1777,  0.8497,  0.9984,  0.5953,  0.0011,\n",
      "        -0.8816,  0.8031,  0.3669,  0.2448,  0.6804, -0.0057,  0.4628,  0.4090,\n",
      "        -0.9412,  0.0733, -0.8997,  0.5655, -0.3458,  0.6799,  0.3458,  0.0447,\n",
      "         0.2228, -0.8859,  0.5393, -0.9930,  0.8176,  0.1969,  0.2349, -0.4229,\n",
      "         0.7033, -0.3353,  0.9937,  0.9622, -0.9997,  0.2766,  0.8383,  0.4240,\n",
      "         0.8075, -0.8637, -0.1443,  0.1204, -0.5885,  0.8189,  0.1334, -0.4080,\n",
      "         0.7480, -0.9059, -0.0584, -0.4752, -0.0479, -0.0934, -0.7614,  0.0351,\n",
      "         0.5344,  0.3318, -0.9926, -0.3032, -0.9792, -0.2553,  0.7953,  0.2900,\n",
      "         0.9980, -0.1505,  0.0229, -0.1043, -0.9920, -0.8210,  0.1800, -0.2029,\n",
      "        -0.0112,  0.8141,  0.3015, -0.4665, -0.9994,  0.4634,  0.6443,  0.4522,\n",
      "         0.5968, -0.0872, -0.5226,  0.0402, -0.1048,  0.2270,  0.2417, -0.4370,\n",
      "         0.3581,  0.0713,  0.9993, -0.9305, -0.7458, -0.8566,  0.0078, -0.1837,\n",
      "         0.3948,  0.4068,  0.4259,  0.3954,  0.0047,  0.9209, -0.9029, -0.9362,\n",
      "         0.9958, -0.3617, -0.6632, -0.2340, -0.3552, -0.2164, -0.0383,  0.2313,\n",
      "        -0.2207, -0.3060, -0.9753, -0.1224,  0.4338, -0.6896, -0.4209, -0.2959,\n",
      "        -0.9998,  0.8763,  0.8187,  0.9988, -0.9945,  0.5113,  0.1934,  0.9776,\n",
      "         0.2650, -0.3765, -0.5410,  0.9936,  0.6690, -0.1336, -0.0023, -0.3447,\n",
      "        -0.1787, -0.5357,  0.8269,  0.0641,  0.1334, -0.8459, -0.9990,  0.9993,\n",
      "        -0.2150,  0.9123,  0.4483,  0.1325, -0.4421,  0.3608,  0.1448, -0.6667,\n",
      "        -0.9995,  0.1146, -0.9998, -0.9110, -0.0874,  0.7125, -0.9944, -0.6036,\n",
      "        -0.0412, -0.9995,  0.1913, -0.1939,  0.2198, -0.8351,  0.8214, -0.2558,\n",
      "         0.7680,  0.6785, -0.7877, -0.1390, -0.3812,  0.9904,  0.3146,  0.2322,\n",
      "         0.3023, -0.5137,  0.3813, -0.7980, -0.3175, -0.8569, -0.5789,  0.9214,\n",
      "         0.7677, -0.9960, -0.9044,  0.7165, -0.7005,  0.8741, -0.6125, -0.9976,\n",
      "        -0.9981,  0.4018, -0.2389,  0.8458, -0.2449,  0.9996,  0.5141,  0.3132,\n",
      "        -0.0792,  0.2642, -0.0029,  0.0733, -0.3415,  0.9993,  0.5188,  0.8771],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([-0.4721,  0.4917,  0.9993, -0.9371,  0.8155,  0.0561,  0.6142, -0.8864,\n",
      "        -0.7192, -0.4086,  0.8549,  0.9795, -0.9563, -0.9987, -0.4413, -0.7582,\n",
      "         0.9413, -0.5797, -0.9997,  0.4775, -0.0493, -0.9986,  0.5406,  0.7419,\n",
      "         0.6941, -0.0177,  0.7911,  0.9997,  0.0626,  0.4911,  0.1117, -0.9311,\n",
      "         0.0114, -0.9904,  0.3209, -0.0660, -0.0422, -0.2832,  0.3841, -0.5843,\n",
      "        -0.2785,  0.6669,  0.2286, -0.5500,  0.2762, -0.3039,  0.2936, -0.0268,\n",
      "        -0.2902,  0.9999, -0.6615,  0.9988, -0.8692,  0.9705,  0.9396,  0.3460,\n",
      "         0.9571,  0.2372, -0.9525,  0.3660,  0.8191,  0.0219,  0.2609, -0.7466,\n",
      "        -0.5238,  0.5354, -0.2866,  0.3822,  0.1058, -0.1865, -0.4258,  0.4962,\n",
      "         0.8663, -0.7863, -0.0415, -0.6979,  0.8390, -0.9994,  0.5255,  0.9994,\n",
      "        -0.0847, -0.9965,  0.9379, -0.3022,  0.1394, -0.3831, -0.9492, -0.9955,\n",
      "         0.1008, -0.3505,  0.1887, -0.8644, -0.0285, -0.0049,  0.9997, -0.1839,\n",
      "        -0.3302,  0.2544,  0.6307, -0.2999, -0.5525,  0.6097,  0.9379, -0.8154,\n",
      "         0.9419, -0.1077, -0.7435, -0.3073,  0.0269,  0.3353,  0.8603, -0.7064,\n",
      "        -0.5179,  0.2294,  0.6299, -0.1907,  0.9191, -0.3885, -0.3508,  0.9998,\n",
      "        -0.2242,  0.1636,  0.9820, -0.4839,  0.0716, -0.3992,  0.3436, -0.3340,\n",
      "         0.2640, -0.4638,  0.7138, -0.9459, -0.9115,  0.9947, -0.4034,  0.9997,\n",
      "        -0.9939,  0.8721, -0.9994, -0.6139,  0.2758, -0.1634, -0.5603,  0.6962,\n",
      "         0.7776,  0.2398, -0.3181,  0.5133,  0.5693, -0.1424,  0.1791,  0.6547,\n",
      "        -0.7048,  0.9971,  0.9394,  0.5589,  0.6183,  0.3088, -0.0491,  0.0633,\n",
      "         0.6000, -0.9930,  0.2077, -0.8423,  0.9960,  0.8918,  0.1021, -0.8898,\n",
      "         0.9988,  0.1691,  0.0848, -0.6367, -0.1410, -0.9461,  0.3851,  0.4353,\n",
      "         0.5428,  0.9991, -0.9594,  0.9993,  0.9950, -0.1230,  0.5694,  0.9642,\n",
      "        -0.9572, -0.7851, -0.8830,  0.6612, -0.4853,  0.2676,  0.3459,  0.7626,\n",
      "         0.9258, -0.0765, -0.9926, -0.3830,  0.8325, -0.2246,  0.9996,  0.5869,\n",
      "        -0.9978,  0.1040, -0.0550,  0.6239, -0.2618,  0.7742, -0.2656,  0.1693,\n",
      "         0.8896, -0.9971,  0.9099, -0.2837, -0.4942,  0.5896,  0.8923,  0.0340,\n",
      "        -0.3355,  0.3142, -0.1144,  0.9992, -0.9964, -0.0798,  0.3111, -0.9736,\n",
      "        -0.9811,  0.8436, -0.1723, -0.3473, -0.2042, -0.7935,  0.2224,  0.5046,\n",
      "         0.9229,  0.2986,  0.0519, -0.9984, -0.8353, -0.1235, -0.0932,  0.2174,\n",
      "         0.6742, -0.4873, -0.6237, -0.9390,  0.8819, -0.2020, -0.0449,  0.4379,\n",
      "         0.4310, -0.8793, -0.2202, -0.1127, -0.9928,  0.9959,  0.3607,  0.9052,\n",
      "         0.8557, -0.9313,  0.4116, -0.9524, -0.1706, -0.9948,  0.0621, -0.2117,\n",
      "         0.6328, -0.1643,  0.9349, -0.5302, -0.3201, -0.0516, -0.9992,  0.8204,\n",
      "        -0.2738,  0.9882, -0.5743,  0.8589,  0.8591,  0.5674, -0.8668, -0.9982,\n",
      "         0.2460,  0.9957, -0.9589, -0.4128,  0.9993, -0.9418, -0.5814, -0.8592,\n",
      "        -0.8977, -0.9943, -0.0946, -0.0269,  0.0507,  0.8313, -0.1250,  0.1102,\n",
      "         0.9367,  0.9395, -0.0642,  0.3600,  0.3220, -0.8583, -0.9959, -0.5405,\n",
      "         0.2998, -0.9997,  0.9985, -0.8780,  0.9967,  0.2508, -0.9143,  0.4980,\n",
      "        -0.0538, -0.3999,  0.2359,  0.9990,  0.8952, -0.3460,  0.2418,  0.2206,\n",
      "         0.0912, -0.1791,  0.1772, -0.1889,  0.2069, -0.7228,  0.7077, -0.1903,\n",
      "        -0.9279,  0.9225,  0.1768,  0.5538, -0.0016,  0.5102,  0.9084, -0.2993,\n",
      "         0.2780,  0.1955, -0.9895, -0.8062,  0.1006, -0.9294,  0.2621,  0.5428,\n",
      "         0.8868, -0.7589,  0.9735, -0.0902,  0.5967, -0.9303,  0.9998, -0.9499,\n",
      "         0.3361, -0.0983, -0.0597,  0.3666,  0.9170,  0.8411,  0.7319, -0.4080,\n",
      "        -0.5250,  0.2010,  0.8368, -0.4092, -0.0355, -0.9589,  0.3095,  0.9903,\n",
      "         0.9270, -0.2187, -0.7119, -0.9432,  0.5236, -0.1723,  0.2276, -0.2206,\n",
      "        -0.4522,  0.3168,  0.9569,  0.1637,  0.3090,  0.2550, -0.8568,  0.6468,\n",
      "         0.4409,  0.9983, -0.8586,  0.4221,  0.8741, -0.3837, -0.4153,  0.4378,\n",
      "         0.9600, -0.6542, -0.2890, -0.9959,  0.0093, -0.7310,  0.4345,  0.4574,\n",
      "         0.0694, -0.0830,  0.4067, -0.1363,  0.3711,  0.0728,  0.7447, -0.2772,\n",
      "        -0.2382, -0.3913,  0.2342,  0.5068, -0.0984,  0.8636, -0.5301,  0.9994,\n",
      "         0.1539, -0.9995, -0.8924,  0.4120, -0.9997, -0.5609, -0.9672,  0.8592,\n",
      "         0.0153, -0.9402, -0.9594, -0.9819, -0.9905, -0.3149, -0.3669, -0.2288,\n",
      "        -0.8168,  0.9871,  0.1579, -0.1294, -0.1759, -0.4621, -0.3418, -0.9189,\n",
      "         0.3835, -0.9995,  0.1269,  0.9156, -0.9286, -0.2932, -0.8458,  0.3680,\n",
      "        -0.7496,  0.4171,  0.8875,  0.0552,  0.2503, -0.9997,  0.8742, -0.0291,\n",
      "         0.0939, -0.6156, -0.8659,  0.9979,  0.2533,  0.0239, -0.1325, -0.9936,\n",
      "         0.6578, -0.5252, -0.4170, -0.8994,  0.1061, -0.6050, -0.9991,  0.4255,\n",
      "         0.8858,  0.9530,  0.9210,  0.0815, -0.4076, -0.7546,  0.2611, -0.9995,\n",
      "         0.2266,  0.4650, -0.7582,  0.3149,  0.8353,  0.8675, -0.3324, -0.6255,\n",
      "         0.3615,  0.2361,  0.3117,  0.6616, -0.3451,  0.5310, -0.3014, -0.8860,\n",
      "        -0.6856,  0.9751, -0.9402,  0.5318,  0.8285,  0.9455,  0.3627, -0.1791,\n",
      "        -0.5096, -0.9905,  0.0694,  0.0583, -0.9993,  0.9991, -0.9997,  0.1264,\n",
      "         0.1648,  0.0791,  0.9447,  0.0361, -0.9990, -0.9991, -0.8281,  0.0629,\n",
      "         0.9129,  0.0893,  0.2513,  0.2908, -0.6558,  0.9617,  0.2341,  0.2413,\n",
      "        -0.9246,  0.9961,  0.2485, -0.9866,  0.8378, -0.9979,  0.5393,  0.9000,\n",
      "         0.8183,  0.8295, -0.9355,  0.9997, -0.9986,  0.9501, -0.9997, -0.9513,\n",
      "         0.9985, -0.8881,  0.5453, -0.9966, -0.9281, -0.5646,  0.3303, -0.4497,\n",
      "         0.9210, -0.9972, -0.9800,  0.1135,  0.0374, -0.6520,  0.8884,  0.2473,\n",
      "         0.9251,  0.0946,  0.8622,  0.0352,  0.9459,  0.9936,  0.2111,  0.1165,\n",
      "        -0.9545,  0.8258,  0.2805,  0.3519,  0.8274, -0.0681,  0.1347,  0.4946,\n",
      "        -0.9796,  0.2162, -0.7504,  0.6680, -0.0622,  0.7432,  0.2886, -0.0315,\n",
      "         0.0142, -0.9338,  0.6307, -0.9950,  0.6674, -0.2738,  0.1160, -0.4286,\n",
      "         0.7591, -0.6207,  0.9974,  0.9875, -0.9974,  0.2648,  0.9049,  0.2914,\n",
      "         0.8294, -0.9282, -0.0120,  0.7102, -0.2940,  0.8658,  0.2401, -0.3825,\n",
      "         0.9176, -0.9597,  0.1178, -0.4282, -0.0546, -0.1445, -0.8454,  0.0750,\n",
      "         0.7603,  0.1171, -0.9969, -0.0727, -0.9940, -0.2313,  0.8683,  0.8512,\n",
      "         0.9991, -0.2814, -0.0650,  0.0023, -0.9981, -0.9544,  0.2201, -0.1947,\n",
      "         0.1809,  0.9452, -0.0245, -0.3784, -0.9996,  0.3813,  0.9060,  0.3848,\n",
      "         0.3281, -0.1690, -0.5534, -0.4905,  0.0139,  0.2935,  0.1369, -0.5279,\n",
      "         0.4033, -0.2694,  0.9996, -0.9781, -0.6969, -0.9059,  0.1562, -0.2667,\n",
      "         0.4509,  0.2590,  0.3859,  0.6229, -0.5299,  0.9736, -0.9723, -0.9611,\n",
      "         0.9983, -0.3132, -0.8418, -0.2276, -0.4664, -0.1922, -0.1492,  0.3410,\n",
      "        -0.1823, -0.0792, -0.9726, -0.2615,  0.2081, -0.6910, -0.4186, -0.4509,\n",
      "        -0.9985,  0.9455,  0.8867,  0.9993, -0.9980,  0.7616,  0.1547,  0.9902,\n",
      "        -0.0233, -0.5383, -0.1226,  0.9975,  0.4013, -0.1401, -0.0250, -0.3129,\n",
      "         0.0193, -0.6798,  0.9193, -0.3689,  0.0603, -0.8455, -0.9995,  0.9993,\n",
      "        -0.1633,  0.9504,  0.3749,  0.1407, -0.4331,  0.7478, -0.4603, -0.6161,\n",
      "        -0.9997,  0.2262, -0.9990, -0.9378,  0.0687,  0.8705, -0.9973, -0.7015,\n",
      "        -0.1253, -0.9998, -0.0791, -0.7688, -0.0490, -0.9286,  0.9210,  0.0812,\n",
      "         0.5278,  0.8269, -0.8308,  0.3368, -0.4190,  0.9636,  0.3968,  0.2789,\n",
      "         0.1501, -0.7671, -0.2439, -0.8221, -0.2178, -0.9409, -0.0445,  0.9691,\n",
      "         0.8912, -0.9968, -0.9435,  0.8709, -0.7178,  0.9338, -0.3582, -0.9988,\n",
      "        -0.9991,  0.2235, -0.0597,  0.9427, -0.3885,  0.9985,  0.3479,  0.1973,\n",
      "        -0.5148, -0.4084, -0.1873, -0.3010, -0.3718,  0.9995,  0.2514,  0.9531],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([-0.1782,  0.3868,  0.9931, -0.7480,  0.3852, -0.2141,  0.1229, -0.8848,\n",
      "         0.2189, -0.3820,  0.3620,  0.8183, -0.9378, -0.9801, -0.4404, -0.2495,\n",
      "         0.6210, -0.3694, -0.9969, -0.2379,  0.0981, -0.9872,  0.3871,  0.5840,\n",
      "        -0.1927, -0.1702,  0.4423,  0.9950, -0.1799,  0.2894,  0.1186, -0.7772,\n",
      "         0.0618, -0.9498,  0.1642, -0.1700,  0.0115, -0.1469,  0.0653, -0.2060,\n",
      "         0.0285,  0.2230,  0.1170, -0.4347, -0.0933, -0.5344,  0.3104, -0.2037,\n",
      "        -0.2218,  0.9989, -0.2167,  0.9435, -0.9048,  0.6766,  0.5082, -0.0041,\n",
      "         0.7175,  0.1919, -0.9349,  0.1466,  0.3161,  0.0711,  0.0569, -0.5213,\n",
      "        -0.6151,  0.7545, -0.0558,  0.3939,  0.3335, -0.0640, -0.6417,  0.3163,\n",
      "         0.4483, -0.3508,  0.0950, -0.5406,  0.7419, -0.9929,  0.2306,  0.9933,\n",
      "         0.0194, -0.9743,  0.7209, -0.2884,  0.0670, -0.5166, -0.9688, -0.9557,\n",
      "        -0.1467,  0.1801,  0.2457, -0.5843, -0.2017,  0.0820,  0.9937, -0.1506,\n",
      "        -0.2723,  0.0274,  0.5571, -0.1295, -0.2375,  0.5608,  0.9614, -0.9267,\n",
      "         0.9411,  0.0042, -0.2386, -0.1708, -0.6551,  0.2814,  0.3356, -0.1275,\n",
      "        -0.3755,  0.1412,  0.1027, -0.3393,  0.6628,  0.2098, -0.2043,  0.9971,\n",
      "        -0.2066,  0.3895,  0.8578, -0.3096,  0.1497, -0.3797,  0.0827, -0.4456,\n",
      "         0.3625,  0.0457,  0.4584, -0.7447, -0.9230,  0.9597, -0.3094,  0.9941,\n",
      "        -0.9152,  0.7691, -0.9928, -0.7370,  0.1805, -0.3764, -0.5699,  0.1608,\n",
      "         0.0673,  0.1318, -0.1910,  0.7017,  0.2005,  0.2309,  0.2640,  0.5869,\n",
      "        -0.1912,  0.9372,  0.9198,  0.3961,  0.2998,  0.3134, -0.2617,  0.1089,\n",
      "        -0.3178, -0.9371, -0.5227, -0.8333,  0.9671,  0.6401,  0.0634, -0.9337,\n",
      "         0.9893,  0.4889, -0.0890, -0.2188, -0.2091, -0.9657,  0.1426,  0.4353,\n",
      "         0.2700,  0.9875, -0.7767,  0.9935,  0.9075,  0.0780,  0.2557,  0.9536,\n",
      "        -0.7476, -0.4085, -0.5401,  0.6340, -0.4616,  0.2168,  0.2946,  0.6029,\n",
      "         0.9519, -0.5539, -0.9778, -0.1594,  0.4952, -0.2604,  0.9921,  0.8439,\n",
      "        -0.9806,  0.0820, -0.0800, -0.5245, -0.1337, -0.1252, -0.1060, -0.0831,\n",
      "         0.8776, -0.9466,  0.9577, -0.6573, -0.6050,  0.2811,  0.3806,  0.2150,\n",
      "        -0.2678,  0.2793, -0.0298,  0.9869, -0.9680,  0.1678, -0.0296, -0.9060,\n",
      "        -0.8558,  0.4593, -0.0686,  0.0343, -0.1536, -0.7732,  0.1810,  0.4047,\n",
      "         0.7402,  0.1779,  0.3730, -0.9873, -0.9103,  0.1270, -0.2567,  0.0363,\n",
      "         0.5014, -0.3600, -0.1325, -0.9677,  0.6101,  0.2446,  0.2827, -0.2055,\n",
      "         0.1504, -0.9333, -0.1566, -0.1618, -0.9396,  0.9557,  0.3401,  0.9127,\n",
      "         0.2817, -0.6822,  0.3690, -0.9678, -0.3813, -0.8511, -0.0895, -0.4237,\n",
      "         0.4935, -0.2291,  0.6727,  0.1881,  0.0987, -0.0433, -0.9933,  0.3556,\n",
      "        -0.0088,  0.9235, -0.1345,  0.4777,  0.3172,  0.6464, -0.7275, -0.9793,\n",
      "         0.2474,  0.9318, -0.7363, -0.2603,  0.9892, -0.9562,  0.0038, -0.5394,\n",
      "        -0.2282, -0.9413,  0.0637, -0.2294,  0.1979,  0.1557,  0.0273,  0.0908,\n",
      "         0.6725,  0.2782, -0.0415,  0.4100,  0.2464, -0.7045, -0.9640, -0.5581,\n",
      "         0.2238, -0.9955,  0.9841, -0.0622,  0.9081, -0.2821, -0.9468,  0.1460,\n",
      "        -0.0736, -0.4496,  0.1198,  0.9876,  0.2067, -0.2402,  0.0890,  0.0171,\n",
      "         0.1991, -0.1606,  0.4641, -0.0308,  0.1552, -0.2094,  0.5992, -0.1476,\n",
      "        -0.4488,  0.9215,  0.0837, -0.1122, -0.1849, -0.0155,  0.4721, -0.1106,\n",
      "         0.2105,  0.3808, -0.9597, -0.7430, -0.1002, -0.9127,  0.3851,  0.5369,\n",
      "         0.3743,  0.4153,  0.4605,  0.0380,  0.4763, -0.9622,  0.9974, -0.3243,\n",
      "         0.2995, -0.0891,  0.0748,  0.5452,  0.7027,  0.9083,  0.7265,  0.2792,\n",
      "        -0.2991, -0.3859,  0.2478, -0.3404, -0.2753, -0.9706,  0.7192,  0.9472,\n",
      "         0.9355, -0.0858, -0.5109, -0.9442, -0.1449,  0.1130, -0.0654, -0.2107,\n",
      "        -0.3951,  0.1376,  0.9636,  0.1244,  0.4827,  0.2603, -0.3302,  0.6375,\n",
      "         0.4953,  0.9742, -0.5226, -0.2046,  0.3581, -0.2480, -0.3621, -0.0742,\n",
      "         0.9597,  0.2715, -0.0559, -0.9485, -0.1551, -0.5102,  0.3983,  0.3726,\n",
      "         0.0138,  0.0684,  0.2104, -0.0572, -0.0704,  0.0426, -0.1011, -0.3025,\n",
      "        -0.1295, -0.3163,  0.2561,  0.4688, -0.0802,  0.5437, -0.0918,  0.9942,\n",
      "         0.0021, -0.9923, -0.9436,  0.1716, -0.9965, -0.5150, -0.6137,  0.4301,\n",
      "        -0.2929, -0.9648, -0.9704, -0.5507, -0.7288, -0.0600, -0.1836, -0.1354,\n",
      "        -0.8892,  0.9632, -0.0130,  0.3789, -0.0191, -0.0294,  0.1998, -0.9582,\n",
      "         0.4439, -0.9918,  0.4300,  0.8705, -0.9062, -0.0802, -0.5512,  0.4987,\n",
      "        -0.0940, -0.1039,  0.4441, -0.2628,  0.3236, -0.9952,  0.3981, -0.2195,\n",
      "        -0.0551, -0.5950, -0.3558,  0.9784, -0.3214, -0.0860, -0.0223, -0.9527,\n",
      "         0.5104, -0.4538, -0.1704, -0.4832,  0.0370,  0.0779, -0.9904,  0.2737,\n",
      "         0.9368,  0.4377,  0.7187,  0.0128, -0.2324, -0.1494,  0.1665, -0.9943,\n",
      "        -0.2498,  0.6219,  0.1496,  0.4211, -0.3488,  0.4884, -0.1842, -0.5067,\n",
      "        -0.2688,  0.3547, -0.0919,  0.6606,  0.0939,  0.4908, -0.0920, -0.5516,\n",
      "        -0.4045,  0.8113, -0.9762, -0.6972,  0.8316,  0.9480,  0.2357, -0.2547,\n",
      "        -0.4721, -0.7498, -0.0409, -0.0220, -0.9884,  0.9878, -0.9954, -0.2240,\n",
      "         0.5203,  0.0086,  0.7485,  0.1197, -0.9890, -0.9894, -0.0131,  0.0146,\n",
      "         0.4277,  0.0510, -0.0231,  0.1090, -0.3126,  0.6830,  0.2461,  0.4749,\n",
      "        -0.9694,  0.9690, -0.1697, -0.8709,  0.7328, -0.9779,  0.5581,  0.5392,\n",
      "         0.7703,  0.3397, -0.9624,  0.9948, -0.9890,  0.1565, -0.9949, -0.9734,\n",
      "         0.9779, -0.4950,  0.4618, -0.9656, -0.9147, -0.4373,  0.2934, -0.1914,\n",
      "         0.5078, -0.9698, -0.8750, -0.0221,  0.0488, -0.2113,  0.9139,  0.3439,\n",
      "         0.4964,  0.0957,  0.4749, -0.2134,  0.9155,  0.8342,  0.0742,  0.5141,\n",
      "        -0.7434,  0.5342, -0.0418,  0.0830,  0.4466, -0.0102,  0.6797,  0.4510,\n",
      "        -0.8372,  0.4579, -0.6294,  0.7263, -0.2056,  0.4544,  0.3277,  0.0351,\n",
      "         0.0394, -0.6470,  0.5415, -0.9545,  0.3874, -0.1627,  0.1415, -0.0949,\n",
      "         0.5333,  0.3584,  0.9749,  0.8977, -0.9405,  0.1527,  0.5491,  0.4716,\n",
      "         0.4276, -0.7151, -0.0510,  0.6255, -0.4233,  0.6128,  0.0795, -0.2907,\n",
      "         0.5801, -0.7100,  0.1045, -0.3109, -0.0343, -0.1515, -0.6347,  0.0276,\n",
      "         0.6944,  0.2242, -0.9625, -0.4229, -0.9428, -0.1373,  0.5894,  0.2244,\n",
      "         0.9859, -0.3174,  0.0383,  0.1117, -0.9694, -0.9688,  0.0787, -0.1350,\n",
      "         0.3692,  0.9675,  0.1478, -0.2814, -0.9953,  0.3333,  0.9074,  0.2324,\n",
      "         0.3352,  0.2234,  0.0581, -0.4250,  0.1900,  0.1886,  0.2854,  0.5369,\n",
      "         0.5183, -0.3168,  0.9954, -0.7938, -0.6821, -0.5644, -0.0013, -0.4630,\n",
      "         0.4546,  0.4481,  0.1018,  0.7206, -0.3554,  0.8455, -0.7752, -0.7939,\n",
      "         0.9832, -0.3381, -0.8936, -0.1619, -0.2457, -0.1681, -0.0873,  0.4226,\n",
      "         0.4758, -0.1226, -0.4888,  0.0227,  0.2820,  0.2078, -0.3251, -0.1249,\n",
      "        -0.9421,  0.6935,  0.6993,  0.9924, -0.9801,  0.3096,  0.2087,  0.9188,\n",
      "         0.1679, -0.2626, -0.1243,  0.9683,  0.5797,  0.1829, -0.1591, -0.0362,\n",
      "        -0.0741, -0.4014,  0.9486,  0.0046, -0.1437, -0.5291, -0.9936,  0.9912,\n",
      "        -0.0580,  0.7856,  0.2583, -0.3510,  0.3217,  0.6377, -0.3437, -0.1639,\n",
      "        -0.9935,  0.0535, -0.9373, -0.7599, -0.1142, -0.1279, -0.9646,  0.2885,\n",
      "        -0.0807, -0.9957,  0.2910, -0.5909, -0.2570, -0.5764,  0.9471,  0.1269,\n",
      "         0.5402,  0.3918, -0.2858,  0.3244, -0.1739,  0.9371,  0.2883,  0.2087,\n",
      "         0.2758, -0.8258, -0.0252, -0.5184, -0.0804, -0.6488,  0.0858,  0.8259,\n",
      "         0.4138, -0.9728, -0.7666,  0.8453, -0.5844,  0.7689, -0.3316, -0.9867,\n",
      "        -0.9863,  0.2302, -0.0986,  0.5074, -0.1412,  0.9707,  0.0419,  0.3040,\n",
      "        -0.2715, -0.3355, -0.3765,  0.1468, -0.2522,  0.9916,  0.1234,  0.6908],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([-0.4280,  0.4809,  0.9978, -0.8715,  0.7361,  0.3041,  0.3252, -0.9114,\n",
      "        -0.5344, -0.2689,  0.7501,  0.9544, -0.9804, -0.9970, -0.3162, -0.6054,\n",
      "         0.8603, -0.5273, -0.9991, -0.3360, -0.0534, -0.9968,  0.3839,  0.8354,\n",
      "         0.3384, -0.0586,  0.6128,  0.9989,  0.1209,  0.2688,  0.0388, -0.8717,\n",
      "         0.2926, -0.9802,  0.2673, -0.1098,  0.3372, -0.2180,  0.7046, -0.3755,\n",
      "        -0.1649, -0.3778,  0.2725, -0.6003,  0.4031, -0.4824,  0.3629, -0.0784,\n",
      "        -0.2382,  0.9995, -0.4204,  0.9827, -0.9346,  0.8657,  0.8326,  0.1350,\n",
      "         0.8868,  0.2028, -0.9672,  0.3262,  0.6152,  0.1705,  0.1670, -0.6421,\n",
      "        -0.6416,  0.7931, -0.5101,  0.3410,  0.3348, -0.1521, -0.4214,  0.3399,\n",
      "         0.7916, -0.7388,  0.0132, -0.7128,  0.8851, -0.9983,  0.3374,  0.9985,\n",
      "         0.2684, -0.9894,  0.8561, -0.0948, -0.1008, -0.1230, -0.9721, -0.9877,\n",
      "         0.0081, -0.2513,  0.4189, -0.7364, -0.0698, -0.4232,  0.9990, -0.0178,\n",
      "        -0.2184,  0.0848,  0.7054, -0.3724, -0.4879,  0.7909,  0.9634, -0.8888,\n",
      "         0.9581, -0.0718, -0.3875, -0.6599, -0.1708,  0.2616,  0.5943, -0.5762,\n",
      "        -0.6245,  0.0642,  0.7342, -0.3759,  0.8314,  0.2956, -0.1688,  0.9994,\n",
      "        -0.2309,  0.3541,  0.9593, -0.0571, -0.3173, -0.3424, -0.1147, -0.1422,\n",
      "         0.1591, -0.3365,  0.6135, -0.8904, -0.9441,  0.9905, -0.1964,  0.9990,\n",
      "        -0.9743,  0.8152, -0.9980, -0.7473, -0.0377, -0.2542, -0.5909,  0.4275,\n",
      "         0.5677,  0.1505, -0.4466,  0.4818,  0.2793, -0.3923,  0.0068,  0.6226,\n",
      "        -0.4564,  0.9777,  0.9657,  0.6530,  0.7285,  0.3513, -0.2005,  0.2323,\n",
      "         0.0864, -0.9819,  0.3354, -0.8339,  0.9906,  0.8074,  0.6340, -0.9560,\n",
      "         0.9974,  0.1232, -0.0827, -0.1916, -0.0814, -0.9701,  0.3293,  0.4124,\n",
      "         0.4503,  0.9977, -0.8913,  0.9978,  0.9538, -0.0376,  0.4345,  0.9719,\n",
      "        -0.9289, -0.6670, -0.8095,  0.6986, -0.3684,  0.5007,  0.2546,  0.6536,\n",
      "         0.9586, -0.3352, -0.9926, -0.2315,  0.7472, -0.2295,  0.9989,  0.7363,\n",
      "        -0.9951, -0.3727,  0.3096,  0.2287, -0.1604,  0.5369, -0.2901, -0.0447,\n",
      "         0.9446, -0.9731,  0.9604, -0.5143, -0.3410,  0.5447,  0.6677, -0.0711,\n",
      "        -0.1998,  0.3048, -0.3002,  0.9971, -0.9926,  0.1015,  0.1783, -0.9594,\n",
      "        -0.9531,  0.6745, -0.0557, -0.5602, -0.1126, -0.7625,  0.2313,  0.7195,\n",
      "         0.8732,  0.0785, -0.0507, -0.9959, -0.9248, -0.2916, -0.5509,  0.0849,\n",
      "         0.6114, -0.3988, -0.4329, -0.9717,  0.8029,  0.1752, -0.0167,  0.2015,\n",
      "         0.1271, -0.9352,  0.1794, -0.6009, -0.9881,  0.9909, -0.1074,  0.9321,\n",
      "         0.7017, -0.8545,  0.6238, -0.9758, -0.2150, -0.9547,  0.1607, -0.0204,\n",
      "         0.1086, -0.1872,  0.8384, -0.2214, -0.2282,  0.2461, -0.9976,  0.6189,\n",
      "        -0.2264,  0.9756, -0.1880,  0.8044,  0.7261,  0.7030, -0.7341, -0.9959,\n",
      "         0.4918,  0.9600, -0.9140, -0.2591,  0.9968, -0.9638, -0.3391, -0.7287,\n",
      "        -0.7299, -0.9879,  0.1172, -0.5400,  0.0090,  0.6855,  0.2506,  0.2719,\n",
      "         0.8432,  0.7095,  0.0049,  0.3190,  0.2844, -0.8590, -0.9787, -0.2739,\n",
      "         0.1610, -0.9989,  0.9965, -0.5956,  0.9761,  0.2346, -0.9483,  0.4552,\n",
      "        -0.0020, -0.5823,  0.1578,  0.9975,  0.6473, -0.2531,  0.1441,  0.2370,\n",
      "         0.1040,  0.0858, -0.2189, -0.1129,  0.1489, -0.5688,  0.8620,  0.0721,\n",
      "        -0.7717,  0.9493,  0.1682,  0.4106, -0.4387,  0.3752,  0.7960, -0.1384,\n",
      "         0.1825,  0.4796, -0.9563, -0.8342,  0.0207, -0.9682,  0.2276,  0.8721,\n",
      "         0.8016, -0.3528,  0.8519,  0.0132,  0.7077, -0.9717,  0.9995, -0.8205,\n",
      "         0.2428,  0.0716, -0.3663,  0.4911,  0.8910,  0.9435,  0.8897, -0.4373,\n",
      "        -0.3774,  0.0824,  0.5375, -0.7188, -0.2085, -0.9711,  0.4001,  0.9849,\n",
      "         0.9640, -0.0298, -0.6208, -0.9618,  0.0667, -0.2147, -0.1444, -0.1726,\n",
      "        -0.4615,  0.4192,  0.9719,  0.1134,  0.6265,  0.1355, -0.7704,  0.7269,\n",
      "         0.7467,  0.9931, -0.7627,  0.2271,  0.6290, -0.3042, -0.4672,  0.1116,\n",
      "         0.9708, -0.3566, -0.1992, -0.9860, -0.1733, -0.7537,  0.3065, -0.0053,\n",
      "        -0.0346, -0.0815,  0.5771,  0.0604,  0.2034, -0.0661,  0.6382, -0.4631,\n",
      "        -0.0935, -0.2838,  0.1477,  0.4445,  0.0931,  0.6402, -0.2780,  0.9989,\n",
      "         0.2579, -0.9984, -0.9575,  0.0790, -0.9991, -0.4052, -0.8571,  0.6144,\n",
      "         0.1043, -0.9665, -0.9806, -0.8651, -0.8964, -0.0497, -0.2147, -0.2496,\n",
      "        -0.8446,  0.9656,  0.0937,  0.0381, -0.0438, -0.2783, -0.4466, -0.9607,\n",
      "         0.5460, -0.9981, -0.0791,  0.9408, -0.9583, -0.4314, -0.7790,  0.4327,\n",
      "        -0.5449,  0.2822,  0.8352, -0.1313, -0.1928, -0.9992,  0.7344, -0.3504,\n",
      "        -0.0509, -0.7661, -0.7497,  0.9935,  0.1205, -0.1297, -0.1017, -0.9879,\n",
      "         0.7604, -0.6549, -0.6762, -0.8118,  0.1800, -0.4497, -0.9967,  0.3797,\n",
      "         0.9261,  0.7944,  0.8536,  0.3852, -0.3154, -0.5669,  0.0918, -0.9984,\n",
      "         0.2011,  0.6976, -0.3239,  0.0873,  0.3244,  0.6748, -0.6974, -0.6735,\n",
      "         0.0604,  0.1702, -0.0396,  0.5871, -0.0735,  0.4891, -0.1850, -0.7677,\n",
      "        -0.6569,  0.9299, -0.9692, -0.1990,  0.8390,  0.9648,  0.2106, -0.2682,\n",
      "        -0.7176, -0.9420, -0.0250,  0.0342, -0.9978,  0.9968, -0.9992, -0.0409,\n",
      "         0.2476,  0.3856,  0.8595,  0.1586, -0.9966, -0.9977, -0.6826,  0.1717,\n",
      "         0.7703,  0.0442,  0.2704,  0.1204, -0.6594,  0.9000, -0.5213,  0.2088,\n",
      "        -0.9662,  0.9892, -0.1100, -0.9707,  0.8938, -0.9950,  0.6714,  0.8007,\n",
      "         0.7870,  0.6374, -0.9707,  0.9989, -0.9958,  0.7516, -0.9990, -0.9763,\n",
      "         0.9957, -0.7865,  0.1413, -0.9893, -0.9588, -0.2228,  0.2314, -0.4843,\n",
      "         0.8444, -0.9957, -0.9601,  0.2728, -0.1999, -0.5672,  0.9388,  0.1194,\n",
      "         0.7416,  0.0719,  0.8001,  0.0538,  0.9707,  0.9531, -0.0415,  0.0357,\n",
      "        -0.8740,  0.7005,  0.1048,  0.1138,  0.7553, -0.0553,  0.3052,  0.4337,\n",
      "        -0.9493,  0.2000, -0.5199,  0.8567,  0.4257,  0.6408,  0.3126, -0.0964,\n",
      "        -0.0862, -0.8384,  0.5840, -0.9890,  0.4597, -0.2762,  0.0975, -0.2875,\n",
      "         0.6920, -0.3326,  0.9924,  0.9687, -0.9754,  0.2225,  0.7564,  0.2518,\n",
      "         0.5629, -0.9025, -0.0359,  0.8111, -0.4196,  0.8068,  0.3007, -0.2107,\n",
      "         0.8277, -0.8843, -0.2968, -0.2408,  0.0181, -0.2545, -0.7463,  0.0199,\n",
      "         0.8088,  0.0843, -0.9921, -0.1111, -0.9846, -0.1758,  0.7630,  0.4734,\n",
      "         0.9973, -0.2660,  0.0583, -0.0534, -0.9938, -0.9771,  0.0892, -0.2461,\n",
      "        -0.1225,  0.9770, -0.1087,  0.0046, -0.9988,  0.1901,  0.9405,  0.1823,\n",
      "         0.2941,  0.0780, -0.1514, -0.7212, -0.1298,  0.1196,  0.6220, -0.0353,\n",
      "         0.2136, -0.2306,  0.9984, -0.9335, -0.5853, -0.7971,  0.3015, -0.1474,\n",
      "         0.4053,  0.3027,  0.0415,  0.8769, -0.6708,  0.9208, -0.8871, -0.9317,\n",
      "         0.9957, -0.1030, -0.9172, -0.2253, -0.2128, -0.2108,  0.0021,  0.5435,\n",
      "         0.2165, -0.0292, -0.8237,  0.6500, -0.0694, -0.3110, -0.2352, -0.1752,\n",
      "        -0.9867,  0.8858,  0.8732,  0.9980, -0.9936,  0.6000,  0.1183,  0.9742,\n",
      "         0.0371, -0.3767, -0.0302,  0.9921,  0.3489,  0.4965, -0.1285, -0.0712,\n",
      "         0.1412, -0.5033,  0.9550, -0.4789, -0.2106, -0.7136, -0.9987,  0.9984,\n",
      "        -0.1398,  0.9216,  0.3968,  0.2403, -0.1403,  0.8831, -0.5944, -0.4724,\n",
      "        -0.9990, -0.2159, -0.9860, -0.8878, -0.2137,  0.6033, -0.9926, -0.2538,\n",
      "        -0.2041, -0.9992,  0.7331, -0.8470, -0.3926, -0.8118,  0.9623,  0.0775,\n",
      "         0.2441,  0.6471, -0.6577,  0.5967, -0.1695,  0.9269,  0.3390,  0.2524,\n",
      "        -0.0522, -0.8685,  0.0239, -0.7254,  0.5023, -0.8668, -0.2574,  0.9420,\n",
      "         0.8438, -0.9953, -0.9077,  0.9063, -0.7570,  0.9025, -0.4873, -0.9965,\n",
      "        -0.9985,  0.1784,  0.0140,  0.8254, -0.2525,  0.9859,  0.3013,  0.2102,\n",
      "        -0.5023, -0.5593, -0.0756, -0.1626, -0.2792,  0.9985, -0.0527,  0.8289],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([-2.5337e-01,  3.1133e-01,  9.9391e-01, -8.3995e-01,  5.5155e-01,\n",
      "         3.0091e-01,  3.3945e-01, -9.4467e-01, -1.8357e-01, -2.9086e-01,\n",
      "         4.8427e-01,  8.5602e-01, -9.7936e-01, -9.8288e-01, -2.4287e-01,\n",
      "        -3.6093e-01,  6.8499e-01, -3.3148e-01, -9.9611e-01, -2.6348e-01,\n",
      "        -1.4469e-01, -9.8734e-01,  2.2648e-01,  7.9415e-01,  6.1181e-02,\n",
      "        -6.7767e-02,  6.1054e-01,  9.9610e-01,  8.2493e-03,  8.4966e-03,\n",
      "        -2.0534e-02, -7.7825e-01,  2.9601e-01, -9.5817e-01,  1.1387e-01,\n",
      "        -1.0060e-01,  2.8327e-01,  2.9961e-02,  2.4611e-01, -7.1611e-01,\n",
      "         4.2507e-03,  1.7915e-01,  1.5663e-01, -3.3736e-01,  2.7279e-01,\n",
      "        -5.1971e-01,  9.3292e-02, -1.3912e-01, -1.4494e-01,  9.9805e-01,\n",
      "        -3.6171e-01,  7.9400e-01, -9.6899e-01,  5.1918e-01,  7.3070e-01,\n",
      "        -1.6605e-01,  7.1655e-01, -2.3816e-02, -9.7471e-01, -6.0313e-02,\n",
      "         2.9327e-01,  2.1260e-01,  3.5397e-01, -3.3300e-01, -4.3276e-01,\n",
      "         7.1627e-01, -3.4532e-01,  2.8878e-01,  1.3522e-01, -6.5523e-02,\n",
      "        -6.0429e-01,  2.7236e-01,  6.1020e-01, -5.3884e-01,  3.2418e-02,\n",
      "        -6.8062e-01,  7.3761e-01, -9.9493e-01,  5.0760e-01,  9.9155e-01,\n",
      "         1.8190e-01, -9.6987e-01,  7.7746e-01, -7.4442e-02,  1.0079e-01,\n",
      "        -3.5190e-01, -9.7567e-01, -9.6117e-01,  8.5282e-02, -4.7318e-02,\n",
      "         5.9439e-01, -5.8656e-01,  3.9596e-02, -5.3742e-02,  9.9447e-01,\n",
      "        -6.2281e-01, -2.1481e-01, -1.2526e-01,  7.7084e-01, -6.0799e-01,\n",
      "        -2.0532e-01,  6.6037e-01,  9.8008e-01, -9.4419e-01,  9.7351e-01,\n",
      "         3.3863e-01, -4.6546e-01, -5.5766e-01, -2.5067e-01,  2.0338e-01,\n",
      "         4.1443e-01, -3.0210e-01, -6.4161e-01,  4.6041e-02,  6.1166e-01,\n",
      "        -8.3391e-01,  7.0849e-01,  4.0422e-01, -1.3970e-01,  9.9722e-01,\n",
      "        -9.6732e-02,  3.6810e-01,  8.9244e-01, -2.8570e-01, -3.1183e-01,\n",
      "        -2.9833e-01, -7.2419e-02, -3.6034e-01, -8.4317e-02,  9.2744e-02,\n",
      "         4.3205e-01, -7.8754e-01, -9.5261e-01,  9.6198e-01, -1.4235e-01,\n",
      "         9.9532e-01, -9.2116e-01,  8.6437e-01, -9.9398e-01, -8.6492e-01,\n",
      "         2.8488e-01, -2.8077e-01, -6.7964e-01,  1.4069e-01,  1.9101e-01,\n",
      "         2.6187e-02, -6.6013e-01,  4.9536e-01,  3.5952e-01,  3.6520e-03,\n",
      "         2.6547e-01,  5.6462e-01, -3.7956e-01,  6.9813e-01,  9.6991e-01,\n",
      "         5.3788e-01,  5.4732e-01,  1.9035e-01, -2.7398e-01,  3.1789e-01,\n",
      "        -1.2973e-01, -9.4498e-01, -1.3291e-01, -8.9851e-01,  9.7534e-01,\n",
      "         6.9486e-01,  1.8611e-01, -9.6750e-01,  9.9012e-01,  1.8113e-01,\n",
      "        -1.1693e-01,  1.6489e-02,  1.4014e-01, -9.8006e-01,  2.2539e-01,\n",
      "         2.7132e-01,  1.7094e-01,  9.9027e-01, -7.5743e-01,  9.8827e-01,\n",
      "         7.2544e-01,  1.4406e-01,  2.8217e-01,  9.8620e-01, -8.2673e-01,\n",
      "        -4.4651e-01, -6.3297e-01,  4.6513e-01, -4.8143e-01,  4.4657e-01,\n",
      "         4.1473e-01,  6.5187e-01,  9.5540e-01, -3.3441e-01, -9.6955e-01,\n",
      "        -9.6748e-02,  6.1131e-01, -2.3056e-01,  9.9435e-01,  3.3049e-01,\n",
      "        -9.8526e-01, -4.3430e-01,  3.4222e-01, -1.5721e-01, -1.6536e-02,\n",
      "         2.1378e-01, -3.6910e-01, -1.5789e-01,  9.6075e-01, -6.7434e-01,\n",
      "         9.7642e-01, -2.8240e-01, -3.4907e-01,  2.7083e-01,  5.2861e-01,\n",
      "        -3.9799e-01, -2.1263e-01,  1.8815e-01, -3.1787e-01,  9.8970e-01,\n",
      "        -9.8364e-01,  7.0097e-02,  1.6230e-01, -9.1856e-01, -8.8436e-01,\n",
      "         6.0008e-01,  6.6034e-02, -1.6762e-02,  1.8112e-02, -4.1512e-01,\n",
      "        -1.9160e-03,  6.2359e-01,  7.7644e-01, -5.3256e-02, -1.0542e-01,\n",
      "        -9.8841e-01, -9.3926e-01,  1.4657e-01, -5.0133e-01, -8.0447e-02,\n",
      "         4.7940e-01, -3.0654e-01, -2.5224e-01, -9.6859e-01,  6.4522e-01,\n",
      "         3.9816e-01, -5.2723e-02,  1.9421e-01,  1.6455e-01, -9.5423e-01,\n",
      "         1.1132e-01, -2.4124e-01, -9.6864e-01,  9.7623e-01, -1.2518e-03,\n",
      "         9.5488e-01,  3.2217e-01, -6.8759e-01,  6.7820e-01, -9.8499e-01,\n",
      "        -2.3436e-01, -6.3074e-01,  2.2370e-02, -3.6028e-02,  3.0762e-01,\n",
      "        -2.7178e-02,  6.5588e-01, -2.2130e-01, -5.3766e-01,  9.2025e-02,\n",
      "        -9.9324e-01,  4.3698e-01,  2.7871e-03,  9.3057e-01, -3.6250e-01,\n",
      "         4.0218e-01,  4.6972e-01,  7.8499e-01, -7.0983e-01, -9.8243e-01,\n",
      "         6.0666e-01,  7.2772e-01, -8.3941e-01, -1.2134e-01,  9.9082e-01,\n",
      "        -9.6389e-01, -1.0605e-01, -6.8806e-01, -3.9954e-01, -9.5010e-01,\n",
      "         2.6870e-01, -5.3853e-01,  1.5962e-01,  3.9997e-01,  1.1439e-02,\n",
      "         3.7729e-01,  6.5223e-01,  2.5708e-01,  9.2076e-02,  6.6102e-02,\n",
      "         1.1600e-01, -6.2137e-01, -8.0576e-01, -4.5250e-01,  1.7167e-01,\n",
      "        -9.9582e-01,  9.8500e-01, -3.2561e-01,  6.4843e-01, -4.8876e-02,\n",
      "        -9.8263e-01,  3.5199e-01,  1.8760e-01, -5.6290e-01,  3.5499e-02,\n",
      "         9.9293e-01,  4.3783e-01, -8.5498e-02,  6.0707e-02,  5.5857e-01,\n",
      "         8.2232e-02,  9.9863e-02,  2.8362e-01, -2.1129e-01, -1.6273e-03,\n",
      "        -2.8937e-01,  7.5425e-01,  2.7578e-01, -6.6209e-01,  9.4934e-01,\n",
      "         2.9684e-02,  9.4210e-02, -5.3488e-01,  2.1648e-01,  6.0094e-01,\n",
      "        -1.0858e-01, -1.3986e-01,  2.9673e-01, -8.4951e-01, -8.8185e-01,\n",
      "        -8.9253e-02, -9.7499e-01,  2.2837e-01,  5.2012e-01,  6.6489e-01,\n",
      "         4.0877e-01,  4.4462e-01,  4.1388e-03,  6.9873e-01, -9.7582e-01,\n",
      "         9.9819e-01, -5.0648e-01,  1.7502e-01,  9.2232e-02, -2.5035e-01,\n",
      "         1.5662e-01,  7.8489e-01,  9.7497e-01,  8.8996e-01, -3.4238e-01,\n",
      "        -6.2621e-01, -1.4606e-01,  2.6634e-01, -5.6963e-01, -1.1930e-01,\n",
      "        -9.8291e-01,  3.4165e-01,  9.1909e-01,  9.5598e-01,  4.1058e-02,\n",
      "        -1.0065e-01, -9.7365e-01, -2.7955e-02, -1.6848e-01, -1.5168e-01,\n",
      "        -1.0664e-01, -5.6992e-01,  6.0572e-01,  9.8233e-01, -1.3655e-01,\n",
      "         7.1039e-01,  1.6862e-01, -4.9010e-01,  7.6926e-01,  6.8124e-01,\n",
      "         9.8221e-01, -6.6236e-01,  6.4041e-02,  5.0008e-01, -3.4706e-01,\n",
      "        -5.6006e-01, -1.4188e-01,  9.8522e-01,  1.4532e-01, -1.1835e-01,\n",
      "        -9.5261e-01, -1.8114e-01, -5.7799e-01,  1.6429e-01,  4.1443e-01,\n",
      "        -6.5258e-02, -1.0546e-01,  5.0995e-01,  5.6637e-02,  1.6819e-01,\n",
      "        -1.1745e-01,  3.7282e-01, -1.2526e-01, -4.3335e-02, -1.9987e-01,\n",
      "        -1.3009e-01,  2.4146e-01,  9.5377e-02,  4.9605e-01, -2.6681e-01,\n",
      "         9.9383e-01,  4.7852e-01, -9.9339e-01, -9.6774e-01, -2.3730e-01,\n",
      "        -9.9682e-01, -2.9031e-02, -3.8024e-01,  4.0880e-01,  3.5312e-01,\n",
      "        -9.7701e-01, -9.8663e-01, -6.2883e-01, -4.7666e-01,  2.0250e-01,\n",
      "        -3.9791e-01,  4.1071e-04, -6.8927e-01,  8.0337e-01, -1.3248e-03,\n",
      "         2.3443e-01,  1.0395e-01, -7.2708e-02, -9.3793e-02, -9.6736e-01,\n",
      "         6.3066e-01, -9.9295e-01,  6.7279e-02,  9.5468e-01, -9.6627e-01,\n",
      "        -4.2918e-01, -7.0429e-01,  4.5049e-01, -1.3640e-01,  4.7508e-02,\n",
      "         5.4061e-01, -1.5088e-01,  7.2085e-02, -9.9541e-01,  5.3970e-01,\n",
      "        -5.7997e-01, -6.1273e-02, -7.4791e-01, -5.8060e-01,  9.8636e-01,\n",
      "         8.2520e-03, -2.0028e-01, -1.2603e-03, -9.6745e-01,  6.8757e-01,\n",
      "        -5.8850e-01, -6.6339e-01, -5.5230e-01, -7.3308e-02, -2.8369e-01,\n",
      "        -9.8959e-01,  4.3305e-02,  9.5084e-01,  4.4700e-01,  7.4939e-01,\n",
      "         1.3571e-01, -1.0768e-01, -2.4431e-01,  6.3382e-02, -9.9407e-01,\n",
      "         1.2793e-01,  7.3011e-01, -1.4965e-01, -2.6445e-02, -5.7391e-02,\n",
      "         5.5695e-01, -6.3008e-01, -7.5157e-01, -1.0737e-01,  9.9372e-02,\n",
      "         1.2050e-01,  4.3608e-01,  4.4195e-02,  2.7194e-01,  5.5276e-03,\n",
      "        -5.6812e-01, -5.0447e-01,  8.7172e-01, -9.8214e-01, -3.6777e-01,\n",
      "         8.4818e-01,  9.6741e-01, -1.0130e-02,  9.3318e-02, -6.7779e-01,\n",
      "        -4.9400e-01, -5.5722e-02,  1.3765e-01, -9.9174e-01,  9.8749e-01,\n",
      "        -9.9577e-01,  3.5192e-02,  1.5484e-01,  5.0561e-01,  7.4544e-01,\n",
      "        -5.3133e-03, -9.8990e-01, -9.9013e-01, -2.0784e-01,  2.2991e-01,\n",
      "         6.4105e-01,  3.4873e-01,  2.4033e-03, -2.3927e-01, -1.5705e-01,\n",
      "         7.7708e-01, -2.2184e-02,  2.3516e-01, -9.6933e-01,  9.7281e-01,\n",
      "        -9.8266e-02, -9.2496e-01,  8.7253e-01, -9.8351e-01,  8.7429e-01,\n",
      "         5.4371e-01,  7.1137e-01,  4.2838e-01, -9.7930e-01,  9.9449e-01,\n",
      "        -9.8378e-01,  1.2688e-01, -9.9524e-01, -9.8378e-01,  9.8144e-01,\n",
      "        -6.3849e-01,  1.7574e-01, -9.7477e-01, -9.6701e-01, -4.8547e-01,\n",
      "         8.9509e-02, -2.3483e-01,  6.5728e-01, -9.8525e-01, -9.1246e-01,\n",
      "        -3.3845e-01, -4.8867e-02, -2.6382e-01,  9.5544e-01, -7.8386e-02,\n",
      "         5.5673e-01, -1.1962e-01,  5.5523e-01,  2.9287e-02,  9.7862e-01,\n",
      "         6.5945e-01, -2.9405e-01, -1.5492e-01, -8.1026e-01,  6.4193e-01,\n",
      "         6.0527e-02,  4.7245e-02,  4.9387e-01,  5.3394e-03,  1.0960e-01,\n",
      "         3.1545e-01, -8.5709e-01,  4.2754e-01, -3.4972e-01,  9.2006e-01,\n",
      "         1.8676e-01,  5.5612e-01,  1.5988e-01, -7.6411e-02, -4.9819e-02,\n",
      "        -7.1587e-01,  3.8870e-01, -9.7130e-01,  5.2948e-01, -5.4482e-01,\n",
      "        -5.5213e-02, -6.2441e-02,  3.4471e-01,  2.1128e-01,  9.7772e-01,\n",
      "         9.1744e-01, -6.7417e-01, -3.9900e-02,  6.2368e-01,  2.6120e-01,\n",
      "         6.5298e-01, -6.3262e-01, -1.0329e-02,  9.0586e-01, -2.3147e-01,\n",
      "         6.5880e-01,  1.7138e-01, -1.4050e-01,  6.5248e-01, -7.7136e-01,\n",
      "        -2.6049e-01, -3.0120e-01,  1.3502e-01, -7.6404e-02, -6.3385e-01,\n",
      "        -2.1808e-01,  8.6068e-01,  5.2674e-02, -9.6784e-01, -3.8127e-01,\n",
      "        -9.5946e-01, -4.3318e-02,  6.5517e-01,  5.4407e-02,  9.9032e-01,\n",
      "        -4.1669e-01,  1.5456e-01,  1.6241e-01, -9.7897e-01, -9.8516e-01,\n",
      "         5.9617e-02, -1.2371e-01, -7.9451e-02,  9.7989e-01,  6.3236e-02,\n",
      "        -1.6543e-01, -9.9298e-01,  2.0387e-01,  9.5274e-01,  3.2378e-01,\n",
      "         3.6210e-01, -2.8519e-01, -1.7723e-01, -7.7084e-01,  2.6160e-01,\n",
      "         1.3546e-01,  3.9198e-01,  4.3209e-01,  4.0475e-01, -4.7504e-01,\n",
      "         9.9576e-01, -8.6833e-01, -4.3242e-01, -7.6644e-01,  2.1357e-01,\n",
      "         2.6792e-01,  2.9878e-01,  4.6381e-01, -2.2175e-01,  9.0598e-01,\n",
      "        -7.1616e-01,  8.2846e-01, -8.6453e-01, -8.0602e-01,  9.8260e-01,\n",
      "         2.4593e-03, -9.4153e-01,  1.8707e-01, -2.2712e-01,  9.2708e-02,\n",
      "         1.1069e-01,  7.1362e-01,  5.0992e-01, -4.7671e-02, -4.2624e-01,\n",
      "        -1.9828e-02,  6.1810e-05, -1.5006e-01, -9.8839e-02, -1.7114e-02,\n",
      "        -7.4729e-01,  7.1813e-01,  6.9401e-01,  9.9192e-01, -9.8016e-01,\n",
      "         3.1754e-01, -2.5525e-02,  9.2570e-01,  2.2580e-01, -2.6262e-01,\n",
      "         8.5838e-02,  9.7102e-01,  3.7760e-01,  3.3793e-01, -4.9887e-02,\n",
      "        -5.1536e-02,  3.7635e-02, -4.3280e-01,  9.8004e-01, -5.0916e-01,\n",
      "        -5.4647e-02, -6.1587e-01, -9.9404e-01,  9.9262e-01,  8.1125e-02,\n",
      "         8.6384e-01,  2.7409e-01, -6.2569e-02,  3.7505e-02,  8.4811e-01,\n",
      "        -5.3855e-01, -3.2037e-01, -9.9498e-01,  1.4067e-01, -8.0342e-01,\n",
      "        -8.0419e-01, -3.4818e-01,  1.9215e-01, -9.7308e-01,  6.0268e-02,\n",
      "        -2.8716e-01, -9.9518e-01,  6.0197e-01, -7.9137e-01, -1.7378e-01,\n",
      "        -5.6026e-01,  9.7126e-01,  1.6108e-01,  2.6925e-01,  5.1016e-01,\n",
      "        -5.2085e-01,  5.5765e-01, -2.8545e-01,  7.7422e-01,  3.9765e-01,\n",
      "         3.2620e-02, -6.9036e-02, -8.8386e-01,  3.9578e-02, -6.3937e-01,\n",
      "         2.2226e-01, -6.9199e-01, -1.0374e-01,  8.5231e-01,  6.2033e-01,\n",
      "        -9.7880e-01, -7.8021e-01,  9.0784e-01, -3.6120e-01,  7.3226e-01,\n",
      "        -3.9700e-01, -9.8591e-01, -9.9256e-01,  1.8395e-01,  1.8632e-01,\n",
      "         7.1763e-01, -2.7681e-02,  8.3141e-01,  1.7773e-01, -9.8031e-02,\n",
      "        -2.2421e-01, -2.1267e-01, -3.0574e-01,  2.7251e-02, -2.0360e-01,\n",
      "         9.9292e-01, -1.4451e-01,  7.5081e-01], grad_fn=<SliceBackward>)\n",
      "tensor([-4.9362e-01,  6.9544e-01,  9.9935e-01, -9.2596e-01,  7.7222e-01,\n",
      "        -3.8106e-01,  7.9130e-01, -8.8357e-01, -6.1218e-01, -4.6745e-01,\n",
      "         8.4993e-01,  9.2389e-01, -9.1283e-01, -9.9893e-01, -7.8012e-01,\n",
      "        -6.2774e-01,  8.4430e-01, -6.3633e-01, -9.9961e-01,  5.4448e-01,\n",
      "        -1.7029e-01, -9.9897e-01,  5.0807e-01,  3.3415e-01,  5.5706e-01,\n",
      "        -1.4596e-01,  7.0497e-01,  9.9943e-01,  3.7414e-01,  3.8557e-01,\n",
      "         2.3840e-01, -8.5937e-01,  1.0824e-01, -9.8594e-01,  4.0817e-01,\n",
      "        -7.0254e-02, -2.5069e-01, -4.1686e-01,  1.3701e-01, -3.2901e-01,\n",
      "        -4.2157e-01,  7.1087e-01, -8.8392e-02, -5.8828e-01, -1.9715e-01,\n",
      "        -2.9746e-01,  3.1497e-01, -3.0763e-01, -3.3889e-01,  9.9997e-01,\n",
      "        -6.3025e-01,  9.9967e-01, -8.6359e-01,  9.6208e-01,  8.1832e-01,\n",
      "         3.2227e-01,  9.2489e-01,  1.9273e-01, -9.2902e-01,  1.1877e-01,\n",
      "         7.1215e-01, -4.8648e-02,  5.3581e-01, -4.2588e-01, -5.3365e-01,\n",
      "         4.9879e-01, -3.8792e-01,  5.1557e-01,  8.3886e-04, -1.3502e-02,\n",
      "        -3.9346e-01,  6.3389e-01,  7.8482e-01, -7.6007e-01,  5.2999e-02,\n",
      "        -6.3725e-01,  7.8295e-01, -9.9954e-01,  5.6575e-01,  9.9937e-01,\n",
      "         2.5377e-02, -9.9100e-01,  8.7427e-01, -4.2673e-01,  2.1419e-01,\n",
      "        -6.9059e-01, -9.1511e-01, -9.8858e-01,  6.7109e-02, -1.8807e-01,\n",
      "        -4.8159e-01, -7.7228e-01, -2.1868e-01,  3.3324e-01,  9.9947e-01,\n",
      "         3.5452e-01, -3.8899e-01,  2.4728e-01,  3.0946e-01,  1.3949e-01,\n",
      "        -2.5081e-01,  3.8096e-01,  8.8518e-01, -7.0679e-01,  9.2527e-01,\n",
      "        -2.5471e-01, -6.8390e-01,  2.9936e-02, -4.8783e-01,  3.1925e-01,\n",
      "         7.1460e-01, -8.1951e-01, -2.7376e-01,  3.6705e-01,  3.0982e-01,\n",
      "        -1.8860e-01,  8.6726e-01, -1.5685e-01, -4.6510e-01,  9.9969e-01,\n",
      "        -3.7948e-01, -3.7746e-01,  9.5608e-01, -6.2064e-01,  1.0769e-01,\n",
      "        -4.7946e-01,  1.8244e-01, -4.9317e-01,  2.3906e-01, -3.2400e-01,\n",
      "         7.5979e-01, -8.6854e-01, -8.5158e-01,  9.9178e-01, -4.8797e-01,\n",
      "         9.9944e-01, -9.8304e-01,  7.0720e-01, -9.9929e-01, -7.5088e-01,\n",
      "         4.0390e-01, -4.2696e-01, -6.4421e-02,  5.7095e-01,  6.2894e-01,\n",
      "         5.1010e-01,  1.9214e-01,  6.4050e-01,  3.8491e-01,  1.3977e-01,\n",
      "         4.2994e-01,  6.3482e-01, -6.2966e-01,  9.9945e-01,  9.1793e-01,\n",
      "         3.0937e-01,  1.9703e-01,  5.1548e-01,  4.2812e-01, -3.2066e-01,\n",
      "         5.6469e-01, -9.7695e-01, -3.9727e-01, -7.2861e-01,  9.9657e-01,\n",
      "         8.2340e-01, -1.0445e-01, -8.6248e-01,  9.9866e-01,  3.7227e-01,\n",
      "         3.8715e-01, -4.5349e-01, -1.8916e-01, -8.9930e-01,  3.7889e-01,\n",
      "         5.7493e-01,  4.8672e-01,  9.9908e-01, -8.5657e-01,  9.9976e-01,\n",
      "         9.9897e-01, -1.8033e-01,  5.3971e-01,  9.1361e-01, -9.1039e-01,\n",
      "        -6.1369e-01, -8.3549e-01,  5.5199e-01, -7.5725e-01,  1.6690e-01,\n",
      "         1.7852e-01,  7.3804e-01,  8.4992e-01, -4.8642e-02, -9.9718e-01,\n",
      "        -3.8463e-01,  7.4153e-01, -4.2893e-01,  9.9930e-01,  5.9406e-01,\n",
      "        -9.9690e-01,  2.3363e-01, -5.7708e-01,  6.4752e-01, -2.1600e-01,\n",
      "         7.4213e-01,  1.1421e-01,  2.4495e-01,  8.2811e-01, -9.9954e-01,\n",
      "         8.2569e-01, -1.7992e-01, -6.9831e-01,  5.6095e-01,  7.2253e-01,\n",
      "         7.2603e-01, -4.7354e-01,  4.2804e-01,  4.9743e-02,  9.9894e-01,\n",
      "        -9.9473e-01, -2.3763e-01,  1.4898e-01, -9.7311e-01, -9.3499e-01,\n",
      "         6.5515e-01, -3.0479e-01, -1.2386e-01, -2.2694e-01, -8.8523e-01,\n",
      "         2.1454e-01,  3.7178e-01,  8.4016e-01,  5.1737e-01,  5.9717e-01,\n",
      "        -9.9773e-01, -6.4648e-01, -1.6338e-01,  2.1450e-01,  2.9578e-01,\n",
      "         7.6145e-01, -5.0243e-01, -6.0826e-01, -8.9136e-01,  8.3602e-01,\n",
      "        -3.5176e-01,  3.4825e-01,  1.5648e-02,  4.1324e-01, -7.7111e-01,\n",
      "        -5.2802e-01,  2.1323e-01, -9.9383e-01,  9.9371e-01,  5.2115e-01,\n",
      "         8.4364e-01,  6.3548e-01, -8.4565e-01,  3.1515e-01, -9.1746e-01,\n",
      "        -4.0745e-01, -9.9855e-01, -8.3695e-02, -3.0046e-01,  7.2572e-01,\n",
      "        -2.6030e-01,  8.0631e-01, -4.9072e-01,  1.9090e-02, -4.3615e-01,\n",
      "        -9.9900e-01,  6.7397e-01, -6.5230e-02,  9.6376e-01, -7.9745e-01,\n",
      "         6.5944e-01,  6.6158e-01,  3.2811e-01, -7.6957e-01, -9.9763e-01,\n",
      "        -2.5800e-01,  9.9930e-01, -9.2735e-01, -4.4533e-01,  9.9806e-01,\n",
      "        -8.7015e-01, -4.2813e-01, -7.1953e-01, -6.3815e-01, -9.9275e-01,\n",
      "        -2.8060e-02,  1.3528e-01, -1.7391e-04,  6.7731e-01, -2.5126e-01,\n",
      "        -1.3461e-01,  9.0969e-01,  9.4568e-01, -2.4446e-01,  2.2949e-01,\n",
      "         4.9664e-01, -8.8846e-01, -9.9957e-01, -5.1518e-01,  3.4667e-01,\n",
      "        -9.9968e-01,  9.9826e-01, -6.1027e-01,  9.9895e-01, -3.7410e-01,\n",
      "        -8.7143e-01,  6.8642e-01, -1.5885e-01,  1.2261e-02,  3.1789e-01,\n",
      "         9.9805e-01,  7.6257e-01, -4.4662e-01,  3.7208e-01,  1.2749e-01,\n",
      "         3.1230e-01, -3.2792e-01,  4.5515e-01,  1.0064e-01,  3.4758e-01,\n",
      "        -7.6480e-01,  4.5023e-01, -5.2997e-01, -7.8436e-01,  8.1036e-01,\n",
      "         2.5902e-01,  3.4230e-01,  2.6907e-01,  4.6807e-01,  8.3181e-01,\n",
      "        -3.9865e-01,  9.7583e-02,  1.2362e-01, -9.9919e-01, -6.4471e-01,\n",
      "         1.1121e-01, -9.1561e-01,  1.8579e-01,  5.2377e-01,  6.7545e-01,\n",
      "        -5.9501e-01,  9.7988e-01, -6.3634e-02,  1.2114e-01, -8.4817e-01,\n",
      "         9.9982e-01, -9.1173e-01,  4.2701e-01, -2.0696e-01,  5.5159e-02,\n",
      "         4.6669e-01,  8.4335e-01,  8.7258e-01,  4.2110e-01,  3.3517e-01,\n",
      "        -3.0511e-01,  2.8127e-01,  5.7144e-01, -1.0960e-01, -3.3179e-01,\n",
      "        -9.0837e-01,  5.7250e-01,  9.8888e-01,  8.8368e-01, -1.5616e-01,\n",
      "        -6.3215e-01, -8.8052e-01,  5.2328e-01,  6.8299e-02,  5.9067e-01,\n",
      "        -3.2906e-01, -1.3687e-01, -1.4985e-01,  9.1336e-01,  3.2396e-01,\n",
      "         3.0554e-01,  4.2650e-01, -7.5033e-01,  1.2173e-01,  3.5746e-01,\n",
      "         9.9668e-01, -8.3894e-01,  1.0262e-01,  6.6999e-01, -3.7524e-01,\n",
      "        -3.6248e-01,  2.1692e-01,  9.2446e-01, -7.3733e-01, -3.3529e-01,\n",
      "        -9.8635e-01, -2.4193e-01, -6.0659e-01,  3.2676e-01,  6.4231e-01,\n",
      "        -7.9995e-03,  2.0031e-02,  1.7981e-02, -7.4070e-02,  3.4024e-01,\n",
      "         2.4575e-01,  6.4012e-01, -2.0543e-01, -2.0070e-01, -6.0451e-01,\n",
      "         3.3043e-01,  5.4610e-01, -2.4742e-01,  7.1042e-01, -5.5609e-01,\n",
      "         9.9955e-01,  6.5220e-02, -9.9900e-01, -7.8839e-01,  6.0312e-01,\n",
      "        -9.9982e-01, -6.1166e-01, -9.5268e-01,  6.9711e-01, -4.9451e-01,\n",
      "        -8.7130e-01, -9.1393e-01, -9.5071e-01, -9.9636e-01, -5.1916e-01,\n",
      "        -4.5818e-01, -4.3800e-01, -7.8531e-01,  9.9900e-01, -3.9054e-02,\n",
      "         4.4834e-02, -1.0499e-01, -5.9099e-01, -3.4318e-01, -8.5718e-01,\n",
      "        -8.6345e-03, -9.9940e-01,  5.8639e-01,  8.7947e-01, -9.0544e-01,\n",
      "         2.9220e-01, -7.0114e-01,  4.1168e-01, -6.5636e-01,  5.1404e-01,\n",
      "         7.6785e-01,  6.1270e-02,  3.8261e-01, -9.9983e-01,  7.9343e-01,\n",
      "         1.5130e-01,  8.7949e-02, -5.2159e-01, -7.9843e-01,  9.9798e-01,\n",
      "        -1.3678e-01,  2.0502e-01, -1.6064e-01, -9.9590e-01,  2.6809e-01,\n",
      "        -2.6152e-01,  1.8807e-01, -8.7372e-01,  2.7696e-01, -6.6832e-01,\n",
      "        -9.9891e-01,  3.5245e-01,  8.3061e-01,  9.4197e-01,  8.7211e-01,\n",
      "         1.6821e-01, -5.8283e-01, -6.3278e-01,  3.5571e-01, -9.9940e-01,\n",
      "         1.9281e-02,  3.1041e-01, -5.8165e-01,  4.7068e-01,  6.7778e-01,\n",
      "         7.0515e-01,  3.1286e-01, -3.3657e-01, -5.4182e-01,  3.5749e-01,\n",
      "         5.0351e-01,  5.8488e-01, -1.5071e-01,  5.9251e-01, -2.1525e-01,\n",
      "        -7.8710e-01, -7.0337e-01,  9.4849e-01, -8.8485e-01,  3.2420e-01,\n",
      "         6.3472e-01,  8.7693e-01,  1.9287e-01, -4.0489e-02, -1.4529e-01,\n",
      "        -9.9514e-01, -2.8526e-01, -2.0655e-01, -9.9901e-01,  9.9940e-01,\n",
      "        -9.9968e-01,  8.5394e-02,  4.6345e-01, -9.0240e-02,  8.9613e-01,\n",
      "         1.7329e-02, -9.9812e-01, -9.9860e-01, -7.1456e-01, -1.4199e-01,\n",
      "         8.3332e-01, -5.3190e-04,  1.6279e-01,  4.0267e-01, -3.2235e-01,\n",
      "         8.5409e-01,  3.6066e-01,  4.5017e-01, -8.8804e-01,  9.9370e-01,\n",
      "         2.4130e-01, -9.6650e-01,  5.1453e-01, -9.9802e-01,  4.8980e-01,\n",
      "         8.1747e-01,  7.5184e-01,  7.5692e-01, -8.7426e-01,  9.9948e-01,\n",
      "        -9.9889e-01,  9.4350e-01, -9.9957e-01, -9.1044e-01,  9.9710e-01,\n",
      "        -8.3030e-01,  7.0629e-01, -9.9533e-01, -8.8370e-01, -4.8929e-01,\n",
      "         3.1421e-01, -4.2798e-01,  7.6742e-01, -9.9620e-01, -9.5497e-01,\n",
      "         3.3179e-01,  5.9677e-01, -3.6015e-01,  8.4896e-01,  4.8792e-01,\n",
      "         8.0979e-01,  2.2155e-01,  8.4784e-01, -1.0680e-01,  9.1645e-01,\n",
      "         9.9684e-01,  5.8726e-01,  4.9511e-01, -8.8393e-01,  7.9893e-01,\n",
      "         4.2578e-01,  4.0776e-01,  7.2033e-01, -2.0526e-01,  4.5423e-01,\n",
      "         3.4225e-01, -9.1471e-01,  8.4381e-02, -9.0483e-01,  7.3920e-01,\n",
      "        -3.7444e-01,  7.7790e-01,  4.0958e-01,  6.3583e-02,  1.7361e-01,\n",
      "        -8.4475e-01,  6.4849e-01, -9.9437e-01,  4.7472e-01,  8.4406e-04,\n",
      "         2.4787e-01, -3.8268e-01,  6.2990e-01, -4.2234e-01,  9.9642e-01,\n",
      "         9.7145e-01, -9.9932e-01,  3.1136e-01,  7.3979e-01,  3.4003e-01,\n",
      "         7.0532e-01, -8.8045e-01, -2.1642e-01,  4.5150e-01, -4.0692e-01,\n",
      "         7.8859e-01,  2.7955e-01, -3.9585e-01,  8.3296e-01, -8.8411e-01,\n",
      "         3.3191e-01, -4.0379e-01, -2.2290e-01, -1.5468e-01, -6.8089e-01,\n",
      "         1.6059e-01,  6.3316e-01,  3.5082e-01, -9.9383e-01, -6.7291e-01,\n",
      "        -9.8665e-01, -3.2539e-01,  7.9544e-01,  7.2724e-01,  9.9828e-01,\n",
      "        -1.5832e-01, -1.0601e-01, -1.9841e-01, -9.9478e-01, -8.8884e-01,\n",
      "         3.1485e-01, -2.2538e-01,  4.4837e-01,  8.9106e-01,  1.0033e-01,\n",
      "        -4.9762e-01, -9.9972e-01,  5.4033e-01,  7.9673e-01,  5.4676e-01,\n",
      "         4.2448e-01, -6.9546e-02, -5.0206e-01, -2.4002e-01, -4.4116e-02,\n",
      "         3.6128e-01, -8.8923e-02, -5.6716e-01,  6.0520e-01, -2.6423e-01,\n",
      "         9.9966e-01, -9.2074e-01, -7.8383e-01, -8.3985e-01,  1.0903e-01,\n",
      "        -2.8178e-01,  6.1430e-01,  4.4558e-01,  7.3069e-01,  3.9164e-01,\n",
      "        -1.0528e-01,  9.2898e-01, -8.9978e-01, -9.3366e-01,  9.9686e-01,\n",
      "        -3.6344e-01, -6.8650e-01, -1.2072e-01, -4.6418e-01, -2.7055e-01,\n",
      "        -2.3479e-01,  4.9920e-01, -2.4074e-01, -3.3379e-01, -9.6824e-01,\n",
      "        -2.1669e-01,  2.5160e-01, -5.3551e-01, -3.0124e-01, -2.8130e-01,\n",
      "        -9.9975e-01,  8.6898e-01,  8.5866e-01,  9.9899e-01, -9.9633e-01,\n",
      "         5.8478e-01,  2.1782e-01,  9.8187e-01,  2.2865e-01, -6.3467e-01,\n",
      "        -6.3153e-01,  9.9638e-01,  5.5084e-01, -1.5140e-01, -4.0149e-02,\n",
      "        -2.9513e-01,  1.3026e-01, -5.6626e-01,  8.8916e-01,  1.4402e-01,\n",
      "         1.4704e-01, -8.7123e-01, -9.9946e-01,  9.9931e-01, -2.6654e-01,\n",
      "         9.0230e-01,  3.8947e-01,  1.3222e-01, -1.8033e-01,  6.3332e-01,\n",
      "         2.0031e-01, -6.7639e-01, -9.9969e-01,  2.6863e-01, -9.9965e-01,\n",
      "        -8.1503e-01,  1.0862e-01,  7.4468e-01, -9.9726e-01, -2.9650e-01,\n",
      "        -6.3087e-02, -9.9957e-01,  3.5260e-02, -4.8452e-01,  2.2934e-01,\n",
      "        -8.6020e-01,  8.4627e-01, -1.1634e-01,  7.2328e-01,  7.3287e-01,\n",
      "        -6.4276e-01,  4.7162e-03, -6.1106e-01,  9.9183e-01,  5.4653e-01,\n",
      "         2.7754e-01,  1.6553e-01, -5.8914e-01,  5.3569e-01, -7.6522e-01,\n",
      "        -7.0907e-01, -8.2337e-01, -5.4550e-01,  9.3471e-01,  6.7054e-01,\n",
      "        -9.9740e-01, -8.4155e-01,  7.3936e-01, -6.1606e-01,  8.2916e-01,\n",
      "        -5.6806e-01, -9.9836e-01, -9.9869e-01,  3.7636e-01,  2.2697e-02,\n",
      "         8.1796e-01, -3.1344e-01,  9.9958e-01,  3.2357e-01,  1.8811e-01,\n",
      "        -3.2486e-01, -1.4517e-01, -1.6701e-01, -2.8655e-01, -4.6927e-01,\n",
      "         9.9944e-01,  5.7009e-01,  8.6055e-01], grad_fn=<SliceBackward>)\n",
      "tensor([-4.6216e-01,  5.7067e-01,  9.9865e-01, -9.4402e-01,  7.9339e-01,\n",
      "         2.1265e-01,  8.0589e-01, -9.7782e-01, -6.8291e-01, -4.3096e-01,\n",
      "         9.0200e-01,  9.6034e-01, -9.7895e-01, -9.9730e-01, -1.5120e-01,\n",
      "        -7.2610e-01,  8.7503e-01, -6.4435e-01, -9.9924e-01,  2.6637e-01,\n",
      "        -2.0134e-01, -9.9789e-01,  3.9919e-01,  7.9126e-01,  6.3685e-01,\n",
      "        -9.1979e-02,  8.7363e-01,  9.9919e-01,  6.3127e-01, -2.5146e-01,\n",
      "         3.5973e-01, -8.9676e-01,  2.5418e-01, -9.8673e-01,  2.4591e-01,\n",
      "        -1.1116e-01,  2.1887e-01, -2.0567e-01,  3.7516e-01, -7.0381e-01,\n",
      "        -4.3400e-01,  4.0518e-01,  2.7975e-01, -4.8400e-01,  3.5203e-01,\n",
      "        -3.8795e-01,  2.8020e-01, -7.6245e-02, -1.9333e-01,  9.9949e-01,\n",
      "        -7.1483e-01,  9.8504e-01, -9.6527e-01,  8.8767e-01,  9.2187e-01,\n",
      "         7.8503e-02,  9.5161e-01,  2.8740e-01, -9.8773e-01,  3.5028e-01,\n",
      "         8.3765e-01,  6.4387e-02,  6.1755e-01, -4.1354e-01, -2.1259e-01,\n",
      "         4.8861e-01, -7.6083e-01,  3.3351e-01, -1.4885e-02,  3.5918e-02,\n",
      "        -3.2515e-01,  4.6959e-01,  8.4646e-01, -8.5193e-01, -1.2982e-01,\n",
      "        -6.8896e-01,  2.1930e-01, -9.9880e-01,  6.7100e-01,  9.9916e-01,\n",
      "         6.0805e-01, -9.9322e-01,  9.0406e-01, -1.2290e-01, -3.4990e-01,\n",
      "         9.5499e-02, -9.8536e-01, -9.8845e-01,  4.8159e-02, -3.4310e-01,\n",
      "         6.4303e-01, -8.5906e-01,  2.3672e-01, -2.5866e-01,  9.9929e-01,\n",
      "        -5.8153e-01, -3.9426e-01,  1.8674e-01,  7.3961e-01, -6.6949e-01,\n",
      "        -5.2492e-01,  7.2015e-01,  9.8283e-01, -9.2999e-01,  9.8154e-01,\n",
      "         1.9749e-01, -6.5026e-01, -5.7822e-01,  3.3355e-01,  3.6251e-01,\n",
      "         8.2362e-01, -8.8353e-01, -6.1604e-01,  2.5874e-01,  7.4811e-01,\n",
      "        -7.5351e-01,  9.0910e-01,  1.1030e-01, -4.7898e-01,  9.9950e-01,\n",
      "        -1.3759e-01,  2.6963e-01,  9.7618e-01, -3.3798e-02, -6.4261e-01,\n",
      "        -4.0934e-01, -3.0253e-01, -6.8326e-02, -4.1139e-02, -4.6737e-01,\n",
      "         7.0101e-01, -9.1036e-01, -9.7189e-01,  9.8957e-01, -3.2723e-01,\n",
      "         9.9917e-01, -9.8093e-01,  8.9580e-01, -9.9899e-01, -8.7153e-01,\n",
      "        -7.5408e-02, -1.7885e-01, -7.3447e-01,  2.9673e-01,  8.2213e-01,\n",
      "         2.9580e-01, -5.2468e-01, -1.5164e-01,  5.0840e-01, -5.2861e-01,\n",
      "         3.8338e-02,  7.2740e-01, -7.0163e-01,  9.6869e-01,  9.7613e-01,\n",
      "         7.2278e-01,  7.1871e-01,  3.7710e-01, -4.0049e-01,  3.4009e-01,\n",
      "         8.4803e-01, -9.8266e-01,  2.4321e-01, -9.1472e-01,  9.9366e-01,\n",
      "         8.8800e-01,  5.5970e-01, -9.7275e-01,  9.9826e-01, -4.8123e-01,\n",
      "        -1.1890e-01, -3.5358e-01, -6.1381e-02, -9.8215e-01,  3.6776e-01,\n",
      "         5.9912e-01,  6.0970e-01,  9.9472e-01, -9.5328e-01,  9.9743e-01,\n",
      "         9.5709e-01,  8.9407e-02,  5.8339e-01,  9.8363e-01, -9.5523e-01,\n",
      "        -7.5848e-01, -8.5427e-01,  2.3206e-01, -3.9810e-02,  4.6517e-01,\n",
      "         4.7180e-01,  7.1367e-01,  9.7700e-01,  9.2313e-02, -9.8251e-01,\n",
      "        -2.8060e-01,  8.0055e-01, -2.7778e-01,  9.9894e-01,  3.1413e-01,\n",
      "        -9.9657e-01,  1.3720e-01,  1.3530e-01,  7.2252e-01, -2.6772e-01,\n",
      "         7.7451e-01, -5.7700e-01,  1.2495e-02,  9.7336e-01, -9.6824e-01,\n",
      "         9.6802e-01, -1.6164e-01, -1.0696e-01,  4.4525e-01,  8.2649e-01,\n",
      "        -1.1997e-01, -3.3569e-01,  4.5267e-01, -3.7768e-01,  9.9841e-01,\n",
      "        -9.9461e-01, -4.2072e-01,  9.5913e-02, -9.7285e-01, -9.6417e-01,\n",
      "         7.9807e-01, -3.0712e-01, -4.5053e-01, -4.1270e-01, -1.4404e-01,\n",
      "         2.9820e-01,  7.0793e-01,  8.8547e-01,  5.5772e-02, -4.6513e-01,\n",
      "        -9.9725e-01, -9.4872e-01, -3.7076e-01, -6.3173e-01,  1.8261e-01,\n",
      "         6.1632e-01, -4.8532e-01, -8.3514e-01, -9.7748e-01,  8.6602e-01,\n",
      "         3.6955e-01, -3.7371e-01,  1.8348e-01, -2.3905e-01, -9.6972e-01,\n",
      "        -2.0740e-01, -5.5058e-02, -9.8419e-01,  9.9470e-01, -1.6859e-01,\n",
      "         9.6696e-01,  7.4893e-01, -8.3113e-01,  8.0477e-01, -9.8359e-01,\n",
      "        -2.7247e-01, -9.7153e-01,  2.7780e-01,  3.4328e-01,  2.3680e-01,\n",
      "        -1.7854e-01,  8.3261e-01, -6.2991e-01, -4.8336e-01,  2.1611e-01,\n",
      "        -9.9852e-01,  7.1900e-01, -5.1428e-02,  9.7998e-01, -3.7694e-01,\n",
      "         1.8748e-01,  8.2037e-01,  8.4703e-01, -8.6342e-01, -9.9719e-01,\n",
      "         4.8187e-01,  9.5953e-01, -9.2899e-01, -2.3168e-01,  9.9842e-01,\n",
      "        -9.7094e-01, -5.8245e-01, -7.6369e-01, -7.6248e-01, -9.9395e-01,\n",
      "         1.0500e-01, -3.8290e-01,  9.1112e-03,  8.9387e-01,  3.3405e-01,\n",
      "         6.3822e-02,  9.0850e-01,  8.3108e-01, -1.6133e-01,  9.9891e-02,\n",
      "         4.0040e-01, -9.0615e-01, -9.7265e-01, -2.3081e-01,  2.9063e-01,\n",
      "        -9.9919e-01,  9.9655e-01, -8.1322e-01,  9.6517e-01,  2.4535e-01,\n",
      "        -9.6945e-01,  5.6548e-01, -3.5037e-03, -5.6062e-01,  2.2017e-01,\n",
      "         9.9790e-01,  8.6115e-01, -2.9829e-01,  2.4330e-01,  5.5568e-01,\n",
      "        -1.0648e-02,  4.2849e-01, -2.4538e-01, -1.7078e-01,  2.7102e-01,\n",
      "        -7.8765e-01,  8.6813e-01,  1.9997e-01, -8.9172e-01,  9.4686e-01,\n",
      "         2.6764e-01,  5.6444e-01, -2.2800e-01,  6.5719e-01,  8.9788e-01,\n",
      "        -2.7954e-01, -2.8888e-01,  2.8019e-01, -9.4198e-01, -8.9727e-01,\n",
      "         1.8355e-01, -9.8012e-01, -8.3950e-02,  6.7108e-01,  8.5994e-01,\n",
      "        -8.5706e-01,  8.8356e-01, -6.3124e-02,  7.1745e-01, -9.6985e-01,\n",
      "         9.9972e-01, -8.8103e-01,  3.7483e-01,  2.3776e-01, -3.7673e-01,\n",
      "        -2.1196e-01,  8.7762e-01,  9.6981e-01,  8.9830e-01, -3.5923e-01,\n",
      "        -6.7648e-01,  3.1176e-01,  7.2195e-01, -7.4334e-01, -2.4888e-01,\n",
      "        -9.8809e-01, -6.6645e-02,  9.7812e-01,  9.7019e-01, -7.7759e-02,\n",
      "         1.7449e-01, -9.7106e-01,  5.7593e-01, -4.0039e-01, -8.3674e-02,\n",
      "        -3.0997e-01, -6.4338e-01,  6.0954e-01,  9.8305e-01, -3.9278e-01,\n",
      "         5.9177e-01,  2.5237e-01, -8.6505e-01,  7.4974e-01,  7.7343e-01,\n",
      "         9.9666e-01, -9.1569e-01,  2.5043e-01,  8.4566e-01, -3.3165e-01,\n",
      "        -6.3078e-01,  3.5081e-01,  9.8418e-01, -6.6700e-01, -2.5334e-01,\n",
      "        -9.9074e-01, -2.5830e-04, -5.4956e-01,  4.9938e-02,  1.5638e-02,\n",
      "         6.7282e-02, -6.5565e-01,  5.5447e-01,  2.7821e-02,  4.5675e-01,\n",
      "         2.5038e-01,  7.4836e-01, -3.4884e-01,  1.6530e-02, -3.1479e-01,\n",
      "        -1.5678e-02,  5.9078e-01,  5.4086e-02,  7.5022e-01, -5.7371e-01,\n",
      "         9.9802e-01,  1.5397e-01, -9.9885e-01, -9.5804e-01,  9.3347e-02,\n",
      "        -9.9854e-01,  9.6389e-02, -8.9962e-01,  7.7972e-01,  1.1286e-01,\n",
      "        -9.7287e-01, -9.8403e-01, -8.9334e-01, -9.3898e-01,  2.2148e-01,\n",
      "         1.5260e-01, -3.0020e-01, -4.4180e-01,  9.0994e-01,  1.2631e-01,\n",
      "         1.5733e-01, -2.3508e-02, -6.3284e-01, -4.9263e-01, -9.6871e-01,\n",
      "         3.8080e-01, -9.9886e-01, -1.1541e-01,  9.6850e-01, -9.8373e-01,\n",
      "        -4.7917e-01, -7.4104e-01, -5.6138e-01, -7.0227e-01,  4.7333e-01,\n",
      "         8.0244e-01,  4.9248e-02, -9.6052e-02, -9.9818e-01,  8.0616e-01,\n",
      "        -4.3760e-01,  4.7669e-02, -8.2336e-01, -8.1881e-01,  9.9556e-01,\n",
      "         5.7167e-01, -1.2644e-01, -2.3847e-02, -9.9047e-01,  8.0634e-01,\n",
      "        -8.3516e-01, -6.0345e-01, -9.2059e-01,  2.2257e-01, -8.4519e-01,\n",
      "        -9.9747e-01,  3.9139e-01,  9.6564e-01,  8.7423e-01,  9.1028e-01,\n",
      "         3.4801e-01, -4.3542e-01, -7.7794e-01,  2.7745e-01, -9.9922e-01,\n",
      "         3.4824e-01,  6.7333e-01, -6.3696e-01, -2.3996e-01,  7.8944e-01,\n",
      "         8.0743e-01, -6.8006e-01, -7.8444e-01,  1.1895e-01,  6.2609e-02,\n",
      "         7.0588e-01,  4.3315e-02, -9.1028e-02,  4.6063e-01, -9.3190e-02,\n",
      "        -9.0775e-01, -7.2959e-01,  9.5470e-01, -9.8437e-01,  2.9876e-01,\n",
      "         9.0743e-01,  9.7307e-01,  3.6160e-02, -1.2252e-02, -7.9041e-01,\n",
      "        -9.3625e-01, -3.2195e-01, -1.1964e-01, -9.9879e-01,  9.9860e-01,\n",
      "        -9.9934e-01,  3.5855e-01, -2.1856e-01,  4.2187e-01,  9.3858e-01,\n",
      "         1.2738e-01, -9.9746e-01, -9.9839e-01, -2.3586e-01,  9.4899e-02,\n",
      "         8.8415e-01, -4.1909e-02,  8.6689e-02, -1.1913e-01, -2.9925e-01,\n",
      "         9.1305e-01,  4.9636e-01, -2.0748e-01, -9.6987e-01,  9.9303e-01,\n",
      "         2.5809e-01, -9.7641e-01,  9.0436e-01, -9.9533e-01,  8.8774e-01,\n",
      "         8.9466e-01,  6.2153e-01,  7.8060e-01, -9.7978e-01,  9.9914e-01,\n",
      "        -9.9799e-01,  8.5412e-01, -9.9941e-01, -9.8619e-01,  9.9684e-01,\n",
      "        -9.0468e-01,  5.8214e-02, -9.9345e-01, -9.7106e-01,  1.7969e-01,\n",
      "         3.3747e-01, -3.1650e-01,  8.9155e-01, -9.9712e-01, -9.6199e-01,\n",
      "         2.0160e-01,  1.2536e-01, -6.6469e-01,  9.6280e-01, -2.0272e-01,\n",
      "         8.2127e-01,  2.7510e-02,  8.0967e-01,  2.4006e-01,  9.8775e-01,\n",
      "         9.5800e-01,  5.4882e-02, -2.5048e-01, -9.1867e-01,  9.0353e-01,\n",
      "        -1.0079e-01,  2.5958e-01,  8.2353e-01, -1.4343e-02, -2.4596e-01,\n",
      "         1.9105e-01, -9.3647e-01,  2.6298e-01, -4.2474e-01,  9.1966e-01,\n",
      "         2.9347e-01,  7.1482e-01,  3.1467e-01, -2.1501e-01, -1.9445e-02,\n",
      "        -9.2132e-01,  6.1522e-01, -9.9378e-01,  6.5152e-01, -5.9684e-01,\n",
      "         1.7893e-01, -3.5105e-01,  5.1233e-01, -2.5378e-01,  9.9492e-01,\n",
      "         9.7470e-01, -9.7029e-01,  2.4927e-01,  8.4725e-01, -3.0246e-01,\n",
      "         7.9088e-01, -9.1180e-01, -1.2747e-02,  8.6696e-01, -5.2611e-01,\n",
      "         8.4145e-01,  5.0881e-02, -1.8809e-01,  9.2469e-01, -9.3717e-01,\n",
      "        -5.7492e-01, -4.9442e-01,  1.8296e-01, -2.7495e-01, -7.7370e-01,\n",
      "         1.6321e-02,  8.7264e-01,  1.7768e-01, -9.9434e-01, -2.0962e-01,\n",
      "        -9.8797e-01, -2.1879e-01,  8.1973e-01,  4.6848e-01,  9.9820e-01,\n",
      "        -6.2841e-01,  7.6545e-02, -9.4271e-02, -9.9452e-01, -9.8600e-01,\n",
      "         2.9348e-01, -2.7154e-01, -4.6257e-01,  9.8617e-01,  6.6775e-02,\n",
      "         2.1998e-01, -9.9870e-01,  4.1278e-01,  9.5646e-01,  3.5536e-01,\n",
      "         5.4498e-01, -6.6879e-01, -4.7279e-01, -8.3909e-01, -1.0359e-01,\n",
      "         2.8556e-01,  5.5805e-01, -7.3215e-01,  5.3080e-02, -6.4059e-01,\n",
      "         9.9929e-01, -9.5596e-01, -6.9173e-01, -8.8258e-01,  4.0973e-01,\n",
      "         4.2084e-01,  5.3529e-01,  2.0325e-01,  9.9008e-02,  8.8188e-01,\n",
      "        -6.3794e-01,  9.3589e-01, -9.3866e-01, -9.4356e-01,  9.9591e-01,\n",
      "        -1.8968e-03, -9.4213e-01,  1.0405e-01, -5.0471e-01,  3.2844e-02,\n",
      "         6.8119e-02,  7.5814e-01, -1.3759e-01, -2.7807e-01, -9.3574e-01,\n",
      "         4.2663e-01, -3.9169e-01, -7.3805e-01, -4.2715e-01, -1.5017e-01,\n",
      "        -9.7394e-01,  9.2650e-01,  8.7224e-01,  9.9851e-01, -9.9442e-01,\n",
      "         7.3610e-01,  2.7250e-01,  9.8310e-01,  1.4935e-01, -5.9033e-01,\n",
      "        -7.0035e-02,  9.9031e-01,  3.5851e-02,  3.2834e-01, -2.5598e-02,\n",
      "        -1.0989e-01,  2.6820e-01, -5.6297e-01,  9.8665e-01, -4.6497e-01,\n",
      "        -2.8471e-01, -8.6587e-01, -9.9852e-01,  9.9895e-01, -1.6813e-01,\n",
      "         9.5683e-01,  5.0078e-01,  4.1104e-01, -4.3019e-01,  9.1848e-01,\n",
      "        -5.8106e-01, -6.9529e-01, -9.9952e-01, -5.9128e-02, -9.8369e-01,\n",
      "        -9.1293e-01, -2.8530e-01,  8.5313e-01, -9.9560e-01, -6.8213e-01,\n",
      "        -1.6073e-01, -9.9943e-01,  7.5655e-01, -8.7517e-01, -4.8867e-01,\n",
      "        -8.9043e-01,  9.7349e-01,  2.8586e-02, -8.9084e-02,  7.6983e-01,\n",
      "        -7.2916e-01,  5.3045e-01, -1.0936e-01,  7.8865e-01,  4.4621e-01,\n",
      "         2.6575e-01, -2.1787e-01, -9.2729e-01, -8.8391e-02, -8.3110e-01,\n",
      "        -2.2825e-01, -9.0121e-01, -6.3198e-01,  9.5089e-01,  8.6854e-01,\n",
      "        -9.9170e-01, -9.0665e-01,  9.3119e-01, -1.3321e-01,  9.1501e-01,\n",
      "        -2.8643e-01, -9.9709e-01, -9.9869e-01,  2.1823e-01,  1.9099e-01,\n",
      "         8.9280e-01, -2.9895e-01,  9.7306e-01,  4.0635e-01, -2.6267e-01,\n",
      "         3.1621e-01, -5.6088e-01, -1.1052e-01, -3.9799e-01, -2.5686e-01,\n",
      "         9.9865e-01, -1.0993e-01,  9.0169e-01], grad_fn=<SliceBackward>)\n",
      "tensor([-5.6024e-01,  6.6035e-01,  9.9917e-01, -9.4330e-01,  7.9979e-01,\n",
      "        -5.6805e-01,  7.5231e-01, -8.0783e-01, -6.5795e-01, -3.0807e-01,\n",
      "         8.3171e-01,  9.7016e-01, -8.2447e-01, -9.9875e-01, -8.5499e-01,\n",
      "        -7.0098e-01,  8.3487e-01, -6.0572e-01, -9.9962e-01,  5.8081e-01,\n",
      "        -3.6236e-02, -9.9842e-01,  4.6180e-01,  4.3539e-01,  5.3590e-01,\n",
      "        -1.0976e-01,  6.3437e-01,  9.9960e-01, -8.6866e-02,  7.1551e-01,\n",
      "         3.0396e-01, -8.9597e-01, -5.6154e-01, -9.8810e-01,  3.3132e-01,\n",
      "        -8.2625e-02, -4.0943e-01, -2.8061e-01,  5.5070e-02, -1.9783e-01,\n",
      "        -2.2213e-01,  7.8736e-01, -4.8758e-02, -5.3946e-01, -4.0220e-01,\n",
      "        -4.0151e-01,  4.8770e-01, -2.2628e-01, -4.2362e-01,  9.9994e-01,\n",
      "        -6.3650e-01,  9.9985e-01, -7.3224e-01,  9.8004e-01,  8.8541e-01,\n",
      "         1.5700e-01,  9.3695e-01,  2.6510e-01, -8.8208e-01,  3.5845e-01,\n",
      "         7.6144e-01, -2.1676e-02,  1.4394e-01, -5.3031e-01, -7.7432e-01,\n",
      "         6.6212e-01, -1.7005e-01,  5.7936e-01,  1.0548e-01,  6.0437e-02,\n",
      "        -5.6500e-01,  6.3274e-01,  9.0127e-01, -7.9381e-01,  1.1546e-01,\n",
      "        -5.3593e-01,  8.5240e-01, -9.9948e-01,  2.9006e-01,  9.9922e-01,\n",
      "        -2.6686e-01, -9.9515e-01,  9.2337e-01, -3.8772e-01,  2.9851e-01,\n",
      "        -8.1822e-01, -8.1017e-01, -9.9213e-01,  1.0615e-01,  5.1270e-02,\n",
      "        -1.3153e-01, -8.3875e-01, -1.8732e-01,  4.7743e-01,  9.9962e-01,\n",
      "         6.2191e-01, -4.2018e-01,  2.4069e-01,  2.2783e-01, -5.3412e-03,\n",
      "        -4.5838e-01,  1.9303e-01,  7.8783e-01, -4.6108e-01,  8.2941e-01,\n",
      "        -3.5438e-01, -6.5514e-01, -2.7845e-02, -6.8209e-01,  3.8525e-01,\n",
      "         7.9883e-01, -7.4745e-01, -2.5636e-01,  3.3927e-01,  1.7784e-01,\n",
      "        -3.1152e-01,  8.8181e-01, -5.3637e-01, -5.1779e-01,  9.9973e-01,\n",
      "        -3.7693e-01, -6.4069e-01,  9.7017e-01, -8.3588e-01,  2.0864e-01,\n",
      "        -4.8025e-01,  6.0365e-01, -6.4676e-01,  3.8281e-01, -1.7133e-01,\n",
      "         7.0132e-01, -8.9995e-01, -6.3308e-01,  9.9112e-01, -5.5626e-01,\n",
      "         9.9953e-01, -9.8691e-01,  6.0392e-01, -9.9933e-01, -6.5350e-01,\n",
      "         7.2128e-01, -3.4294e-01,  2.6097e-01,  4.4793e-01,  6.6262e-01,\n",
      "         4.2039e-01,  2.5857e-01,  7.5494e-01,  4.4597e-01,  3.6436e-01,\n",
      "         4.2763e-01,  6.6806e-01, -5.4856e-01,  9.9955e-01,  8.1223e-01,\n",
      "         7.6125e-02, -1.1775e-01,  4.9871e-01,  5.9242e-01, -1.3721e-01,\n",
      "         4.9193e-01, -9.8650e-01, -5.6853e-01, -5.0885e-01,  9.9545e-01,\n",
      "         8.7935e-01, -1.7479e-01, -7.0809e-01,  9.9876e-01,  5.7705e-01,\n",
      "         2.6489e-01, -6.2312e-01, -3.7966e-01, -7.6949e-01,  3.9685e-01,\n",
      "         6.0127e-01,  3.7375e-01,  9.9900e-01, -9.4280e-01,  9.9968e-01,\n",
      "         9.9940e-01, -1.3412e-01,  4.5672e-01,  8.5278e-01, -9.4490e-01,\n",
      "        -7.0763e-01, -7.8773e-01,  4.5149e-01, -7.4994e-01, -5.4010e-02,\n",
      "         2.5382e-01,  6.8083e-01,  7.0621e-01, -4.3242e-01, -9.9566e-01,\n",
      "        -4.6137e-01,  7.4879e-01, -3.4488e-01,  9.9940e-01,  7.9570e-01,\n",
      "        -9.9677e-01,  7.2518e-01, -6.1426e-01,  7.5928e-01, -3.0311e-01,\n",
      "         7.6929e-01,  2.5747e-01,  2.5889e-01,  8.2552e-01, -9.9973e-01,\n",
      "         5.8992e-01, -4.7963e-01, -7.7535e-01,  4.4266e-01,  8.0813e-01,\n",
      "         5.9131e-01, -3.9886e-01,  3.3343e-01,  3.0500e-01,  9.9883e-01,\n",
      "        -9.9395e-01, -1.3219e-01,  1.4083e-01, -9.7159e-01, -9.4874e-01,\n",
      "         7.7972e-01, -2.8845e-01,  4.2974e-01, -3.9490e-01, -9.3650e-01,\n",
      "         1.8243e-01,  3.0741e-01,  8.9984e-01,  4.7558e-01,  5.8353e-01,\n",
      "        -9.9838e-01, -2.5882e-01,  1.6281e-01,  2.6982e-01,  3.8857e-01,\n",
      "         7.2059e-01, -4.9648e-01, -5.2211e-01, -7.6569e-01,  8.6456e-01,\n",
      "        -1.9848e-01,  3.6237e-01, -1.9507e-01,  5.6698e-01, -5.6042e-01,\n",
      "        -7.0548e-01,  3.9560e-01, -9.8998e-01,  9.9632e-01,  8.4617e-01,\n",
      "         7.0671e-01,  8.2857e-01, -8.8279e-01,  4.0018e-01, -8.1634e-01,\n",
      "        -2.5769e-01, -9.9907e-01,  1.0055e-01, -5.8718e-01,  7.6655e-01,\n",
      "        -2.9330e-01,  8.6546e-01, -2.8097e-01,  2.5840e-01, -2.7834e-01,\n",
      "        -9.9901e-01,  8.2898e-01, -2.4792e-01,  9.7691e-01, -8.5674e-01,\n",
      "         7.1089e-01,  7.9466e-01,  4.1419e-01, -8.0096e-01, -9.9795e-01,\n",
      "        -1.8655e-01,  9.9941e-01, -9.0932e-01, -5.2503e-01,  9.9858e-01,\n",
      "        -7.0142e-01, -3.1913e-01, -8.3231e-01, -9.0356e-01, -9.9265e-01,\n",
      "         1.2510e-01,  2.5429e-01, -5.4841e-02,  8.3562e-01, -5.4874e-01,\n",
      "         1.2847e-02,  9.5117e-01,  9.6395e-01, -2.3678e-01,  3.6719e-01,\n",
      "         4.5414e-01, -8.7488e-01, -9.9976e-01, -5.2989e-01,  4.1042e-01,\n",
      "        -9.9966e-01,  9.9837e-01, -8.1006e-01,  9.9952e-01, -6.9342e-01,\n",
      "        -7.5453e-01,  4.8752e-01, -2.5946e-01,  2.2943e-01,  2.9158e-01,\n",
      "         9.9857e-01,  7.7986e-01, -4.8768e-01,  2.9586e-01, -1.1392e-01,\n",
      "         1.9867e-01, -5.0966e-01,  4.3962e-01,  1.0336e-02,  2.8165e-01,\n",
      "        -7.8528e-01,  3.8141e-01, -4.1242e-01, -8.5040e-01,  7.4248e-01,\n",
      "         2.7323e-01,  4.3104e-01,  1.4489e-01,  4.1052e-01,  8.7860e-01,\n",
      "        -2.7886e-01,  1.6597e-01,  1.8349e-01, -9.9913e-01, -6.2024e-01,\n",
      "         2.6538e-01, -8.9647e-01,  2.8796e-01, -3.0408e-01,  8.1726e-01,\n",
      "        -7.0955e-01,  9.8451e-01, -1.3866e-01,  3.4325e-01, -6.7881e-01,\n",
      "         9.9977e-01, -9.5098e-01,  3.7616e-01, -3.3269e-01,  4.9624e-01,\n",
      "         5.0859e-01,  9.0742e-01,  7.4952e-01,  5.9763e-01,  4.8089e-01,\n",
      "        -8.9546e-02, -4.1775e-02,  7.9471e-01,  2.0521e-01, -1.5117e-01,\n",
      "        -7.6433e-01,  7.1841e-01,  9.8893e-01,  5.9599e-01, -1.7345e-01,\n",
      "        -7.8145e-01, -7.6432e-01,  2.3956e-01,  3.7711e-01,  2.4244e-01,\n",
      "        -4.0904e-01, -2.4666e-01,  2.8798e-02,  8.0623e-01,  3.8206e-01,\n",
      "         2.9733e-01,  3.1330e-01, -8.2959e-01,  5.0953e-01,  4.1312e-01,\n",
      "         9.9664e-01, -8.0707e-01,  1.7191e-01,  8.1710e-01, -4.5531e-01,\n",
      "        -1.6027e-01,  4.0371e-01,  8.4168e-01, -4.6007e-01, -2.3325e-01,\n",
      "        -9.9305e-01, -1.1427e-01, -7.9111e-01,  5.7277e-01,  6.7609e-01,\n",
      "         1.5856e-02,  2.3924e-01, -2.1409e-01,  8.9332e-02,  2.2070e-01,\n",
      "         2.7270e-01,  6.5522e-01, -6.4212e-02, -2.6218e-01, -4.9945e-01,\n",
      "         3.9026e-01,  4.2894e-01, -2.9673e-01,  7.4108e-01, -3.9438e-01,\n",
      "         9.9944e-01, -6.1765e-02, -9.9925e-01, -6.1315e-01,  6.1074e-01,\n",
      "        -9.9968e-01, -7.0873e-01, -9.7544e-01,  8.6035e-01, -6.9884e-01,\n",
      "        -7.4771e-01, -7.9937e-01, -9.7533e-01, -9.9734e-01, -3.8111e-01,\n",
      "        -6.4402e-01, -3.5333e-01, -9.0536e-01,  9.9901e-01,  8.4752e-03,\n",
      "        -9.9551e-04, -8.6640e-02, -4.8836e-01, -5.6169e-02, -6.4092e-01,\n",
      "        -8.1723e-03, -9.9951e-01,  6.1013e-01,  7.8141e-01, -8.1064e-01,\n",
      "         4.7873e-01, -7.7443e-01,  5.0609e-01, -6.8580e-01,  3.8377e-01,\n",
      "         8.4593e-01,  1.8974e-01,  4.4870e-01, -9.9981e-01,  8.4271e-01,\n",
      "         2.8026e-01,  3.8463e-02, -5.1165e-01, -8.0753e-01,  9.9760e-01,\n",
      "        -1.2791e-01,  1.0722e-01, -2.1249e-01, -9.9034e-01,  3.8841e-02,\n",
      "        -7.2242e-02, -2.1027e-01, -9.0300e-01,  3.9767e-01, -3.1136e-01,\n",
      "        -9.9874e-01,  5.6802e-01,  5.9674e-01,  9.4756e-01,  8.9049e-01,\n",
      "        -5.5413e-02, -5.5276e-01, -6.8722e-01,  2.5002e-01, -9.9937e-01,\n",
      "        -4.5878e-01,  5.6648e-02, -4.0951e-01,  6.4859e-01,  8.1508e-01,\n",
      "         8.3842e-01,  2.8058e-01, -1.8391e-01, -5.7543e-01,  4.3716e-01,\n",
      "         2.5075e-01,  7.9810e-01, -1.3177e-01,  6.5276e-01, -2.0304e-01,\n",
      "        -8.3493e-01, -6.3765e-01,  9.5472e-01, -7.5342e-01,  3.0426e-01,\n",
      "         4.0696e-01,  7.7305e-01,  4.2283e-01, -1.4826e-01,  9.0764e-02,\n",
      "        -9.9579e-01, -1.1815e-01, -2.5216e-01, -9.9891e-01,  9.9911e-01,\n",
      "        -9.9962e-01,  1.5183e-03,  5.9842e-01, -5.5828e-01,  8.9357e-01,\n",
      "         6.6000e-02, -9.9913e-01, -9.9877e-01, -9.3094e-01, -2.2221e-01,\n",
      "         8.7539e-01, -2.7937e-02,  2.8122e-01,  5.1506e-01, -2.3884e-01,\n",
      "         9.4595e-01,  8.9657e-01,  7.3683e-01, -7.4870e-01,  9.9440e-01,\n",
      "         2.4384e-01, -9.7753e-01,  6.1183e-01, -9.9739e-01,  2.4152e-01,\n",
      "         8.6194e-01,  7.5214e-01,  7.9916e-01, -7.5447e-01,  9.9959e-01,\n",
      "        -9.9872e-01,  9.6951e-01, -9.9966e-01, -8.0802e-01,  9.9810e-01,\n",
      "        -8.1989e-01,  5.9514e-01, -9.9527e-01, -8.3874e-01, -8.1052e-01,\n",
      "         3.6144e-01, -4.7874e-01,  8.8608e-01, -9.9625e-01, -9.6899e-01,\n",
      "         3.4210e-01,  7.5378e-01, -1.1341e-01,  7.0813e-01,  5.6348e-01,\n",
      "         9.0942e-01,  2.4847e-01,  8.8184e-01, -1.6978e-01,  8.8956e-01,\n",
      "         9.9810e-01,  4.3094e-01,  7.4559e-01, -9.1018e-01,  8.1684e-01,\n",
      "         4.8587e-01,  2.7834e-01,  7.9640e-01, -2.6069e-01,  6.0716e-01,\n",
      "         5.3197e-01, -9.4294e-01, -1.4210e-03, -9.2739e-01,  5.7341e-01,\n",
      "        -5.0302e-01,  7.8661e-01,  2.8298e-01,  2.2500e-01,  1.5984e-01,\n",
      "        -9.0878e-01,  5.8791e-01, -9.9046e-01,  5.0467e-01,  2.8115e-01,\n",
      "         2.5557e-01, -4.1180e-01,  7.0710e-01, -4.2974e-01,  9.9487e-01,\n",
      "         9.8232e-01, -9.9954e-01,  2.9463e-01,  8.8433e-01,  6.5612e-01,\n",
      "         5.6566e-01, -8.8115e-01, -2.4359e-01,  5.4642e-01, -3.0703e-01,\n",
      "         7.6803e-01,  4.0012e-01, -4.9136e-01,  9.2800e-01, -9.4942e-01,\n",
      "         1.5068e-01, -4.0471e-01, -7.9158e-02, -1.8667e-01, -7.7618e-01,\n",
      "         2.5884e-01,  2.5655e-01,  4.7197e-01, -9.9311e-01, -8.4170e-01,\n",
      "        -9.9174e-01, -3.5658e-01,  8.7940e-01,  8.7185e-01,  9.9865e-01,\n",
      "        -1.4768e-02, -1.5286e-01, -2.4092e-01, -9.9670e-01, -8.3350e-01,\n",
      "         3.1684e-01, -3.1524e-01,  6.5871e-01,  7.9710e-01,  2.2950e-01,\n",
      "        -6.9819e-01, -9.9953e-01,  4.6790e-01,  6.7277e-01,  5.9690e-01,\n",
      "        -3.8625e-02,  4.6141e-02, -1.4976e-01, -1.6487e-01,  9.5699e-02,\n",
      "         3.7317e-01, -1.2281e-01, -7.5478e-01,  7.8105e-01, -2.5495e-01,\n",
      "         9.9969e-01, -9.5585e-01, -7.4459e-01, -7.7484e-01,  3.3352e-02,\n",
      "        -3.8963e-01,  5.3627e-01,  3.2060e-01,  7.1204e-01,  3.6528e-01,\n",
      "        -6.1209e-02,  9.3804e-01, -9.4910e-01, -9.6129e-01,  9.9791e-01,\n",
      "        -8.1352e-01, -6.2145e-01, -4.0664e-01, -4.3318e-01, -2.5509e-01,\n",
      "        -2.1566e-01,  3.8910e-01, -2.7607e-01, -2.1639e-01, -9.7728e-01,\n",
      "        -6.3820e-01,  6.2304e-01, -6.6766e-01, -1.7833e-01, -3.8103e-01,\n",
      "        -9.9984e-01,  8.9538e-01,  8.4997e-01,  9.9932e-01, -9.9672e-01,\n",
      "         5.8202e-01,  2.3678e-01,  9.8350e-01, -5.0638e-03, -5.3699e-01,\n",
      "        -7.2540e-01,  9.9611e-01,  6.8052e-01, -3.2191e-01,  4.5880e-02,\n",
      "        -3.7153e-01,  2.0017e-01, -7.8779e-01,  8.4711e-01,  5.4776e-01,\n",
      "         4.5804e-01, -7.9628e-01, -9.9938e-01,  9.9914e-01, -2.4260e-01,\n",
      "         9.4100e-01,  4.9765e-01, -1.0759e-01, -5.4212e-02,  5.9669e-01,\n",
      "         2.7171e-01, -3.1017e-01, -9.9967e-01,  3.2679e-01, -9.9989e-01,\n",
      "        -8.9834e-01,  9.9873e-02,  8.6357e-01, -9.9613e-01, -5.6879e-01,\n",
      "        -6.7778e-02, -9.9974e-01, -9.2478e-03, -3.4513e-01,  3.4563e-01,\n",
      "        -8.6808e-01,  7.0015e-01,  4.8357e-02,  7.8610e-01,  7.4625e-01,\n",
      "        -7.4888e-01, -1.1125e-01, -8.2683e-01,  9.9513e-01,  4.8756e-01,\n",
      "         3.8542e-01,  3.0517e-01, -4.2793e-01,  5.9295e-01, -7.3776e-01,\n",
      "        -8.1285e-01, -8.9297e-01, -1.5513e-02,  9.5527e-01,  8.0485e-01,\n",
      "        -9.9675e-01, -9.0437e-01,  4.6881e-01, -7.5409e-01,  9.2381e-01,\n",
      "        -4.4813e-01, -9.9860e-01, -9.9884e-01,  2.9897e-01, -1.4463e-01,\n",
      "         9.0760e-01, -3.7094e-01,  9.9975e-01,  1.0806e-01,  4.6487e-01,\n",
      "        -6.3458e-01, -3.4433e-02, -1.1683e-01, -2.6581e-01, -4.9482e-01,\n",
      "         9.9944e-01,  5.1584e-01,  8.7584e-01], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(pooled.shape[0]):\n",
    "    print(pooled[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss(torch.tensor([[],[]]), torch.tensor())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
